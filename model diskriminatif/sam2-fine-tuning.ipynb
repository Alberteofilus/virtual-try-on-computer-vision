{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-18T14:13:06.996751Z",
     "iopub.status.busy": "2025-12-18T14:13:06.996275Z",
     "iopub.status.idle": "2025-12-18T14:18:33.114408Z",
     "shell.execute_reply": "2025-12-18T14:18:33.113207Z",
     "shell.execute_reply.started": "2025-12-18T14:13:06.996732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'sam2'...\n",
      "remote: Enumerating objects: 1070, done.\u001b[K\n",
      "remote: Total 1070 (delta 0), reused 0 (delta 0), pack-reused 1070 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1070/1070), 128.11 MiB | 40.46 MiB/s, done.\n",
      "Resolving deltas: 100% (380/380), done.\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m/kaggle/working/sam2\n",
      "Obtaining file:///kaggle/working/sam2\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.2.6)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
      "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.3.0)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (25.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.15.0)\n",
      "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.20.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.3)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: SAM-2, iopath\n",
      "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for SAM-2: filename=sam_2-1.0-0.editable-cp311-cp311-linux_x86_64.whl size=13854 sha256=dd6c768ec2193d95a94a88222315da9157e01b371724ebd57a290a92bd217b36\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mfh40l99/wheels/2b/74/7e/44b6a6f6c7d2776eaa3baacd85c49ff4650b1e232599c6998c\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=21177f96149cf67c9b3b40f28a074a8201fc9a10daeafacc65a35695ca2fc4ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
      "Successfully built SAM-2 iopath\n",
      "Installing collected packages: portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, nvidia-cusolver-cu12, SAM-2\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SAM-2-1.0 hydra-core-1.3.2 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.2.0\n",
      "--2025-12-18 14:18:32--  https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.96, 3.163.189.108, 3.163.189.14, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.96|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 184309650 (176M) [application/vnd.snesdev-page-table]\n",
      "Saving to: ‘checkpoints/sam2_hiera_small.pt’\n",
      "\n",
      "sam2_hiera_small.pt 100%[===================>] 175.77M   298MB/s    in 0.6s    \n",
      "\n",
      "2025-12-18 14:18:33 (298 MB/s) - ‘checkpoints/sam2_hiera_small.pt’ saved [184309650/184309650]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/sam2.git\n",
    "!pip install -q matplotlib opencv-python\n",
    "%cd sam2 \n",
    "!pip install -e .\n",
    "\n",
    "!mkdir -p checkpoints\n",
    "!wget -P checkpoints https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:19:11.254983Z",
     "iopub.status.busy": "2025-12-18T14:19:11.254428Z",
     "iopub.status.idle": "2025-12-18T14:19:11.260323Z",
     "shell.execute_reply": "2025-12-18T14:19:11.259761Z",
     "shell.execute_reply.started": "2025-12-18T14:19:11.254949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:19:14.420875Z",
     "iopub.status.busy": "2025-12-18T14:19:14.420626Z",
     "iopub.status.idle": "2025-12-18T14:20:06.478900Z",
     "shell.execute_reply": "2025-12-18T14:20:06.478122Z",
     "shell.execute_reply.started": "2025-12-18T14:19:14.420857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.2/703.2 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.7/385.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.6/456.6 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for titlecase (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for PTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for async_asgi_testclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for numerize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.2 which is incompatible.\n",
      "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.2 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.2 which is incompatible.\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.2 which is incompatible.\n",
      "google-adk 1.18.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 13.1 which is incompatible.\n",
      "featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.2 which is incompatible.\n",
      "a2a-sdk 0.3.10 requires httpx>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "visions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.2 which is incompatible.\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.2 which is incompatible.\n",
      "google-genai 1.48.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.2 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 2.12.0 requires pandas>=1.5.3, but you have pandas 1.5.2 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\n",
      "gradio 5.38.1 requires python-multipart>=0.0.18, but you have python-multipart 0.0.12 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
      "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 1.5.2 which is incompatible.\n",
      "langsmith 0.4.8 requires requests-toolbelt<2.0.0,>=1.0.0, but you have requests-toolbelt 0.10.1 which is incompatible.\n",
      "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.2 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.2 which is incompatible.\n",
      "db-dtypes 1.4.3 requires pandas>=1.5.3, but you have pandas 1.5.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 13.1 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade dataset-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:23:37.510120Z",
     "iopub.status.busy": "2025-12-18T14:23:37.509360Z",
     "iopub.status.idle": "2025-12-18T14:23:40.920498Z",
     "shell.execute_reply": "2025-12-18T14:23:40.919490Z",
     "shell.execute_reply.started": "2025-12-18T14:23:37.510088Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:23:47.248418Z",
     "iopub.status.busy": "2025-12-18T14:23:47.248031Z",
     "iopub.status.idle": "2025-12-18T14:23:47.253549Z",
     "shell.execute_reply": "2025-12-18T14:23:47.252809Z",
     "shell.execute_reply.started": "2025-12-18T14:23:47.248384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path sam2 berhasil ditambahkan!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.exists('/kaggle/working/sam2'):\n",
    "    sys.path.append('/kaggle/working/sam2')\n",
    "    print(\"Path sam2 berhasil ditambahkan!\")\n",
    "else:\n",
    "    print(\"Folder sam2 tidak ditemukan, pastikan lokasi clone benar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:23:50.042991Z",
     "iopub.status.busy": "2025-12-18T14:23:50.042724Z",
     "iopub.status.idle": "2025-12-18T14:23:50.048511Z",
     "shell.execute_reply": "2025-12-18T14:23:50.047929Z",
     "shell.execute_reply.started": "2025-12-18T14:23:50.042971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direktori awal: /kaggle/working\n",
      "Berhasil pindah ke: /kaggle/working/sam2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(f\"Direktori awal: {os.getcwd()}\")\n",
    "\n",
    "if os.path.exists(\"/kaggle/working/sam2\") and os.getcwd() != \"/kaggle/working/sam2\":\n",
    "    os.chdir(\"/kaggle/working/sam2\")\n",
    "    print(f\"Berhasil pindah ke: {os.getcwd()}\")\n",
    "\n",
    "if \"/kaggle/working/sam2\" not in sys.path:\n",
    "    sys.path.append(\"/kaggle/working/sam2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:23:53.396893Z",
     "iopub.status.busy": "2025-12-18T14:23:53.396205Z",
     "iopub.status.idle": "2025-12-18T16:06:25.682334Z",
     "shell.execute_reply": "2025-12-18T16:06:25.681565Z",
     "shell.execute_reply.started": "2025-12-18T14:23:53.396868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 14:24:06.393019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766067846.571060      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766067846.619271      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODEL] Building SAM2 model...\n",
      "[PEFT] Found 50 linear layers in Mask Decoder to target.\n",
      "trainable params: 236,660 || all params: 46,274,282 || trainable%: 0.5114\n",
      "[DATA] 11647 VITON images found.\n",
      "[DATA] Dataset length: 11647\n",
      "[OPTIMIZER] Using bitsandbytes 8-bit AdamW\n",
      "\n",
      "--- MULAI TRAINING VITON (PEFT + BNB 8-bit) ---\n",
      "\n",
      "[Epoch 1/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/2613205530.py:130: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
      "/tmp/ipykernel_47/2613205530.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_47/2613205530.py:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Step 0 | BCE Loss: 0.267712\n",
      "[Epoch 1] Step 10 | BCE Loss: 0.041734\n",
      "[Epoch 1] Step 20 | BCE Loss: 0.047942\n",
      "[Epoch 1] Step 30 | BCE Loss: 0.066249\n",
      "[Epoch 1] Step 40 | BCE Loss: 0.031446\n",
      "[Epoch 1] Step 50 | BCE Loss: 0.026553\n",
      "[Epoch 1] Step 60 | BCE Loss: 0.031714\n",
      "[Epoch 1] Step 70 | BCE Loss: 0.025866\n",
      "[Epoch 1] Step 80 | BCE Loss: 0.028618\n",
      "[Epoch 1] Step 90 | BCE Loss: 0.031356\n",
      "[Epoch 1] Step 100 | BCE Loss: 0.020659\n",
      "[Epoch 1] Step 110 | BCE Loss: 0.022472\n",
      "[Epoch 1] Step 120 | BCE Loss: 0.020400\n",
      "[Epoch 1] Step 130 | BCE Loss: 0.022779\n",
      "[Epoch 1] Step 140 | BCE Loss: 0.021875\n",
      "[Epoch 1] Step 150 | BCE Loss: 0.029401\n",
      "[Epoch 1] Step 160 | BCE Loss: 0.017893\n",
      "[Epoch 1] Step 170 | BCE Loss: 0.018344\n",
      "[Epoch 1] Step 180 | BCE Loss: 0.023489\n",
      "[Epoch 1] Step 190 | BCE Loss: 0.022257\n",
      "[Epoch 1] Step 200 | BCE Loss: 0.025559\n",
      "[Epoch 1] Step 210 | BCE Loss: 0.012296\n",
      "[Epoch 1] Step 220 | BCE Loss: 0.026193\n",
      "[Epoch 1] Step 230 | BCE Loss: 0.016594\n",
      "[Epoch 1] Step 240 | BCE Loss: 0.022145\n",
      "[Epoch 1] Step 250 | BCE Loss: 0.053168\n",
      "[Epoch 1] Step 260 | BCE Loss: 0.017805\n",
      "[Epoch 1] Step 270 | BCE Loss: 0.014855\n",
      "[Epoch 1] Step 280 | BCE Loss: 0.023808\n",
      "[Epoch 1] Step 290 | BCE Loss: 0.022431\n",
      "[Epoch 1] Step 300 | BCE Loss: 0.013853\n",
      "[Epoch 1] Step 310 | BCE Loss: 0.017908\n",
      "[Epoch 1] Step 320 | BCE Loss: 0.016957\n",
      "[Epoch 1] Step 330 | BCE Loss: 0.022332\n",
      "[Epoch 1] Step 340 | BCE Loss: 0.022943\n",
      "[Epoch 1] Step 350 | BCE Loss: 0.020548\n",
      "[Epoch 1] Step 360 | BCE Loss: 0.026653\n",
      "[Epoch 1] Step 370 | BCE Loss: 0.016955\n",
      "[Epoch 1] Step 380 | BCE Loss: 0.016567\n",
      "[Epoch 1] Step 390 | BCE Loss: 0.019390\n",
      "[Epoch 1] Step 400 | BCE Loss: 0.023528\n",
      "[Epoch 1] Step 410 | BCE Loss: 0.024446\n",
      "[Epoch 1] Step 420 | BCE Loss: 0.016131\n",
      "[Epoch 1] Step 430 | BCE Loss: 0.021347\n",
      "[Epoch 1] Step 440 | BCE Loss: 0.013816\n",
      "[Epoch 1] Step 450 | BCE Loss: 0.017154\n",
      "[Epoch 1] Step 460 | BCE Loss: 0.031940\n",
      "[Epoch 1] Step 470 | BCE Loss: 0.020449\n",
      "[Epoch 1] Step 480 | BCE Loss: 0.028277\n",
      "[Epoch 1] Step 490 | BCE Loss: 0.020649\n",
      "[Epoch 1] Step 500 | BCE Loss: 0.051264\n",
      "[Epoch 1] Step 510 | BCE Loss: 0.013980\n",
      "[Epoch 1] Step 520 | BCE Loss: 0.024964\n",
      "[Epoch 1] Step 530 | BCE Loss: 0.032403\n",
      "[Epoch 1] Step 540 | BCE Loss: 0.029035\n",
      "[Epoch 1] Step 550 | BCE Loss: 0.031327\n",
      "[Epoch 1] Step 560 | BCE Loss: 0.020939\n",
      "[Epoch 1] Step 570 | BCE Loss: 0.017449\n",
      "[Epoch 1] Step 580 | BCE Loss: 0.020221\n",
      "[Epoch 1] Step 590 | BCE Loss: 0.016668\n",
      "[Epoch 1] Step 600 | BCE Loss: 0.019422\n",
      "[Epoch 1] Step 610 | BCE Loss: 0.017128\n",
      "[Epoch 1] Step 620 | BCE Loss: 0.016363\n",
      "[Epoch 1] Step 630 | BCE Loss: 0.027258\n",
      "[Epoch 1] Step 640 | BCE Loss: 0.025124\n",
      "[Epoch 1] Step 650 | BCE Loss: 0.020906\n",
      "[Epoch 1] Step 660 | BCE Loss: 0.022643\n",
      "[Epoch 1] Step 670 | BCE Loss: 0.022907\n",
      "[Epoch 1] Step 680 | BCE Loss: 0.020809\n",
      "[Epoch 1] Step 690 | BCE Loss: 0.023427\n",
      "[Epoch 1] Step 700 | BCE Loss: 0.020003\n",
      "[Epoch 1] Step 710 | BCE Loss: 0.013077\n",
      "[Epoch 1] Step 720 | BCE Loss: 0.022815\n",
      "[Epoch 1] Step 730 | BCE Loss: 0.030108\n",
      "[Epoch 1] Step 740 | BCE Loss: 0.015836\n",
      "[Epoch 1] Step 750 | BCE Loss: 0.015665\n",
      "[Epoch 1] Step 760 | BCE Loss: 0.020335\n",
      "[Epoch 1] Step 770 | BCE Loss: 0.020349\n",
      "[Epoch 1] Step 780 | BCE Loss: 0.024077\n",
      "[Epoch 1] Step 790 | BCE Loss: 0.019268\n",
      "[Epoch 1] Step 800 | BCE Loss: 0.012908\n",
      "[Epoch 1] Step 810 | BCE Loss: 0.014509\n",
      "[Epoch 1] Step 820 | BCE Loss: 0.018145\n",
      "[Epoch 1] Step 830 | BCE Loss: 0.017533\n",
      "[Epoch 1] Step 840 | BCE Loss: 0.027408\n",
      "[Epoch 1] Step 850 | BCE Loss: 0.014752\n",
      "[Epoch 1] Step 860 | BCE Loss: 0.021668\n",
      "[Epoch 1] Step 870 | BCE Loss: 0.017346\n",
      "[Epoch 1] Step 880 | BCE Loss: 0.017678\n",
      "[Epoch 1] Step 890 | BCE Loss: 0.030237\n",
      "[Epoch 1] Step 900 | BCE Loss: 0.024410\n",
      "[Epoch 1] Step 910 | BCE Loss: 0.024194\n",
      "[Epoch 1] Step 920 | BCE Loss: 0.019398\n",
      "[Epoch 1] Step 930 | BCE Loss: 0.016513\n",
      "[Epoch 1] Step 940 | BCE Loss: 0.013456\n",
      "[Epoch 1] Step 950 | BCE Loss: 0.026525\n",
      "[Epoch 1] Step 960 | BCE Loss: 0.088323\n",
      "[Epoch 1] Step 970 | BCE Loss: 0.015665\n",
      "[Epoch 1] Step 980 | BCE Loss: 0.020553\n",
      "[Epoch 1] Step 990 | BCE Loss: 0.017732\n",
      "[Epoch 1] Step 1000 | BCE Loss: 0.015514\n",
      "[Epoch 1] Step 1010 | BCE Loss: 0.016720\n",
      "[Epoch 1] Step 1020 | BCE Loss: 0.016766\n",
      "[Epoch 1] Step 1030 | BCE Loss: 0.037258\n",
      "[Epoch 1] Step 1040 | BCE Loss: 0.019294\n",
      "[Epoch 1] Step 1050 | BCE Loss: 0.018167\n",
      "[Epoch 1] Step 1060 | BCE Loss: 0.054897\n",
      "[Epoch 1] Step 1070 | BCE Loss: 0.052345\n",
      "[Epoch 1] Step 1080 | BCE Loss: 0.019343\n",
      "[Epoch 1] Step 1090 | BCE Loss: 0.017889\n",
      "[Epoch 1] Step 1100 | BCE Loss: 0.015965\n",
      "[Epoch 1] Step 1110 | BCE Loss: 0.013998\n",
      "[Epoch 1] Step 1120 | BCE Loss: 0.027653\n",
      "[Epoch 1] Step 1130 | BCE Loss: 0.025235\n",
      "[Epoch 1] Step 1140 | BCE Loss: 0.018964\n",
      "[Epoch 1] Step 1150 | BCE Loss: 0.016763\n",
      "[Epoch 1] Step 1160 | BCE Loss: 0.020391\n",
      "[Epoch 1] Step 1170 | BCE Loss: 0.023608\n",
      "[Epoch 1] Step 1180 | BCE Loss: 0.014476\n",
      "[Epoch 1] Step 1190 | BCE Loss: 0.015367\n",
      "[Epoch 1] Step 1200 | BCE Loss: 0.016034\n",
      "[Epoch 1] Step 1210 | BCE Loss: 0.014012\n",
      "[Epoch 1] Step 1220 | BCE Loss: 0.013344\n",
      "[Epoch 1] Step 1230 | BCE Loss: 0.022464\n",
      "[Epoch 1] Step 1240 | BCE Loss: 0.024778\n",
      "[Epoch 1] Step 1250 | BCE Loss: 0.016613\n",
      "[Epoch 1] Step 1260 | BCE Loss: 0.019909\n",
      "[Epoch 1] Step 1270 | BCE Loss: 0.035490\n",
      "[Epoch 1] Step 1280 | BCE Loss: 0.057692\n",
      "[Epoch 1] Step 1290 | BCE Loss: 0.017039\n",
      "[Epoch 1] Step 1300 | BCE Loss: 0.034391\n",
      "[Epoch 1] Step 1310 | BCE Loss: 0.017774\n",
      "[Epoch 1] Step 1320 | BCE Loss: 0.032088\n",
      "[Epoch 1] Step 1330 | BCE Loss: 0.016560\n",
      "[Epoch 1] Step 1340 | BCE Loss: 0.018394\n",
      "[Epoch 1] Step 1350 | BCE Loss: 0.016734\n",
      "[Epoch 1] Step 1360 | BCE Loss: 0.023227\n",
      "[Epoch 1] Step 1370 | BCE Loss: 0.019049\n",
      "[Epoch 1] Step 1380 | BCE Loss: 0.057840\n",
      "[Epoch 1] Step 1390 | BCE Loss: 0.014140\n",
      "[Epoch 1] Step 1400 | BCE Loss: 0.021115\n",
      "[Epoch 1] Step 1410 | BCE Loss: 0.019643\n",
      "[Epoch 1] Step 1420 | BCE Loss: 0.025556\n",
      "[Epoch 1] Step 1430 | BCE Loss: 0.020572\n",
      "[Epoch 1] Step 1440 | BCE Loss: 0.013943\n",
      "[Epoch 1] Step 1450 | BCE Loss: 0.016080\n",
      "[Epoch 1] Step 1460 | BCE Loss: 0.014794\n",
      "[Epoch 1] Step 1470 | BCE Loss: 0.018958\n",
      "[Epoch 1] Step 1480 | BCE Loss: 0.020934\n",
      "[Epoch 1] Step 1490 | BCE Loss: 0.014559\n",
      "[Epoch 1] Step 1500 | BCE Loss: 0.015844\n",
      "[Epoch 1] Step 1510 | BCE Loss: 0.014926\n",
      "[Epoch 1] Step 1520 | BCE Loss: 0.038024\n",
      "[Epoch 1] Step 1530 | BCE Loss: 0.020351\n",
      "[Epoch 1] Step 1540 | BCE Loss: 0.037164\n",
      "[Epoch 1] Step 1550 | BCE Loss: 0.016422\n",
      "[Epoch 1] Step 1560 | BCE Loss: 0.016498\n",
      "[Epoch 1] Step 1570 | BCE Loss: 0.019676\n",
      "[Epoch 1] Step 1580 | BCE Loss: 0.020655\n",
      "[Epoch 1] Step 1590 | BCE Loss: 0.021392\n",
      "[Epoch 1] Step 1600 | BCE Loss: 0.015481\n",
      "[Epoch 1] Step 1610 | BCE Loss: 0.019213\n",
      "[Epoch 1] Step 1620 | BCE Loss: 0.013867\n",
      "[Epoch 1] Step 1630 | BCE Loss: 0.014242\n",
      "[Epoch 1] Step 1640 | BCE Loss: 0.021067\n",
      "[Epoch 1] Step 1650 | BCE Loss: 0.021724\n",
      "[Epoch 1] Step 1660 | BCE Loss: 0.014329\n",
      "[Epoch 1] Step 1670 | BCE Loss: 0.015624\n",
      "[Epoch 1] Step 1680 | BCE Loss: 0.016845\n",
      "[Epoch 1] Step 1690 | BCE Loss: 0.021465\n",
      "[Epoch 1] Step 1700 | BCE Loss: 0.016555\n",
      "[Epoch 1] Step 1710 | BCE Loss: 0.020238\n",
      "[Epoch 1] Step 1720 | BCE Loss: 0.011801\n",
      "[Epoch 1] Step 1730 | BCE Loss: 0.013824\n",
      "[Epoch 1] Step 1740 | BCE Loss: 0.019164\n",
      "[Epoch 1] Step 1750 | BCE Loss: 0.026490\n",
      "[Epoch 1] Step 1760 | BCE Loss: 0.021162\n",
      "[Epoch 1] Step 1770 | BCE Loss: 0.042737\n",
      "[Epoch 1] Step 1780 | BCE Loss: 0.030290\n",
      "[Epoch 1] Step 1790 | BCE Loss: 0.018705\n",
      "[Epoch 1] Step 1800 | BCE Loss: 0.015055\n",
      "[Epoch 1] Step 1810 | BCE Loss: 0.029719\n",
      "[Epoch 1] Step 1820 | BCE Loss: 0.017916\n",
      "[Epoch 1] Step 1830 | BCE Loss: 0.019510\n",
      "[Epoch 1] Step 1840 | BCE Loss: 0.020712\n",
      "[Epoch 1] Step 1850 | BCE Loss: 0.025835\n",
      "[Epoch 1] Step 1860 | BCE Loss: 0.019917\n",
      "[Epoch 1] Step 1870 | BCE Loss: 0.014960\n",
      "[Epoch 1] Step 1880 | BCE Loss: 0.015258\n",
      "[Epoch 1] Step 1890 | BCE Loss: 0.015593\n",
      "[Epoch 1] Step 1900 | BCE Loss: 0.013609\n",
      "[Epoch 1] Step 1910 | BCE Loss: 0.020073\n",
      "[Epoch 1] Step 1920 | BCE Loss: 0.018643\n",
      "[Epoch 1] Step 1930 | BCE Loss: 0.016283\n",
      "[Epoch 1] Step 1940 | BCE Loss: 0.019720\n",
      "[Epoch 1] Step 1950 | BCE Loss: 0.014527\n",
      "[Epoch 1] Step 1960 | BCE Loss: 0.014253\n",
      "[Epoch 1] Step 1970 | BCE Loss: 0.016795\n",
      "[Epoch 1] Step 1980 | BCE Loss: 0.016610\n",
      "[Epoch 1] Step 1990 | BCE Loss: 0.012734\n",
      "[Epoch 1] Step 2000 | BCE Loss: 0.020062\n",
      "[Epoch 1] Step 2010 | BCE Loss: 0.021407\n",
      "[Epoch 1] Step 2020 | BCE Loss: 0.018320\n",
      "[Epoch 1] Step 2030 | BCE Loss: 0.020783\n",
      "[Epoch 1] Step 2040 | BCE Loss: 0.015729\n",
      "[Epoch 1] Step 2050 | BCE Loss: 0.056129\n",
      "[Epoch 1] Step 2060 | BCE Loss: 0.056168\n",
      "[Epoch 1] Step 2070 | BCE Loss: 0.019094\n",
      "[Epoch 1] Step 2080 | BCE Loss: 0.015480\n",
      "[Epoch 1] Step 2090 | BCE Loss: 0.016537\n",
      "[Epoch 1] Step 2100 | BCE Loss: 0.022988\n",
      "[Epoch 1] Step 2110 | BCE Loss: 0.013153\n",
      "[Epoch 1] Step 2120 | BCE Loss: 0.018834\n",
      "[Epoch 1] Step 2130 | BCE Loss: 0.019286\n",
      "[Epoch 1] Step 2140 | BCE Loss: 0.017753\n",
      "[Epoch 1] Step 2150 | BCE Loss: 0.019793\n",
      "[Epoch 1] Step 2160 | BCE Loss: 0.025344\n",
      "[Epoch 1] Step 2170 | BCE Loss: 0.017544\n",
      "[Epoch 1] Step 2180 | BCE Loss: 0.018079\n",
      "[Epoch 1] Step 2190 | BCE Loss: 0.019914\n",
      "[Epoch 1] Step 2200 | BCE Loss: 0.021426\n",
      "[Epoch 1] Step 2210 | BCE Loss: 0.024681\n",
      "[Epoch 1] Step 2220 | BCE Loss: 0.026086\n",
      "[Epoch 1] Step 2230 | BCE Loss: 0.015278\n",
      "[Epoch 1] Step 2240 | BCE Loss: 0.021309\n",
      "[Epoch 1] Step 2250 | BCE Loss: 0.017963\n",
      "[Epoch 1] Step 2260 | BCE Loss: 0.018365\n",
      "[Epoch 1] Step 2270 | BCE Loss: 0.021912\n",
      "[Epoch 1] Step 2280 | BCE Loss: 0.013863\n",
      "[Epoch 1] Step 2290 | BCE Loss: 0.032087\n",
      "[Epoch 1] Step 2300 | BCE Loss: 0.014776\n",
      "[Epoch 1] Step 2310 | BCE Loss: 0.014634\n",
      "[Epoch 1] Step 2320 | BCE Loss: 0.014019\n",
      "[Epoch 1] Step 2330 | BCE Loss: 0.017374\n",
      "[Epoch 1] Step 2340 | BCE Loss: 0.015790\n",
      "[Epoch 1] Step 2350 | BCE Loss: 0.018367\n",
      "[Epoch 1] Step 2360 | BCE Loss: 0.026598\n",
      "[Epoch 1] Step 2370 | BCE Loss: 0.037958\n",
      "[Epoch 1] Step 2380 | BCE Loss: 0.018369\n",
      "[Epoch 1] Step 2390 | BCE Loss: 0.019769\n",
      "[Epoch 1] Step 2400 | BCE Loss: 0.012391\n",
      "[Epoch 1] Step 2410 | BCE Loss: 0.014875\n",
      "[Epoch 1] Step 2420 | BCE Loss: 0.012776\n",
      "[Epoch 1] Step 2430 | BCE Loss: 0.031184\n",
      "[Epoch 1] Step 2440 | BCE Loss: 0.022512\n",
      "[Epoch 1] Step 2450 | BCE Loss: 0.025238\n",
      "[Epoch 1] Step 2460 | BCE Loss: 0.019557\n",
      "[Epoch 1] Step 2470 | BCE Loss: 0.055329\n",
      "[Epoch 1] Step 2480 | BCE Loss: 0.023667\n",
      "[Epoch 1] Step 2490 | BCE Loss: 0.030837\n",
      "[Epoch 1] Step 2500 | BCE Loss: 0.013924\n",
      "[Epoch 1] Step 2510 | BCE Loss: 0.041609\n",
      "[Epoch 1] Step 2520 | BCE Loss: 0.015188\n",
      "[Epoch 1] Step 2530 | BCE Loss: 0.015228\n",
      "[Epoch 1] Step 2540 | BCE Loss: 0.016656\n",
      "[Epoch 1] Step 2550 | BCE Loss: 0.019240\n",
      "[Epoch 1] Step 2560 | BCE Loss: 0.019960\n",
      "[Epoch 1] Step 2570 | BCE Loss: 0.017915\n",
      "[Epoch 1] Step 2580 | BCE Loss: 0.011759\n",
      "[Epoch 1] Step 2590 | BCE Loss: 0.014156\n",
      "[Epoch 1] Step 2600 | BCE Loss: 0.012545\n",
      "[Epoch 1] Step 2610 | BCE Loss: 0.015973\n",
      "[Epoch 1] Step 2620 | BCE Loss: 0.020501\n",
      "[Epoch 1] Step 2630 | BCE Loss: 0.022139\n",
      "[Epoch 1] Step 2640 | BCE Loss: 0.014787\n",
      "[Epoch 1] Step 2650 | BCE Loss: 0.012430\n",
      "[Epoch 1] Step 2660 | BCE Loss: 0.012683\n",
      "[Epoch 1] Step 2670 | BCE Loss: 0.024095\n",
      "[Epoch 1] Step 2680 | BCE Loss: 0.014794\n",
      "[Epoch 1] Step 2690 | BCE Loss: 0.018772\n",
      "[Epoch 1] Step 2700 | BCE Loss: 0.013972\n",
      "[Epoch 1] Step 2710 | BCE Loss: 0.010784\n",
      "[Epoch 1] Step 2720 | BCE Loss: 0.013721\n",
      "[Epoch 1] Step 2730 | BCE Loss: 0.016747\n",
      "[Epoch 1] Step 2740 | BCE Loss: 0.014022\n",
      "[Epoch 1] Step 2750 | BCE Loss: 0.017134\n",
      "[Epoch 1] Step 2760 | BCE Loss: 0.023536\n",
      "[Epoch 1] Step 2770 | BCE Loss: 0.038889\n",
      "[Epoch 1] Step 2780 | BCE Loss: 0.025294\n",
      "[Epoch 1] Step 2790 | BCE Loss: 0.014756\n",
      "[Epoch 1] Step 2800 | BCE Loss: 0.015925\n",
      "[Epoch 1] Step 2810 | BCE Loss: 0.017457\n",
      "[Epoch 1] Step 2820 | BCE Loss: 0.017707\n",
      "[Epoch 1] Step 2830 | BCE Loss: 0.015033\n",
      "[Epoch 1] Step 2840 | BCE Loss: 0.022806\n",
      "[Epoch 1] Step 2850 | BCE Loss: 0.039207\n",
      "[Epoch 1] Step 2860 | BCE Loss: 0.016726\n",
      "[Epoch 1] Step 2870 | BCE Loss: 0.017731\n",
      "[Epoch 1] Step 2880 | BCE Loss: 0.018426\n",
      "[Epoch 1] Step 2890 | BCE Loss: 0.016959\n",
      "[Epoch 1] Step 2900 | BCE Loss: 0.023043\n",
      "[Epoch 1] Step 2910 | BCE Loss: 0.014413\n",
      "[Epoch 1] Step 2920 | BCE Loss: 0.016930\n",
      "[Epoch 1] Step 2930 | BCE Loss: 0.013864\n",
      "[Epoch 1] Step 2940 | BCE Loss: 0.016562\n",
      "[Epoch 1] Step 2950 | BCE Loss: 0.012902\n",
      "[Epoch 1] Step 2960 | BCE Loss: 0.016969\n",
      "[Epoch 1] Step 2970 | BCE Loss: 0.019716\n",
      "[Epoch 1] Step 2980 | BCE Loss: 0.012925\n",
      "[Epoch 1] Step 2990 | BCE Loss: 0.019496\n",
      "[Epoch 1] Step 3000 | BCE Loss: 0.014008\n",
      "[Epoch 1] Step 3010 | BCE Loss: 0.021305\n",
      "[Epoch 1] Step 3020 | BCE Loss: 0.024462\n",
      "[Epoch 1] Step 3030 | BCE Loss: 0.020522\n",
      "[Epoch 1] Step 3040 | BCE Loss: 0.014345\n",
      "[Epoch 1] Step 3050 | BCE Loss: 0.016892\n",
      "[Epoch 1] Step 3060 | BCE Loss: 0.014295\n",
      "[Epoch 1] Step 3070 | BCE Loss: 0.017647\n",
      "[Epoch 1] Step 3080 | BCE Loss: 0.012993\n",
      "[Epoch 1] Step 3090 | BCE Loss: 0.019630\n",
      "[Epoch 1] Step 3100 | BCE Loss: 0.029593\n",
      "[Epoch 1] Step 3110 | BCE Loss: 0.019889\n",
      "[Epoch 1] Step 3120 | BCE Loss: 0.015989\n",
      "[Epoch 1] Step 3130 | BCE Loss: 0.026619\n",
      "[Epoch 1] Step 3140 | BCE Loss: 0.015756\n",
      "[Epoch 1] Step 3150 | BCE Loss: 0.018377\n",
      "[Epoch 1] Step 3160 | BCE Loss: 0.013952\n",
      "[Epoch 1] Step 3170 | BCE Loss: 0.028279\n",
      "[Epoch 1] Step 3180 | BCE Loss: 0.018721\n",
      "[Epoch 1] Step 3190 | BCE Loss: 0.017358\n",
      "[Epoch 1] Step 3200 | BCE Loss: 0.016710\n",
      "[Epoch 1] Step 3210 | BCE Loss: 0.036818\n",
      "[Epoch 1] Step 3220 | BCE Loss: 0.017134\n",
      "[Epoch 1] Step 3230 | BCE Loss: 0.016316\n",
      "[Epoch 1] Step 3240 | BCE Loss: 0.016819\n",
      "[Epoch 1] Step 3250 | BCE Loss: 0.017771\n",
      "[Epoch 1] Step 3260 | BCE Loss: 0.021097\n",
      "[Epoch 1] Step 3270 | BCE Loss: 0.021305\n",
      "[Epoch 1] Step 3280 | BCE Loss: 0.015766\n",
      "[Epoch 1] Step 3290 | BCE Loss: 0.046597\n",
      "[Epoch 1] Step 3300 | BCE Loss: 0.018290\n",
      "[Epoch 1] Step 3310 | BCE Loss: 0.023876\n",
      "[Epoch 1] Step 3320 | BCE Loss: 0.026343\n",
      "[Epoch 1] Step 3330 | BCE Loss: 0.020085\n",
      "[Epoch 1] Step 3340 | BCE Loss: 0.019276\n",
      "[Epoch 1] Step 3350 | BCE Loss: 0.019442\n",
      "[Epoch 1] Step 3360 | BCE Loss: 0.015855\n",
      "[Epoch 1] Step 3370 | BCE Loss: 0.011825\n",
      "[Epoch 1] Step 3380 | BCE Loss: 0.021102\n",
      "[Epoch 1] Step 3390 | BCE Loss: 0.019924\n",
      "[Epoch 1] Step 3400 | BCE Loss: 0.019585\n",
      "[Epoch 1] Step 3410 | BCE Loss: 0.019746\n",
      "[Epoch 1] Step 3420 | BCE Loss: 0.016180\n",
      "[Epoch 1] Step 3430 | BCE Loss: 0.016902\n",
      "[Epoch 1] Step 3440 | BCE Loss: 0.015040\n",
      "[Epoch 1] Step 3450 | BCE Loss: 0.015793\n",
      "[Epoch 1] Step 3460 | BCE Loss: 0.017620\n",
      "[Epoch 1] Step 3470 | BCE Loss: 0.016492\n",
      "[Epoch 1] Step 3480 | BCE Loss: 0.013503\n",
      "[Epoch 1] Step 3490 | BCE Loss: 0.018868\n",
      "[Epoch 1] Step 3500 | BCE Loss: 0.016199\n",
      "[Epoch 1] Step 3510 | BCE Loss: 0.014582\n",
      "[Epoch 1] Step 3520 | BCE Loss: 0.012058\n",
      "[Epoch 1] Step 3530 | BCE Loss: 0.041736\n",
      "[Epoch 1] Step 3540 | BCE Loss: 0.014744\n",
      "[Epoch 1] Step 3550 | BCE Loss: 0.013580\n",
      "[Epoch 1] Step 3560 | BCE Loss: 0.015180\n",
      "[Epoch 1] Step 3570 | BCE Loss: 0.020890\n",
      "[Epoch 1] Step 3580 | BCE Loss: 0.016733\n",
      "[Epoch 1] Step 3590 | BCE Loss: 0.018228\n",
      "[Epoch 1] Step 3600 | BCE Loss: 0.013779\n",
      "[Epoch 1] Step 3610 | BCE Loss: 0.013356\n",
      "[Epoch 1] Step 3620 | BCE Loss: 0.017353\n",
      "[Epoch 1] Step 3630 | BCE Loss: 0.020690\n",
      "[Epoch 1] Step 3640 | BCE Loss: 0.017510\n",
      "[Epoch 1] Step 3650 | BCE Loss: 0.021664\n",
      "[Epoch 1] Step 3660 | BCE Loss: 0.013033\n",
      "[Epoch 1] Step 3670 | BCE Loss: 0.015324\n",
      "[Epoch 1] Step 3680 | BCE Loss: 0.017296\n",
      "[Epoch 1] Step 3690 | BCE Loss: 0.016520\n",
      "[Epoch 1] Step 3700 | BCE Loss: 0.024872\n",
      "[Epoch 1] Step 3710 | BCE Loss: 0.024720\n",
      "[Epoch 1] Step 3720 | BCE Loss: 0.023258\n",
      "[Epoch 1] Step 3730 | BCE Loss: 0.023670\n",
      "[Epoch 1] Step 3740 | BCE Loss: 0.014654\n",
      "[Epoch 1] Step 3750 | BCE Loss: 0.020896\n",
      "[Epoch 1] Step 3760 | BCE Loss: 0.019625\n",
      "[Epoch 1] Step 3770 | BCE Loss: 0.018034\n",
      "[Epoch 1] Step 3780 | BCE Loss: 0.019258\n",
      "[Epoch 1] Step 3790 | BCE Loss: 0.018554\n",
      "[Epoch 1] Step 3800 | BCE Loss: 0.015148\n",
      "[Epoch 1] Step 3810 | BCE Loss: 0.019059\n",
      "[Epoch 1] Step 3820 | BCE Loss: 0.017855\n",
      "[Epoch 1] Step 3830 | BCE Loss: 0.016609\n",
      "[Epoch 1] Step 3840 | BCE Loss: 0.013808\n",
      "[Epoch 1] Step 3850 | BCE Loss: 0.012915\n",
      "[Epoch 1] Step 3860 | BCE Loss: 0.039550\n",
      "[Epoch 1] Step 3870 | BCE Loss: 0.014518\n",
      "[Epoch 1] Step 3880 | BCE Loss: 0.032714\n",
      "[Epoch 1] Step 3890 | BCE Loss: 0.015009\n",
      "[Epoch 1] Step 3900 | BCE Loss: 0.016487\n",
      "[Epoch 1] Step 3910 | BCE Loss: 0.009848\n",
      "[Epoch 1] Step 3920 | BCE Loss: 0.013001\n",
      "[Epoch 1] Step 3930 | BCE Loss: 0.043820\n",
      "[Epoch 1] Step 3940 | BCE Loss: 0.017381\n",
      "[Epoch 1] Step 3950 | BCE Loss: 0.019173\n",
      "[Epoch 1] Step 3960 | BCE Loss: 0.017547\n",
      "[Epoch 1] Step 3970 | BCE Loss: 0.016087\n",
      "[Epoch 1] Step 3980 | BCE Loss: 0.014834\n",
      "[Epoch 1] Step 3990 | BCE Loss: 0.020446\n",
      "[Epoch 1] Step 4000 | BCE Loss: 0.018567\n",
      "[Epoch 1] Step 4010 | BCE Loss: 0.016026\n",
      "[Epoch 1] Step 4020 | BCE Loss: 0.016657\n",
      "[Epoch 1] Step 4030 | BCE Loss: 0.018440\n",
      "[Epoch 1] Step 4040 | BCE Loss: 0.013860\n",
      "[Epoch 1] Step 4050 | BCE Loss: 0.019008\n",
      "[Epoch 1] Step 4060 | BCE Loss: 0.031553\n",
      "[Epoch 1] Step 4070 | BCE Loss: 0.017645\n",
      "[Epoch 1] Step 4080 | BCE Loss: 0.028231\n",
      "[Epoch 1] Step 4090 | BCE Loss: 0.020640\n",
      "[Epoch 1] Step 4100 | BCE Loss: 0.016038\n",
      "[Epoch 1] Step 4110 | BCE Loss: 0.014819\n",
      "[Epoch 1] Step 4120 | BCE Loss: 0.049562\n",
      "[Epoch 1] Step 4130 | BCE Loss: 0.017742\n",
      "[Epoch 1] Step 4140 | BCE Loss: 0.020936\n",
      "[Epoch 1] Step 4150 | BCE Loss: 0.015971\n",
      "[Epoch 1] Step 4160 | BCE Loss: 0.015748\n",
      "[Epoch 1] Step 4170 | BCE Loss: 0.016861\n",
      "[Epoch 1] Step 4180 | BCE Loss: 0.013041\n",
      "[Epoch 1] Step 4190 | BCE Loss: 0.013981\n",
      "[Epoch 1] Step 4200 | BCE Loss: 0.016221\n",
      "[Epoch 1] Step 4210 | BCE Loss: 0.014092\n",
      "[Epoch 1] Step 4220 | BCE Loss: 0.018321\n",
      "[Epoch 1] Step 4230 | BCE Loss: 0.022058\n",
      "[Epoch 1] Step 4240 | BCE Loss: 0.019528\n",
      "[Epoch 1] Step 4250 | BCE Loss: 0.013202\n",
      "[Epoch 1] Step 4260 | BCE Loss: 0.019928\n",
      "[Epoch 1] Step 4270 | BCE Loss: 0.018610\n",
      "[Epoch 1] Step 4280 | BCE Loss: 0.019923\n",
      "[Epoch 1] Step 4290 | BCE Loss: 0.016740\n",
      "[Epoch 1] Step 4300 | BCE Loss: 0.020819\n",
      "[Epoch 1] Step 4310 | BCE Loss: 0.011520\n",
      "[Epoch 1] Step 4320 | BCE Loss: 0.014612\n",
      "[Epoch 1] Step 4330 | BCE Loss: 0.017252\n",
      "[Epoch 1] Step 4340 | BCE Loss: 0.008922\n",
      "[Epoch 1] Step 4350 | BCE Loss: 0.013527\n",
      "[Epoch 1] Step 4360 | BCE Loss: 0.017846\n",
      "[Epoch 1] Step 4370 | BCE Loss: 0.015035\n",
      "[Epoch 1] Step 4380 | BCE Loss: 0.059575\n",
      "[Epoch 1] Step 4390 | BCE Loss: 0.015152\n",
      "[Epoch 1] Step 4400 | BCE Loss: 0.017081\n",
      "[Epoch 1] Step 4410 | BCE Loss: 0.066739\n",
      "[Epoch 1] Step 4420 | BCE Loss: 0.015545\n",
      "[Epoch 1] Step 4430 | BCE Loss: 0.014724\n",
      "[Epoch 1] Step 4440 | BCE Loss: 0.015763\n",
      "[Epoch 1] Step 4450 | BCE Loss: 0.012899\n",
      "[Epoch 1] Step 4460 | BCE Loss: 0.046418\n",
      "[Epoch 1] Step 4470 | BCE Loss: 0.013955\n",
      "[Epoch 1] Step 4480 | BCE Loss: 0.018853\n",
      "[Epoch 1] Step 4490 | BCE Loss: 0.021568\n",
      "[Epoch 1] Step 4500 | BCE Loss: 0.015281\n",
      "[Epoch 1] Step 4510 | BCE Loss: 0.010296\n",
      "[Epoch 1] Step 4520 | BCE Loss: 0.013618\n",
      "[Epoch 1] Step 4530 | BCE Loss: 0.017944\n",
      "[Epoch 1] Step 4540 | BCE Loss: 0.021825\n",
      "[Epoch 1] Step 4550 | BCE Loss: 0.019470\n",
      "[Epoch 1] Step 4560 | BCE Loss: 0.015003\n",
      "[Epoch 1] Step 4570 | BCE Loss: 0.015994\n",
      "[Epoch 1] Step 4580 | BCE Loss: 0.026573\n",
      "[Epoch 1] Step 4590 | BCE Loss: 0.016234\n",
      "[Epoch 1] Step 4600 | BCE Loss: 0.016067\n",
      "[Epoch 1] Step 4610 | BCE Loss: 0.012306\n",
      "[Epoch 1] Step 4620 | BCE Loss: 0.013059\n",
      "[Epoch 1] Step 4630 | BCE Loss: 0.021531\n",
      "[Epoch 1] Step 4640 | BCE Loss: 0.013802\n",
      "[Epoch 1] Step 4650 | BCE Loss: 0.016625\n",
      "[Epoch 1] Step 4660 | BCE Loss: 0.015744\n",
      "[Epoch 1] Step 4670 | BCE Loss: 0.023259\n",
      "[Epoch 1] Step 4680 | BCE Loss: 0.015228\n",
      "[Epoch 1] Step 4690 | BCE Loss: 0.053639\n",
      "[Epoch 1] Step 4700 | BCE Loss: 0.018619\n",
      "[Epoch 1] Step 4710 | BCE Loss: 0.032670\n",
      "[Epoch 1] Step 4720 | BCE Loss: 0.010357\n",
      "[Epoch 1] Step 4730 | BCE Loss: 0.019448\n",
      "[Epoch 1] Step 4740 | BCE Loss: 0.024215\n",
      "[Epoch 1] Step 4750 | BCE Loss: 0.019093\n",
      "[Epoch 1] Step 4760 | BCE Loss: 0.017074\n",
      "[Epoch 1] Step 4770 | BCE Loss: 0.019251\n",
      "[Epoch 1] Step 4780 | BCE Loss: 0.042339\n",
      "[Epoch 1] Step 4790 | BCE Loss: 0.017031\n",
      "[Epoch 1] Step 4800 | BCE Loss: 0.015364\n",
      "[Epoch 1] Step 4810 | BCE Loss: 0.024894\n",
      "[Epoch 1] Step 4820 | BCE Loss: 0.013259\n",
      "[Epoch 1] Step 4830 | BCE Loss: 0.013380\n",
      "[Epoch 1] Step 4840 | BCE Loss: 0.013550\n",
      "[Epoch 1] Step 4850 | BCE Loss: 0.015563\n",
      "[Epoch 1] Step 4860 | BCE Loss: 0.018230\n",
      "[Epoch 1] Step 4870 | BCE Loss: 0.011631\n",
      "[Epoch 1] Step 4880 | BCE Loss: 0.014640\n",
      "[Epoch 1] Step 4890 | BCE Loss: 0.023210\n",
      "[Epoch 1] Step 4900 | BCE Loss: 0.016218\n",
      "[Epoch 1] Step 4910 | BCE Loss: 0.021393\n",
      "[Epoch 1] Step 4920 | BCE Loss: 0.012257\n",
      "[Epoch 1] Step 4930 | BCE Loss: 0.017835\n",
      "[Epoch 1] Step 4940 | BCE Loss: 0.082636\n",
      "[Epoch 1] Step 4950 | BCE Loss: 0.013161\n",
      "[Epoch 1] Step 4960 | BCE Loss: 0.016643\n",
      "[Epoch 1] Step 4970 | BCE Loss: 0.015821\n",
      "[Epoch 1] Step 4980 | BCE Loss: 0.020104\n",
      "[Epoch 1] Step 4990 | BCE Loss: 0.016284\n",
      "[Epoch 1] Step 5000 | BCE Loss: 0.010271\n",
      "[Epoch 1] Step 5010 | BCE Loss: 0.017145\n",
      "[Epoch 1] Step 5020 | BCE Loss: 0.033325\n",
      "[Epoch 1] Step 5030 | BCE Loss: 0.022881\n",
      "[Epoch 1] Step 5040 | BCE Loss: 0.014877\n",
      "[Epoch 1] Step 5050 | BCE Loss: 0.016455\n",
      "[Epoch 1] Step 5060 | BCE Loss: 0.017588\n",
      "[Epoch 1] Step 5070 | BCE Loss: 0.015424\n",
      "[Epoch 1] Step 5080 | BCE Loss: 0.013803\n",
      "[Epoch 1] Step 5090 | BCE Loss: 0.027680\n",
      "[Epoch 1] Step 5100 | BCE Loss: 0.014555\n",
      "[Epoch 1] Step 5110 | BCE Loss: 0.014426\n",
      "[Epoch 1] Step 5120 | BCE Loss: 0.026111\n",
      "[Epoch 1] Step 5130 | BCE Loss: 0.016880\n",
      "[Epoch 1] Step 5140 | BCE Loss: 0.019098\n",
      "[Epoch 1] Step 5150 | BCE Loss: 0.017747\n",
      "[Epoch 1] Step 5160 | BCE Loss: 0.012120\n",
      "[Epoch 1] Step 5170 | BCE Loss: 0.013565\n",
      "[Epoch 1] Step 5180 | BCE Loss: 0.015309\n",
      "[Epoch 1] Step 5190 | BCE Loss: 0.013328\n",
      "[Epoch 1] Step 5200 | BCE Loss: 0.016081\n",
      "[Epoch 1] Step 5210 | BCE Loss: 0.016181\n",
      "[Epoch 1] Step 5220 | BCE Loss: 0.013124\n",
      "[Epoch 1] Step 5230 | BCE Loss: 0.015223\n",
      "[Epoch 1] Step 5240 | BCE Loss: 0.021398\n",
      "[Epoch 1] Step 5250 | BCE Loss: 0.020301\n",
      "[Epoch 1] Step 5260 | BCE Loss: 0.030096\n",
      "[Epoch 1] Step 5270 | BCE Loss: 0.046782\n",
      "[Epoch 1] Step 5280 | BCE Loss: 0.015422\n",
      "[Epoch 1] Step 5290 | BCE Loss: 0.013772\n",
      "[Epoch 1] Step 5300 | BCE Loss: 0.021143\n",
      "[Epoch 1] Step 5310 | BCE Loss: 0.018077\n",
      "[Epoch 1] Step 5320 | BCE Loss: 0.017978\n",
      "[Epoch 1] Step 5330 | BCE Loss: 0.012136\n",
      "[Epoch 1] Step 5340 | BCE Loss: 0.014219\n",
      "[Epoch 1] Step 5350 | BCE Loss: 0.013801\n",
      "[Epoch 1] Step 5360 | BCE Loss: 0.014837\n",
      "[Epoch 1] Step 5370 | BCE Loss: 0.028537\n",
      "[Epoch 1] Step 5380 | BCE Loss: 0.033715\n",
      "[Epoch 1] Step 5390 | BCE Loss: 0.016496\n",
      "[Epoch 1] Step 5400 | BCE Loss: 0.020917\n",
      "[Epoch 1] Step 5410 | BCE Loss: 0.016792\n",
      "[Epoch 1] Step 5420 | BCE Loss: 0.015337\n",
      "[Epoch 1] Step 5430 | BCE Loss: 0.016232\n",
      "[Epoch 1] Step 5440 | BCE Loss: 0.012913\n",
      "[Epoch 1] Step 5450 | BCE Loss: 0.029138\n",
      "[Epoch 1] Step 5460 | BCE Loss: 0.013323\n",
      "[Epoch 1] Step 5470 | BCE Loss: 0.013172\n",
      "[Epoch 1] Step 5480 | BCE Loss: 0.015073\n",
      "[Epoch 1] Step 5490 | BCE Loss: 0.014619\n",
      "[Epoch 1] Step 5500 | BCE Loss: 0.010196\n",
      "[Epoch 1] Step 5510 | BCE Loss: 0.020407\n",
      "[Epoch 1] Step 5520 | BCE Loss: 0.017135\n",
      "[Epoch 1] Step 5530 | BCE Loss: 0.014012\n",
      "[Epoch 1] Step 5540 | BCE Loss: 0.015084\n",
      "[Epoch 1] Step 5550 | BCE Loss: 0.018517\n",
      "[Epoch 1] Step 5560 | BCE Loss: 0.013726\n",
      "[Epoch 1] Step 5570 | BCE Loss: 0.013568\n",
      "[Epoch 1] Step 5580 | BCE Loss: 0.016418\n",
      "[Epoch 1] Step 5590 | BCE Loss: 0.023861\n",
      "[Epoch 1] Step 5600 | BCE Loss: 0.012376\n",
      "[Epoch 1] Step 5610 | BCE Loss: 0.013362\n",
      "[Epoch 1] Step 5620 | BCE Loss: 0.016352\n",
      "[Epoch 1] Step 5630 | BCE Loss: 0.016492\n",
      "[Epoch 1] Step 5640 | BCE Loss: 0.022462\n",
      "[Epoch 1] Step 5650 | BCE Loss: 0.016946\n",
      "[Epoch 1] Step 5660 | BCE Loss: 0.013377\n",
      "[Epoch 1] Step 5670 | BCE Loss: 0.014720\n",
      "[Epoch 1] Step 5680 | BCE Loss: 0.017803\n",
      "[Epoch 1] Step 5690 | BCE Loss: 0.015978\n",
      "[Epoch 1] Step 5700 | BCE Loss: 0.014980\n",
      "[Epoch 1] Step 5710 | BCE Loss: 0.014320\n",
      "[Epoch 1] Step 5720 | BCE Loss: 0.016090\n",
      "[Epoch 1] Step 5730 | BCE Loss: 0.021700\n",
      "[Epoch 1] Step 5740 | BCE Loss: 0.027249\n",
      "[Epoch 1] Step 5750 | BCE Loss: 0.025158\n",
      "[Epoch 1] Step 5760 | BCE Loss: 0.018074\n",
      "[Epoch 1] Step 5770 | BCE Loss: 0.016757\n",
      "[Epoch 1] Step 5780 | BCE Loss: 0.016920\n",
      "[Epoch 1] Step 5790 | BCE Loss: 0.021654\n",
      "[Epoch 1] Step 5800 | BCE Loss: 0.015782\n",
      "[Epoch 1] Step 5810 | BCE Loss: 0.018501\n",
      "[Epoch 1] Step 5820 | BCE Loss: 0.015455\n",
      "\n",
      "=== Epoch 1 Selesai | Avg BCE Loss: 0.021260 ===\n",
      "[SAVE] Merging weights and saving single .pth file...\n",
      "[SAVE] Full PEFT checkpoint saved to: /kaggle/working/output/sam2_finetuned.pth\n",
      "\n",
      "[Epoch 2/5]\n",
      "[Epoch 2] Step 0 | BCE Loss: 0.022400\n",
      "[Epoch 2] Step 10 | BCE Loss: 0.018462\n",
      "[Epoch 2] Step 20 | BCE Loss: 0.013998\n",
      "[Epoch 2] Step 30 | BCE Loss: 0.018038\n",
      "[Epoch 2] Step 40 | BCE Loss: 0.018283\n",
      "[Epoch 2] Step 50 | BCE Loss: 0.013109\n",
      "[Epoch 2] Step 60 | BCE Loss: 0.019440\n",
      "[Epoch 2] Step 70 | BCE Loss: 0.016447\n",
      "[Epoch 2] Step 80 | BCE Loss: 0.025288\n",
      "[Epoch 2] Step 90 | BCE Loss: 0.015900\n",
      "[Epoch 2] Step 100 | BCE Loss: 0.017774\n",
      "[Epoch 2] Step 110 | BCE Loss: 0.015129\n",
      "[Epoch 2] Step 120 | BCE Loss: 0.015608\n",
      "[Epoch 2] Step 130 | BCE Loss: 0.045990\n",
      "[Epoch 2] Step 140 | BCE Loss: 0.017303\n",
      "[Epoch 2] Step 150 | BCE Loss: 0.019502\n",
      "[Epoch 2] Step 160 | BCE Loss: 0.031779\n",
      "[Epoch 2] Step 170 | BCE Loss: 0.013042\n",
      "[Epoch 2] Step 180 | BCE Loss: 0.015194\n",
      "[Epoch 2] Step 190 | BCE Loss: 0.013656\n",
      "[Epoch 2] Step 200 | BCE Loss: 0.022484\n",
      "[Epoch 2] Step 210 | BCE Loss: 0.014998\n",
      "[Epoch 2] Step 220 | BCE Loss: 0.017700\n",
      "[Epoch 2] Step 230 | BCE Loss: 0.016287\n",
      "[Epoch 2] Step 240 | BCE Loss: 0.037524\n",
      "[Epoch 2] Step 250 | BCE Loss: 0.016718\n",
      "[Epoch 2] Step 260 | BCE Loss: 0.021940\n",
      "[Epoch 2] Step 270 | BCE Loss: 0.012149\n",
      "[Epoch 2] Step 280 | BCE Loss: 0.015459\n",
      "[Epoch 2] Step 290 | BCE Loss: 0.015093\n",
      "[Epoch 2] Step 300 | BCE Loss: 0.019824\n",
      "[Epoch 2] Step 310 | BCE Loss: 0.012510\n",
      "[Epoch 2] Step 320 | BCE Loss: 0.013141\n",
      "[Epoch 2] Step 330 | BCE Loss: 0.018724\n",
      "[Epoch 2] Step 340 | BCE Loss: 0.022425\n",
      "[Epoch 2] Step 350 | BCE Loss: 0.019151\n",
      "[Epoch 2] Step 360 | BCE Loss: 0.021336\n",
      "[Epoch 2] Step 370 | BCE Loss: 0.016815\n",
      "[Epoch 2] Step 380 | BCE Loss: 0.014713\n",
      "[Epoch 2] Step 390 | BCE Loss: 0.018963\n",
      "[Epoch 2] Step 400 | BCE Loss: 0.025715\n",
      "[Epoch 2] Step 410 | BCE Loss: 0.021921\n",
      "[Epoch 2] Step 420 | BCE Loss: 0.014179\n",
      "[Epoch 2] Step 430 | BCE Loss: 0.025367\n",
      "[Epoch 2] Step 440 | BCE Loss: 0.012070\n",
      "[Epoch 2] Step 450 | BCE Loss: 0.017971\n",
      "[Epoch 2] Step 460 | BCE Loss: 0.020628\n",
      "[Epoch 2] Step 470 | BCE Loss: 0.024382\n",
      "[Epoch 2] Step 480 | BCE Loss: 0.017897\n",
      "[Epoch 2] Step 490 | BCE Loss: 0.012386\n",
      "[Epoch 2] Step 500 | BCE Loss: 0.014029\n",
      "[Epoch 2] Step 510 | BCE Loss: 0.019175\n",
      "[Epoch 2] Step 520 | BCE Loss: 0.015535\n",
      "[Epoch 2] Step 530 | BCE Loss: 0.016219\n",
      "[Epoch 2] Step 540 | BCE Loss: 0.016592\n",
      "[Epoch 2] Step 550 | BCE Loss: 0.029840\n",
      "[Epoch 2] Step 560 | BCE Loss: 0.014686\n",
      "[Epoch 2] Step 570 | BCE Loss: 0.013892\n",
      "[Epoch 2] Step 580 | BCE Loss: 0.017034\n",
      "[Epoch 2] Step 590 | BCE Loss: 0.027081\n",
      "[Epoch 2] Step 600 | BCE Loss: 0.016088\n",
      "[Epoch 2] Step 610 | BCE Loss: 0.018873\n",
      "[Epoch 2] Step 620 | BCE Loss: 0.014010\n",
      "[Epoch 2] Step 630 | BCE Loss: 0.020959\n",
      "[Epoch 2] Step 640 | BCE Loss: 0.061517\n",
      "[Epoch 2] Step 650 | BCE Loss: 0.024393\n",
      "[Epoch 2] Step 660 | BCE Loss: 0.019881\n",
      "[Epoch 2] Step 670 | BCE Loss: 0.016588\n",
      "[Epoch 2] Step 680 | BCE Loss: 0.013614\n",
      "[Epoch 2] Step 690 | BCE Loss: 0.013006\n",
      "[Epoch 2] Step 700 | BCE Loss: 0.014676\n",
      "[Epoch 2] Step 710 | BCE Loss: 0.010837\n",
      "[Epoch 2] Step 720 | BCE Loss: 0.014108\n",
      "[Epoch 2] Step 730 | BCE Loss: 0.023763\n",
      "[Epoch 2] Step 740 | BCE Loss: 0.013160\n",
      "[Epoch 2] Step 750 | BCE Loss: 0.012216\n",
      "[Epoch 2] Step 760 | BCE Loss: 0.012272\n",
      "[Epoch 2] Step 770 | BCE Loss: 0.024802\n",
      "[Epoch 2] Step 780 | BCE Loss: 0.012533\n",
      "[Epoch 2] Step 790 | BCE Loss: 0.025812\n",
      "[Epoch 2] Step 800 | BCE Loss: 0.014883\n",
      "[Epoch 2] Step 810 | BCE Loss: 0.015058\n",
      "[Epoch 2] Step 820 | BCE Loss: 0.017220\n",
      "[Epoch 2] Step 830 | BCE Loss: 0.020223\n",
      "[Epoch 2] Step 840 | BCE Loss: 0.019598\n",
      "[Epoch 2] Step 850 | BCE Loss: 0.025062\n",
      "[Epoch 2] Step 860 | BCE Loss: 0.013234\n",
      "[Epoch 2] Step 870 | BCE Loss: 0.011989\n",
      "[Epoch 2] Step 880 | BCE Loss: 0.012847\n",
      "[Epoch 2] Step 890 | BCE Loss: 0.015625\n",
      "[Epoch 2] Step 900 | BCE Loss: 0.018098\n",
      "[Epoch 2] Step 910 | BCE Loss: 0.015200\n",
      "[Epoch 2] Step 920 | BCE Loss: 0.015720\n",
      "[Epoch 2] Step 930 | BCE Loss: 0.019646\n",
      "[Epoch 2] Step 940 | BCE Loss: 0.028990\n",
      "[Epoch 2] Step 950 | BCE Loss: 0.014528\n",
      "[Epoch 2] Step 960 | BCE Loss: 0.017229\n",
      "[Epoch 2] Step 970 | BCE Loss: 0.022731\n",
      "[Epoch 2] Step 980 | BCE Loss: 0.014453\n",
      "[Epoch 2] Step 990 | BCE Loss: 0.016112\n",
      "[Epoch 2] Step 1000 | BCE Loss: 0.013959\n",
      "[Epoch 2] Step 1010 | BCE Loss: 0.020833\n",
      "[Epoch 2] Step 1020 | BCE Loss: 0.017605\n",
      "[Epoch 2] Step 1030 | BCE Loss: 0.012767\n",
      "[Epoch 2] Step 1040 | BCE Loss: 0.014358\n",
      "[Epoch 2] Step 1050 | BCE Loss: 0.015733\n",
      "[Epoch 2] Step 1060 | BCE Loss: 0.011731\n",
      "[Epoch 2] Step 1070 | BCE Loss: 0.017039\n",
      "[Epoch 2] Step 1080 | BCE Loss: 0.012977\n",
      "[Epoch 2] Step 1090 | BCE Loss: 0.016308\n",
      "[Epoch 2] Step 1100 | BCE Loss: 0.025864\n",
      "[Epoch 2] Step 1110 | BCE Loss: 0.041658\n",
      "[Epoch 2] Step 1120 | BCE Loss: 0.013327\n",
      "[Epoch 2] Step 1130 | BCE Loss: 0.015891\n",
      "[Epoch 2] Step 1140 | BCE Loss: 0.016737\n",
      "[Epoch 2] Step 1150 | BCE Loss: 0.021029\n",
      "[Epoch 2] Step 1160 | BCE Loss: 0.023276\n",
      "[Epoch 2] Step 1170 | BCE Loss: 0.016794\n",
      "[Epoch 2] Step 1180 | BCE Loss: 0.015409\n",
      "[Epoch 2] Step 1190 | BCE Loss: 0.016854\n",
      "[Epoch 2] Step 1200 | BCE Loss: 0.016003\n",
      "[Epoch 2] Step 1210 | BCE Loss: 0.018431\n",
      "[Epoch 2] Step 1220 | BCE Loss: 0.014409\n",
      "[Epoch 2] Step 1230 | BCE Loss: 0.025178\n",
      "[Epoch 2] Step 1240 | BCE Loss: 0.018805\n",
      "[Epoch 2] Step 1250 | BCE Loss: 0.014560\n",
      "[Epoch 2] Step 1260 | BCE Loss: 0.021218\n",
      "[Epoch 2] Step 1270 | BCE Loss: 0.031196\n",
      "[Epoch 2] Step 1280 | BCE Loss: 0.014599\n",
      "[Epoch 2] Step 1290 | BCE Loss: 0.027784\n",
      "[Epoch 2] Step 1300 | BCE Loss: 0.015027\n",
      "[Epoch 2] Step 1310 | BCE Loss: 0.015091\n",
      "[Epoch 2] Step 1320 | BCE Loss: 0.014068\n",
      "[Epoch 2] Step 1330 | BCE Loss: 0.015531\n",
      "[Epoch 2] Step 1340 | BCE Loss: 0.015464\n",
      "[Epoch 2] Step 1350 | BCE Loss: 0.026207\n",
      "[Epoch 2] Step 1360 | BCE Loss: 0.013366\n",
      "[Epoch 2] Step 1370 | BCE Loss: 0.012078\n",
      "[Epoch 2] Step 1380 | BCE Loss: 0.040337\n",
      "[Epoch 2] Step 1390 | BCE Loss: 0.019261\n",
      "[Epoch 2] Step 1400 | BCE Loss: 0.013684\n",
      "[Epoch 2] Step 1410 | BCE Loss: 0.022496\n",
      "[Epoch 2] Step 1420 | BCE Loss: 0.020350\n",
      "[Epoch 2] Step 1430 | BCE Loss: 0.013903\n",
      "[Epoch 2] Step 1440 | BCE Loss: 0.031454\n",
      "[Epoch 2] Step 1450 | BCE Loss: 0.018532\n",
      "[Epoch 2] Step 1460 | BCE Loss: 0.011843\n",
      "[Epoch 2] Step 1470 | BCE Loss: 0.019865\n",
      "[Epoch 2] Step 1480 | BCE Loss: 0.021627\n",
      "[Epoch 2] Step 1490 | BCE Loss: 0.012797\n",
      "[Epoch 2] Step 1500 | BCE Loss: 0.015863\n",
      "[Epoch 2] Step 1510 | BCE Loss: 0.017715\n",
      "[Epoch 2] Step 1520 | BCE Loss: 0.028677\n",
      "[Epoch 2] Step 1530 | BCE Loss: 0.011781\n",
      "[Epoch 2] Step 1540 | BCE Loss: 0.018081\n",
      "[Epoch 2] Step 1550 | BCE Loss: 0.016265\n",
      "[Epoch 2] Step 1560 | BCE Loss: 0.026339\n",
      "[Epoch 2] Step 1570 | BCE Loss: 0.016372\n",
      "[Epoch 2] Step 1580 | BCE Loss: 0.027743\n",
      "[Epoch 2] Step 1590 | BCE Loss: 0.012134\n",
      "[Epoch 2] Step 1600 | BCE Loss: 0.011838\n",
      "[Epoch 2] Step 1610 | BCE Loss: 0.029974\n",
      "[Epoch 2] Step 1620 | BCE Loss: 0.012791\n",
      "[Epoch 2] Step 1630 | BCE Loss: 0.036826\n",
      "[Epoch 2] Step 1640 | BCE Loss: 0.014078\n",
      "[Epoch 2] Step 1650 | BCE Loss: 0.017416\n",
      "[Epoch 2] Step 1660 | BCE Loss: 0.019250\n",
      "[Epoch 2] Step 1670 | BCE Loss: 0.011806\n",
      "[Epoch 2] Step 1680 | BCE Loss: 0.018089\n",
      "[Epoch 2] Step 1690 | BCE Loss: 0.015327\n",
      "[Epoch 2] Step 1700 | BCE Loss: 0.013980\n",
      "[Epoch 2] Step 1710 | BCE Loss: 0.015541\n",
      "[Epoch 2] Step 1720 | BCE Loss: 0.021283\n",
      "[Epoch 2] Step 1730 | BCE Loss: 0.014906\n",
      "[Epoch 2] Step 1740 | BCE Loss: 0.018279\n",
      "[Epoch 2] Step 1750 | BCE Loss: 0.015624\n",
      "[Epoch 2] Step 1760 | BCE Loss: 0.025528\n",
      "[Epoch 2] Step 1770 | BCE Loss: 0.085110\n",
      "[Epoch 2] Step 1780 | BCE Loss: 0.016323\n",
      "[Epoch 2] Step 1790 | BCE Loss: 0.019073\n",
      "[Epoch 2] Step 1800 | BCE Loss: 0.019186\n",
      "[Epoch 2] Step 1810 | BCE Loss: 0.019832\n",
      "[Epoch 2] Step 1820 | BCE Loss: 0.017146\n",
      "[Epoch 2] Step 1830 | BCE Loss: 0.038132\n",
      "[Epoch 2] Step 1840 | BCE Loss: 0.018988\n",
      "[Epoch 2] Step 1850 | BCE Loss: 0.025083\n",
      "[Epoch 2] Step 1860 | BCE Loss: 0.018520\n",
      "[Epoch 2] Step 1870 | BCE Loss: 0.012348\n",
      "[Epoch 2] Step 1880 | BCE Loss: 0.014008\n",
      "[Epoch 2] Step 1890 | BCE Loss: 0.015448\n",
      "[Epoch 2] Step 1900 | BCE Loss: 0.013972\n",
      "[Epoch 2] Step 1910 | BCE Loss: 0.018114\n",
      "[Epoch 2] Step 1920 | BCE Loss: 0.016114\n",
      "[Epoch 2] Step 1930 | BCE Loss: 0.017032\n",
      "[Epoch 2] Step 1940 | BCE Loss: 0.014248\n",
      "[Epoch 2] Step 1950 | BCE Loss: 0.013853\n",
      "[Epoch 2] Step 1960 | BCE Loss: 0.017828\n",
      "[Epoch 2] Step 1970 | BCE Loss: 0.017869\n",
      "[Epoch 2] Step 1980 | BCE Loss: 0.020671\n",
      "[Epoch 2] Step 1990 | BCE Loss: 0.014394\n",
      "[Epoch 2] Step 2000 | BCE Loss: 0.014402\n",
      "[Epoch 2] Step 2010 | BCE Loss: 0.012775\n",
      "[Epoch 2] Step 2020 | BCE Loss: 0.014263\n",
      "[Epoch 2] Step 2030 | BCE Loss: 0.022597\n",
      "[Epoch 2] Step 2040 | BCE Loss: 0.030879\n",
      "[Epoch 2] Step 2050 | BCE Loss: 0.013624\n",
      "[Epoch 2] Step 2060 | BCE Loss: 0.018226\n",
      "[Epoch 2] Step 2070 | BCE Loss: 0.013935\n",
      "[Epoch 2] Step 2080 | BCE Loss: 0.028411\n",
      "[Epoch 2] Step 2090 | BCE Loss: 0.015139\n",
      "[Epoch 2] Step 2100 | BCE Loss: 0.017589\n",
      "[Epoch 2] Step 2110 | BCE Loss: 0.024064\n",
      "[Epoch 2] Step 2120 | BCE Loss: 0.018327\n",
      "[Epoch 2] Step 2130 | BCE Loss: 0.013489\n",
      "[Epoch 2] Step 2140 | BCE Loss: 0.011120\n",
      "[Epoch 2] Step 2150 | BCE Loss: 0.022024\n",
      "[Epoch 2] Step 2160 | BCE Loss: 0.019539\n",
      "[Epoch 2] Step 2170 | BCE Loss: 0.015207\n",
      "[Epoch 2] Step 2180 | BCE Loss: 0.016905\n",
      "[Epoch 2] Step 2190 | BCE Loss: 0.016588\n",
      "[Epoch 2] Step 2200 | BCE Loss: 0.017798\n",
      "[Epoch 2] Step 2210 | BCE Loss: 0.012404\n",
      "[Epoch 2] Step 2220 | BCE Loss: 0.017816\n",
      "[Epoch 2] Step 2230 | BCE Loss: 0.016338\n",
      "[Epoch 2] Step 2240 | BCE Loss: 0.032694\n",
      "[Epoch 2] Step 2250 | BCE Loss: 0.013197\n",
      "[Epoch 2] Step 2260 | BCE Loss: 0.013651\n",
      "[Epoch 2] Step 2270 | BCE Loss: 0.013806\n",
      "[Epoch 2] Step 2280 | BCE Loss: 0.013237\n",
      "[Epoch 2] Step 2290 | BCE Loss: 0.013620\n",
      "[Epoch 2] Step 2300 | BCE Loss: 0.012415\n",
      "[Epoch 2] Step 2310 | BCE Loss: 0.016404\n",
      "[Epoch 2] Step 2320 | BCE Loss: 0.021993\n",
      "[Epoch 2] Step 2330 | BCE Loss: 0.011335\n",
      "[Epoch 2] Step 2340 | BCE Loss: 0.025738\n",
      "[Epoch 2] Step 2350 | BCE Loss: 0.020623\n",
      "[Epoch 2] Step 2360 | BCE Loss: 0.016300\n",
      "[Epoch 2] Step 2370 | BCE Loss: 0.016014\n",
      "[Epoch 2] Step 2380 | BCE Loss: 0.017748\n",
      "[Epoch 2] Step 2390 | BCE Loss: 0.014416\n",
      "[Epoch 2] Step 2400 | BCE Loss: 0.013930\n",
      "[Epoch 2] Step 2410 | BCE Loss: 0.022389\n",
      "[Epoch 2] Step 2420 | BCE Loss: 0.017403\n",
      "[Epoch 2] Step 2430 | BCE Loss: 0.015749\n",
      "[Epoch 2] Step 2440 | BCE Loss: 0.038172\n",
      "[Epoch 2] Step 2450 | BCE Loss: 0.011715\n",
      "[Epoch 2] Step 2460 | BCE Loss: 0.014263\n",
      "[Epoch 2] Step 2470 | BCE Loss: 0.018205\n",
      "[Epoch 2] Step 2480 | BCE Loss: 0.018972\n",
      "[Epoch 2] Step 2490 | BCE Loss: 0.013148\n",
      "[Epoch 2] Step 2500 | BCE Loss: 0.014049\n",
      "[Epoch 2] Step 2510 | BCE Loss: 0.018474\n",
      "[Epoch 2] Step 2520 | BCE Loss: 0.015319\n",
      "[Epoch 2] Step 2530 | BCE Loss: 0.015712\n",
      "[Epoch 2] Step 2540 | BCE Loss: 0.016598\n",
      "[Epoch 2] Step 2550 | BCE Loss: 0.012185\n",
      "[Epoch 2] Step 2560 | BCE Loss: 0.019791\n",
      "[Epoch 2] Step 2570 | BCE Loss: 0.017301\n",
      "[Epoch 2] Step 2580 | BCE Loss: 0.017144\n",
      "[Epoch 2] Step 2590 | BCE Loss: 0.030020\n",
      "[Epoch 2] Step 2600 | BCE Loss: 0.020049\n",
      "[Epoch 2] Step 2610 | BCE Loss: 0.015154\n",
      "[Epoch 2] Step 2620 | BCE Loss: 0.015344\n",
      "[Epoch 2] Step 2630 | BCE Loss: 0.017669\n",
      "[Epoch 2] Step 2640 | BCE Loss: 0.035864\n",
      "[Epoch 2] Step 2650 | BCE Loss: 0.037659\n",
      "[Epoch 2] Step 2660 | BCE Loss: 0.015422\n",
      "[Epoch 2] Step 2670 | BCE Loss: 0.009689\n",
      "[Epoch 2] Step 2680 | BCE Loss: 0.020833\n",
      "[Epoch 2] Step 2690 | BCE Loss: 0.014955\n",
      "[Epoch 2] Step 2700 | BCE Loss: 0.019019\n",
      "[Epoch 2] Step 2710 | BCE Loss: 0.017651\n",
      "[Epoch 2] Step 2720 | BCE Loss: 0.012623\n",
      "[Epoch 2] Step 2730 | BCE Loss: 0.022327\n",
      "[Epoch 2] Step 2740 | BCE Loss: 0.028380\n",
      "[Epoch 2] Step 2750 | BCE Loss: 0.021528\n",
      "[Epoch 2] Step 2760 | BCE Loss: 0.014477\n",
      "[Epoch 2] Step 2770 | BCE Loss: 0.017027\n",
      "[Epoch 2] Step 2780 | BCE Loss: 0.014100\n",
      "[Epoch 2] Step 2790 | BCE Loss: 0.014252\n",
      "[Epoch 2] Step 2800 | BCE Loss: 0.013413\n",
      "[Epoch 2] Step 2810 | BCE Loss: 0.015341\n",
      "[Epoch 2] Step 2820 | BCE Loss: 0.015260\n",
      "[Epoch 2] Step 2830 | BCE Loss: 0.034398\n",
      "[Epoch 2] Step 2840 | BCE Loss: 0.018860\n",
      "[Epoch 2] Step 2850 | BCE Loss: 0.018752\n",
      "[Epoch 2] Step 2860 | BCE Loss: 0.015964\n",
      "[Epoch 2] Step 2870 | BCE Loss: 0.019325\n",
      "[Epoch 2] Step 2880 | BCE Loss: 0.014741\n",
      "[Epoch 2] Step 2890 | BCE Loss: 0.020257\n",
      "[Epoch 2] Step 2900 | BCE Loss: 0.011794\n",
      "[Epoch 2] Step 2910 | BCE Loss: 0.013486\n",
      "[Epoch 2] Step 2920 | BCE Loss: 0.015852\n",
      "[Epoch 2] Step 2930 | BCE Loss: 0.022758\n",
      "[Epoch 2] Step 2940 | BCE Loss: 0.015415\n",
      "[Epoch 2] Step 2950 | BCE Loss: 0.018760\n",
      "[Epoch 2] Step 2960 | BCE Loss: 0.024294\n",
      "[Epoch 2] Step 2970 | BCE Loss: 0.011960\n",
      "[Epoch 2] Step 2980 | BCE Loss: 0.018498\n",
      "[Epoch 2] Step 2990 | BCE Loss: 0.016373\n",
      "[Epoch 2] Step 3000 | BCE Loss: 0.014956\n",
      "[Epoch 2] Step 3010 | BCE Loss: 0.014212\n",
      "[Epoch 2] Step 3020 | BCE Loss: 0.011867\n",
      "[Epoch 2] Step 3030 | BCE Loss: 0.018995\n",
      "[Epoch 2] Step 3040 | BCE Loss: 0.022685\n",
      "[Epoch 2] Step 3050 | BCE Loss: 0.014414\n",
      "[Epoch 2] Step 3060 | BCE Loss: 0.042942\n",
      "[Epoch 2] Step 3070 | BCE Loss: 0.014721\n",
      "[Epoch 2] Step 3080 | BCE Loss: 0.015036\n",
      "[Epoch 2] Step 3090 | BCE Loss: 0.015061\n",
      "[Epoch 2] Step 3100 | BCE Loss: 0.018499\n",
      "[Epoch 2] Step 3110 | BCE Loss: 0.042309\n",
      "[Epoch 2] Step 3120 | BCE Loss: 0.031972\n",
      "[Epoch 2] Step 3130 | BCE Loss: 0.012753\n",
      "[Epoch 2] Step 3140 | BCE Loss: 0.013334\n",
      "[Epoch 2] Step 3150 | BCE Loss: 0.017066\n",
      "[Epoch 2] Step 3160 | BCE Loss: 0.017414\n",
      "[Epoch 2] Step 3170 | BCE Loss: 0.020088\n",
      "[Epoch 2] Step 3180 | BCE Loss: 0.011380\n",
      "[Epoch 2] Step 3190 | BCE Loss: 0.016954\n",
      "[Epoch 2] Step 3200 | BCE Loss: 0.014608\n",
      "[Epoch 2] Step 3210 | BCE Loss: 0.017020\n",
      "[Epoch 2] Step 3220 | BCE Loss: 0.016127\n",
      "[Epoch 2] Step 3230 | BCE Loss: 0.016273\n",
      "[Epoch 2] Step 3240 | BCE Loss: 0.013472\n",
      "[Epoch 2] Step 3250 | BCE Loss: 0.023217\n",
      "[Epoch 2] Step 3260 | BCE Loss: 0.022038\n",
      "[Epoch 2] Step 3270 | BCE Loss: 0.009655\n",
      "[Epoch 2] Step 3280 | BCE Loss: 0.037658\n",
      "[Epoch 2] Step 3290 | BCE Loss: 0.046348\n",
      "[Epoch 2] Step 3300 | BCE Loss: 0.052843\n",
      "[Epoch 2] Step 3310 | BCE Loss: 0.016386\n",
      "[Epoch 2] Step 3320 | BCE Loss: 0.021508\n",
      "[Epoch 2] Step 3330 | BCE Loss: 0.018473\n",
      "[Epoch 2] Step 3340 | BCE Loss: 0.027193\n",
      "[Epoch 2] Step 3350 | BCE Loss: 0.015512\n",
      "[Epoch 2] Step 3360 | BCE Loss: 0.021889\n",
      "[Epoch 2] Step 3370 | BCE Loss: 0.013857\n",
      "[Epoch 2] Step 3380 | BCE Loss: 0.019284\n",
      "[Epoch 2] Step 3390 | BCE Loss: 0.015163\n",
      "[Epoch 2] Step 3400 | BCE Loss: 0.012538\n",
      "[Epoch 2] Step 3410 | BCE Loss: 0.014405\n",
      "[Epoch 2] Step 3420 | BCE Loss: 0.026752\n",
      "[Epoch 2] Step 3430 | BCE Loss: 0.015881\n",
      "[Epoch 2] Step 3440 | BCE Loss: 0.010962\n",
      "[Epoch 2] Step 3450 | BCE Loss: 0.012292\n",
      "[Epoch 2] Step 3460 | BCE Loss: 0.015185\n",
      "[Epoch 2] Step 3470 | BCE Loss: 0.014020\n",
      "[Epoch 2] Step 3480 | BCE Loss: 0.019466\n",
      "[Epoch 2] Step 3490 | BCE Loss: 0.028004\n",
      "[Epoch 2] Step 3500 | BCE Loss: 0.021190\n",
      "[Epoch 2] Step 3510 | BCE Loss: 0.029252\n",
      "[Epoch 2] Step 3520 | BCE Loss: 0.021324\n",
      "[Epoch 2] Step 3530 | BCE Loss: 0.012323\n",
      "[Epoch 2] Step 3540 | BCE Loss: 0.014945\n",
      "[Epoch 2] Step 3550 | BCE Loss: 0.016966\n",
      "[Epoch 2] Step 3560 | BCE Loss: 0.026212\n",
      "[Epoch 2] Step 3570 | BCE Loss: 0.016994\n",
      "[Epoch 2] Step 3580 | BCE Loss: 0.020460\n",
      "[Epoch 2] Step 3590 | BCE Loss: 0.034354\n",
      "[Epoch 2] Step 3600 | BCE Loss: 0.014317\n",
      "[Epoch 2] Step 3610 | BCE Loss: 0.017077\n",
      "[Epoch 2] Step 3620 | BCE Loss: 0.014726\n",
      "[Epoch 2] Step 3630 | BCE Loss: 0.028402\n",
      "[Epoch 2] Step 3640 | BCE Loss: 0.021062\n",
      "[Epoch 2] Step 3650 | BCE Loss: 0.017091\n",
      "[Epoch 2] Step 3660 | BCE Loss: 0.015410\n",
      "[Epoch 2] Step 3670 | BCE Loss: 0.016626\n",
      "[Epoch 2] Step 3680 | BCE Loss: 0.014125\n",
      "[Epoch 2] Step 3690 | BCE Loss: 0.014494\n",
      "[Epoch 2] Step 3700 | BCE Loss: 0.016261\n",
      "[Epoch 2] Step 3710 | BCE Loss: 0.018461\n",
      "[Epoch 2] Step 3720 | BCE Loss: 0.013945\n",
      "[Epoch 2] Step 3730 | BCE Loss: 0.012685\n",
      "[Epoch 2] Step 3740 | BCE Loss: 0.013000\n",
      "[Epoch 2] Step 3750 | BCE Loss: 0.013145\n",
      "[Epoch 2] Step 3760 | BCE Loss: 0.016973\n",
      "[Epoch 2] Step 3770 | BCE Loss: 0.013444\n",
      "[Epoch 2] Step 3780 | BCE Loss: 0.018853\n",
      "[Epoch 2] Step 3790 | BCE Loss: 0.009693\n",
      "[Epoch 2] Step 3800 | BCE Loss: 0.021566\n",
      "[Epoch 2] Step 3810 | BCE Loss: 0.011999\n",
      "[Epoch 2] Step 3820 | BCE Loss: 0.018484\n",
      "[Epoch 2] Step 3830 | BCE Loss: 0.014276\n",
      "[Epoch 2] Step 3840 | BCE Loss: 0.019977\n",
      "[Epoch 2] Step 3850 | BCE Loss: 0.013300\n",
      "[Epoch 2] Step 3860 | BCE Loss: 0.015823\n",
      "[Epoch 2] Step 3870 | BCE Loss: 0.018226\n",
      "[Epoch 2] Step 3880 | BCE Loss: 0.019697\n",
      "[Epoch 2] Step 3890 | BCE Loss: 0.016600\n",
      "[Epoch 2] Step 3900 | BCE Loss: 0.020676\n",
      "[Epoch 2] Step 3910 | BCE Loss: 0.012841\n",
      "[Epoch 2] Step 3920 | BCE Loss: 0.014060\n",
      "[Epoch 2] Step 3930 | BCE Loss: 0.031271\n",
      "[Epoch 2] Step 3940 | BCE Loss: 0.016102\n",
      "[Epoch 2] Step 3950 | BCE Loss: 0.018740\n",
      "[Epoch 2] Step 3960 | BCE Loss: 0.012914\n",
      "[Epoch 2] Step 3970 | BCE Loss: 0.019073\n",
      "[Epoch 2] Step 3980 | BCE Loss: 0.014223\n",
      "[Epoch 2] Step 3990 | BCE Loss: 0.032637\n",
      "[Epoch 2] Step 4000 | BCE Loss: 0.011817\n",
      "[Epoch 2] Step 4010 | BCE Loss: 0.041965\n",
      "[Epoch 2] Step 4020 | BCE Loss: 0.012702\n",
      "[Epoch 2] Step 4030 | BCE Loss: 0.015923\n",
      "[Epoch 2] Step 4040 | BCE Loss: 0.013564\n",
      "[Epoch 2] Step 4050 | BCE Loss: 0.017031\n",
      "[Epoch 2] Step 4060 | BCE Loss: 0.021846\n",
      "[Epoch 2] Step 4070 | BCE Loss: 0.019434\n",
      "[Epoch 2] Step 4080 | BCE Loss: 0.021111\n",
      "[Epoch 2] Step 4090 | BCE Loss: 0.016783\n",
      "[Epoch 2] Step 4100 | BCE Loss: 0.011217\n",
      "[Epoch 2] Step 4110 | BCE Loss: 0.016541\n",
      "[Epoch 2] Step 4120 | BCE Loss: 0.026219\n",
      "[Epoch 2] Step 4130 | BCE Loss: 0.017703\n",
      "[Epoch 2] Step 4140 | BCE Loss: 0.017213\n",
      "[Epoch 2] Step 4150 | BCE Loss: 0.012978\n",
      "[Epoch 2] Step 4160 | BCE Loss: 0.017548\n",
      "[Epoch 2] Step 4170 | BCE Loss: 0.016056\n",
      "[Epoch 2] Step 4180 | BCE Loss: 0.023611\n",
      "[Epoch 2] Step 4190 | BCE Loss: 0.015594\n",
      "[Epoch 2] Step 4200 | BCE Loss: 0.014064\n",
      "[Epoch 2] Step 4210 | BCE Loss: 0.019962\n",
      "[Epoch 2] Step 4220 | BCE Loss: 0.017305\n",
      "[Epoch 2] Step 4230 | BCE Loss: 0.023308\n",
      "[Epoch 2] Step 4240 | BCE Loss: 0.143179\n",
      "[Epoch 2] Step 4250 | BCE Loss: 0.037838\n",
      "[Epoch 2] Step 4260 | BCE Loss: 0.022762\n",
      "[Epoch 2] Step 4270 | BCE Loss: 0.018765\n",
      "[Epoch 2] Step 4280 | BCE Loss: 0.014800\n",
      "[Epoch 2] Step 4290 | BCE Loss: 0.012619\n",
      "[Epoch 2] Step 4300 | BCE Loss: 0.011537\n",
      "[Epoch 2] Step 4310 | BCE Loss: 0.024050\n",
      "[Epoch 2] Step 4320 | BCE Loss: 0.021563\n",
      "[Epoch 2] Step 4330 | BCE Loss: 0.016178\n",
      "[Epoch 2] Step 4340 | BCE Loss: 0.012137\n",
      "[Epoch 2] Step 4350 | BCE Loss: 0.013264\n",
      "[Epoch 2] Step 4360 | BCE Loss: 0.015859\n",
      "[Epoch 2] Step 4370 | BCE Loss: 0.016418\n",
      "[Epoch 2] Step 4380 | BCE Loss: 0.017374\n",
      "[Epoch 2] Step 4390 | BCE Loss: 0.015572\n",
      "[Epoch 2] Step 4400 | BCE Loss: 0.015349\n",
      "[Epoch 2] Step 4410 | BCE Loss: 0.013838\n",
      "[Epoch 2] Step 4420 | BCE Loss: 0.014896\n",
      "[Epoch 2] Step 4430 | BCE Loss: 0.017723\n",
      "[Epoch 2] Step 4440 | BCE Loss: 0.014200\n",
      "[Epoch 2] Step 4450 | BCE Loss: 0.013474\n",
      "[Epoch 2] Step 4460 | BCE Loss: 0.012082\n",
      "[Epoch 2] Step 4470 | BCE Loss: 0.022523\n",
      "[Epoch 2] Step 4480 | BCE Loss: 0.015324\n",
      "[Epoch 2] Step 4490 | BCE Loss: 0.013010\n",
      "[Epoch 2] Step 4500 | BCE Loss: 0.013740\n",
      "[Epoch 2] Step 4510 | BCE Loss: 0.015138\n",
      "[Epoch 2] Step 4520 | BCE Loss: 0.014368\n",
      "[Epoch 2] Step 4530 | BCE Loss: 0.021000\n",
      "[Epoch 2] Step 4540 | BCE Loss: 0.019646\n",
      "[Epoch 2] Step 4550 | BCE Loss: 0.018284\n",
      "[Epoch 2] Step 4560 | BCE Loss: 0.014942\n",
      "[Epoch 2] Step 4570 | BCE Loss: 0.016486\n",
      "[Epoch 2] Step 4580 | BCE Loss: 0.015749\n",
      "[Epoch 2] Step 4590 | BCE Loss: 0.013106\n",
      "[Epoch 2] Step 4600 | BCE Loss: 0.019566\n",
      "[Epoch 2] Step 4610 | BCE Loss: 0.014945\n",
      "[Epoch 2] Step 4620 | BCE Loss: 0.011042\n",
      "[Epoch 2] Step 4630 | BCE Loss: 0.013380\n",
      "[Epoch 2] Step 4640 | BCE Loss: 0.015952\n",
      "[Epoch 2] Step 4650 | BCE Loss: 0.042132\n",
      "[Epoch 2] Step 4660 | BCE Loss: 0.024084\n",
      "[Epoch 2] Step 4670 | BCE Loss: 0.023470\n",
      "[Epoch 2] Step 4680 | BCE Loss: 0.011808\n",
      "[Epoch 2] Step 4690 | BCE Loss: 0.016356\n",
      "[Epoch 2] Step 4700 | BCE Loss: 0.024070\n",
      "[Epoch 2] Step 4710 | BCE Loss: 0.039503\n",
      "[Epoch 2] Step 4720 | BCE Loss: 0.013325\n",
      "[Epoch 2] Step 4730 | BCE Loss: 0.017489\n",
      "[Epoch 2] Step 4740 | BCE Loss: 0.017591\n",
      "[Epoch 2] Step 4750 | BCE Loss: 0.013996\n",
      "[Epoch 2] Step 4760 | BCE Loss: 0.011633\n",
      "[Epoch 2] Step 4770 | BCE Loss: 0.017559\n",
      "[Epoch 2] Step 4780 | BCE Loss: 0.018238\n",
      "[Epoch 2] Step 4790 | BCE Loss: 0.021626\n",
      "[Epoch 2] Step 4800 | BCE Loss: 0.012167\n",
      "[Epoch 2] Step 4810 | BCE Loss: 0.018775\n",
      "[Epoch 2] Step 4820 | BCE Loss: 0.016120\n",
      "[Epoch 2] Step 4830 | BCE Loss: 0.019803\n",
      "[Epoch 2] Step 4840 | BCE Loss: 0.016387\n",
      "[Epoch 2] Step 4850 | BCE Loss: 0.020664\n",
      "[Epoch 2] Step 4860 | BCE Loss: 0.020044\n",
      "[Epoch 2] Step 4870 | BCE Loss: 0.016376\n",
      "[Epoch 2] Step 4880 | BCE Loss: 0.029588\n",
      "[Epoch 2] Step 4890 | BCE Loss: 0.012358\n",
      "[Epoch 2] Step 4900 | BCE Loss: 0.013994\n",
      "[Epoch 2] Step 4910 | BCE Loss: 0.012247\n",
      "[Epoch 2] Step 4920 | BCE Loss: 0.017967\n",
      "[Epoch 2] Step 4930 | BCE Loss: 0.013632\n",
      "[Epoch 2] Step 4940 | BCE Loss: 0.014930\n",
      "[Epoch 2] Step 4950 | BCE Loss: 0.025211\n",
      "[Epoch 2] Step 4960 | BCE Loss: 0.016751\n",
      "[Epoch 2] Step 4970 | BCE Loss: 0.022859\n",
      "[Epoch 2] Step 4980 | BCE Loss: 0.013804\n",
      "[Epoch 2] Step 4990 | BCE Loss: 0.010697\n",
      "[Epoch 2] Step 5000 | BCE Loss: 0.018688\n",
      "[Epoch 2] Step 5010 | BCE Loss: 0.013112\n",
      "[Epoch 2] Step 5020 | BCE Loss: 0.013658\n",
      "[Epoch 2] Step 5030 | BCE Loss: 0.016285\n",
      "[Epoch 2] Step 5040 | BCE Loss: 0.013240\n",
      "[Epoch 2] Step 5050 | BCE Loss: 0.015566\n",
      "[Epoch 2] Step 5060 | BCE Loss: 0.023142\n",
      "[Epoch 2] Step 5070 | BCE Loss: 0.015936\n",
      "[Epoch 2] Step 5080 | BCE Loss: 0.018439\n",
      "[Epoch 2] Step 5090 | BCE Loss: 0.018307\n",
      "[Epoch 2] Step 5100 | BCE Loss: 0.014625\n",
      "[Epoch 2] Step 5110 | BCE Loss: 0.014973\n",
      "[Epoch 2] Step 5120 | BCE Loss: 0.015327\n",
      "[Epoch 2] Step 5130 | BCE Loss: 0.019974\n",
      "[Epoch 2] Step 5140 | BCE Loss: 0.015185\n",
      "[Epoch 2] Step 5150 | BCE Loss: 0.048393\n",
      "[Epoch 2] Step 5160 | BCE Loss: 0.015243\n",
      "[Epoch 2] Step 5170 | BCE Loss: 0.017568\n",
      "[Epoch 2] Step 5180 | BCE Loss: 0.013317\n",
      "[Epoch 2] Step 5190 | BCE Loss: 0.012556\n",
      "[Epoch 2] Step 5200 | BCE Loss: 0.020565\n",
      "[Epoch 2] Step 5210 | BCE Loss: 0.013801\n",
      "[Epoch 2] Step 5220 | BCE Loss: 0.015482\n",
      "[Epoch 2] Step 5230 | BCE Loss: 0.015740\n",
      "[Epoch 2] Step 5240 | BCE Loss: 0.017316\n",
      "[Epoch 2] Step 5250 | BCE Loss: 0.015675\n",
      "[Epoch 2] Step 5260 | BCE Loss: 0.011830\n",
      "[Epoch 2] Step 5270 | BCE Loss: 0.011623\n",
      "[Epoch 2] Step 5280 | BCE Loss: 0.016342\n",
      "[Epoch 2] Step 5290 | BCE Loss: 0.013896\n",
      "[Epoch 2] Step 5300 | BCE Loss: 0.019745\n",
      "[Epoch 2] Step 5310 | BCE Loss: 0.014535\n",
      "[Epoch 2] Step 5320 | BCE Loss: 0.014320\n",
      "[Epoch 2] Step 5330 | BCE Loss: 0.017836\n",
      "[Epoch 2] Step 5340 | BCE Loss: 0.030092\n",
      "[Epoch 2] Step 5350 | BCE Loss: 0.013715\n",
      "[Epoch 2] Step 5360 | BCE Loss: 0.014523\n",
      "[Epoch 2] Step 5370 | BCE Loss: 0.019657\n",
      "[Epoch 2] Step 5380 | BCE Loss: 0.016953\n",
      "[Epoch 2] Step 5390 | BCE Loss: 0.011615\n",
      "[Epoch 2] Step 5400 | BCE Loss: 0.025743\n",
      "[Epoch 2] Step 5410 | BCE Loss: 0.016086\n",
      "[Epoch 2] Step 5420 | BCE Loss: 0.017258\n",
      "[Epoch 2] Step 5430 | BCE Loss: 0.021935\n",
      "[Epoch 2] Step 5440 | BCE Loss: 0.018454\n",
      "[Epoch 2] Step 5450 | BCE Loss: 0.018312\n",
      "[Epoch 2] Step 5460 | BCE Loss: 0.016216\n",
      "[Epoch 2] Step 5470 | BCE Loss: 0.014810\n",
      "[Epoch 2] Step 5480 | BCE Loss: 0.013376\n",
      "[Epoch 2] Step 5490 | BCE Loss: 0.017171\n",
      "[Epoch 2] Step 5500 | BCE Loss: 0.011393\n",
      "[Epoch 2] Step 5510 | BCE Loss: 0.021196\n",
      "[Epoch 2] Step 5520 | BCE Loss: 0.011785\n",
      "[Epoch 2] Step 5530 | BCE Loss: 0.014777\n",
      "[Epoch 2] Step 5540 | BCE Loss: 0.016179\n",
      "[Epoch 2] Step 5550 | BCE Loss: 0.012794\n",
      "[Epoch 2] Step 5560 | BCE Loss: 0.011864\n",
      "[Epoch 2] Step 5570 | BCE Loss: 0.023892\n",
      "[Epoch 2] Step 5580 | BCE Loss: 0.011365\n",
      "[Epoch 2] Step 5590 | BCE Loss: 0.018393\n",
      "[Epoch 2] Step 5600 | BCE Loss: 0.012288\n",
      "[Epoch 2] Step 5610 | BCE Loss: 0.012785\n",
      "[Epoch 2] Step 5620 | BCE Loss: 0.014185\n",
      "[Epoch 2] Step 5630 | BCE Loss: 0.013530\n",
      "[Epoch 2] Step 5640 | BCE Loss: 0.032214\n",
      "[Epoch 2] Step 5650 | BCE Loss: 0.014619\n",
      "[Epoch 2] Step 5660 | BCE Loss: 0.019962\n",
      "[Epoch 2] Step 5670 | BCE Loss: 0.016809\n",
      "[Epoch 2] Step 5680 | BCE Loss: 0.016202\n",
      "[Epoch 2] Step 5690 | BCE Loss: 0.012889\n",
      "[Epoch 2] Step 5700 | BCE Loss: 0.018715\n",
      "[Epoch 2] Step 5710 | BCE Loss: 0.013170\n",
      "[Epoch 2] Step 5720 | BCE Loss: 0.014183\n",
      "[Epoch 2] Step 5730 | BCE Loss: 0.013306\n",
      "[Epoch 2] Step 5740 | BCE Loss: 0.016402\n",
      "[Epoch 2] Step 5750 | BCE Loss: 0.015416\n",
      "[Epoch 2] Step 5760 | BCE Loss: 0.017198\n",
      "[Epoch 2] Step 5770 | BCE Loss: 0.014305\n",
      "[Epoch 2] Step 5780 | BCE Loss: 0.020836\n",
      "[Epoch 2] Step 5790 | BCE Loss: 0.017076\n",
      "[Epoch 2] Step 5800 | BCE Loss: 0.014043\n",
      "[Epoch 2] Step 5810 | BCE Loss: 0.017192\n",
      "[Epoch 2] Step 5820 | BCE Loss: 0.017386\n",
      "\n",
      "=== Epoch 2 Selesai | Avg BCE Loss: 0.018732 ===\n",
      "[SAVE] Merging weights and saving single .pth file...\n",
      "[SAVE] Full PEFT checkpoint saved to: /kaggle/working/output/sam2_finetuned.pth\n",
      "\n",
      "[Epoch 3/5]\n",
      "[Epoch 3] Step 0 | BCE Loss: 0.017335\n",
      "[Epoch 3] Step 10 | BCE Loss: 0.020630\n",
      "[Epoch 3] Step 20 | BCE Loss: 0.017820\n",
      "[Epoch 3] Step 30 | BCE Loss: 0.019390\n",
      "[Epoch 3] Step 40 | BCE Loss: 0.013578\n",
      "[Epoch 3] Step 50 | BCE Loss: 0.015444\n",
      "[Epoch 3] Step 60 | BCE Loss: 0.046950\n",
      "[Epoch 3] Step 70 | BCE Loss: 0.013160\n",
      "[Epoch 3] Step 80 | BCE Loss: 0.017820\n",
      "[Epoch 3] Step 90 | BCE Loss: 0.016527\n",
      "[Epoch 3] Step 100 | BCE Loss: 0.013123\n",
      "[Epoch 3] Step 110 | BCE Loss: 0.012336\n",
      "[Epoch 3] Step 120 | BCE Loss: 0.017165\n",
      "[Epoch 3] Step 130 | BCE Loss: 0.012844\n",
      "[Epoch 3] Step 140 | BCE Loss: 0.011689\n",
      "[Epoch 3] Step 150 | BCE Loss: 0.014539\n",
      "[Epoch 3] Step 160 | BCE Loss: 0.032836\n",
      "[Epoch 3] Step 170 | BCE Loss: 0.016397\n",
      "[Epoch 3] Step 180 | BCE Loss: 0.013794\n",
      "[Epoch 3] Step 190 | BCE Loss: 0.037496\n",
      "[Epoch 3] Step 200 | BCE Loss: 0.011703\n",
      "[Epoch 3] Step 210 | BCE Loss: 0.015746\n",
      "[Epoch 3] Step 220 | BCE Loss: 0.013504\n",
      "[Epoch 3] Step 230 | BCE Loss: 0.017870\n",
      "[Epoch 3] Step 240 | BCE Loss: 0.016653\n",
      "[Epoch 3] Step 250 | BCE Loss: 0.013844\n",
      "[Epoch 3] Step 260 | BCE Loss: 0.014039\n",
      "[Epoch 3] Step 270 | BCE Loss: 0.012900\n",
      "[Epoch 3] Step 280 | BCE Loss: 0.015542\n",
      "[Epoch 3] Step 290 | BCE Loss: 0.019348\n",
      "[Epoch 3] Step 300 | BCE Loss: 0.012842\n",
      "[Epoch 3] Step 310 | BCE Loss: 0.021025\n",
      "[Epoch 3] Step 320 | BCE Loss: 0.011485\n",
      "[Epoch 3] Step 330 | BCE Loss: 0.016787\n",
      "[Epoch 3] Step 340 | BCE Loss: 0.012182\n",
      "[Epoch 3] Step 350 | BCE Loss: 0.015365\n",
      "[Epoch 3] Step 360 | BCE Loss: 0.037386\n",
      "[Epoch 3] Step 370 | BCE Loss: 0.016388\n",
      "[Epoch 3] Step 380 | BCE Loss: 0.042674\n",
      "[Epoch 3] Step 390 | BCE Loss: 0.017671\n",
      "[Epoch 3] Step 400 | BCE Loss: 0.017051\n",
      "[Epoch 3] Step 410 | BCE Loss: 0.016716\n",
      "[Epoch 3] Step 420 | BCE Loss: 0.015858\n",
      "[Epoch 3] Step 430 | BCE Loss: 0.015820\n",
      "[Epoch 3] Step 440 | BCE Loss: 0.014110\n",
      "[Epoch 3] Step 450 | BCE Loss: 0.014594\n",
      "[Epoch 3] Step 460 | BCE Loss: 0.012543\n",
      "[Epoch 3] Step 470 | BCE Loss: 0.018054\n",
      "[Epoch 3] Step 480 | BCE Loss: 0.019749\n",
      "[Epoch 3] Step 490 | BCE Loss: 0.011818\n",
      "[Epoch 3] Step 500 | BCE Loss: 0.019772\n",
      "[Epoch 3] Step 510 | BCE Loss: 0.225129\n",
      "[Epoch 3] Step 520 | BCE Loss: 0.016488\n",
      "[Epoch 3] Step 530 | BCE Loss: 0.013146\n",
      "[Epoch 3] Step 540 | BCE Loss: 0.012492\n",
      "[Epoch 3] Step 550 | BCE Loss: 0.014804\n",
      "[Epoch 3] Step 560 | BCE Loss: 0.022610\n",
      "[Epoch 3] Step 570 | BCE Loss: 0.016872\n",
      "[Epoch 3] Step 580 | BCE Loss: 0.023267\n",
      "[Epoch 3] Step 590 | BCE Loss: 0.013026\n",
      "[Epoch 3] Step 600 | BCE Loss: 0.014553\n",
      "[Epoch 3] Step 610 | BCE Loss: 0.015955\n",
      "[Epoch 3] Step 620 | BCE Loss: 0.014838\n",
      "[Epoch 3] Step 630 | BCE Loss: 0.025007\n",
      "[Epoch 3] Step 640 | BCE Loss: 0.017926\n",
      "[Epoch 3] Step 650 | BCE Loss: 0.014058\n",
      "[Epoch 3] Step 660 | BCE Loss: 0.014869\n",
      "[Epoch 3] Step 670 | BCE Loss: 0.014926\n",
      "[Epoch 3] Step 680 | BCE Loss: 0.013630\n",
      "[Epoch 3] Step 690 | BCE Loss: 0.012660\n",
      "[Epoch 3] Step 700 | BCE Loss: 0.013134\n",
      "[Epoch 3] Step 710 | BCE Loss: 0.036153\n",
      "[Epoch 3] Step 720 | BCE Loss: 0.023905\n",
      "[Epoch 3] Step 730 | BCE Loss: 0.016011\n",
      "[Epoch 3] Step 740 | BCE Loss: 0.016179\n",
      "[Epoch 3] Step 750 | BCE Loss: 0.013489\n",
      "[Epoch 3] Step 760 | BCE Loss: 0.013402\n",
      "[Epoch 3] Step 770 | BCE Loss: 0.014089\n",
      "[Epoch 3] Step 780 | BCE Loss: 0.016497\n",
      "[Epoch 3] Step 790 | BCE Loss: 0.018044\n",
      "[Epoch 3] Step 800 | BCE Loss: 0.013591\n",
      "[Epoch 3] Step 810 | BCE Loss: 0.014565\n",
      "[Epoch 3] Step 820 | BCE Loss: 0.015751\n",
      "[Epoch 3] Step 830 | BCE Loss: 0.015255\n",
      "[Epoch 3] Step 840 | BCE Loss: 0.019637\n",
      "[Epoch 3] Step 850 | BCE Loss: 0.016697\n",
      "[Epoch 3] Step 860 | BCE Loss: 0.012759\n",
      "[Epoch 3] Step 870 | BCE Loss: 0.013044\n",
      "[Epoch 3] Step 880 | BCE Loss: 0.012417\n",
      "[Epoch 3] Step 890 | BCE Loss: 0.023190\n",
      "[Epoch 3] Step 900 | BCE Loss: 0.113516\n",
      "[Epoch 3] Step 910 | BCE Loss: 0.014608\n",
      "[Epoch 3] Step 920 | BCE Loss: 0.013368\n",
      "[Epoch 3] Step 930 | BCE Loss: 0.015070\n",
      "[Epoch 3] Step 940 | BCE Loss: 0.013966\n",
      "[Epoch 3] Step 950 | BCE Loss: 0.035107\n",
      "[Epoch 3] Step 960 | BCE Loss: 0.015003\n",
      "[Epoch 3] Step 970 | BCE Loss: 0.010847\n",
      "[Epoch 3] Step 980 | BCE Loss: 0.014270\n",
      "[Epoch 3] Step 990 | BCE Loss: 0.012843\n",
      "[Epoch 3] Step 1000 | BCE Loss: 0.036487\n",
      "[Epoch 3] Step 1010 | BCE Loss: 0.014785\n",
      "[Epoch 3] Step 1020 | BCE Loss: 0.018368\n",
      "[Epoch 3] Step 1030 | BCE Loss: 0.013035\n",
      "[Epoch 3] Step 1040 | BCE Loss: 0.015080\n",
      "[Epoch 3] Step 1050 | BCE Loss: 0.022996\n",
      "[Epoch 3] Step 1060 | BCE Loss: 0.013976\n",
      "[Epoch 3] Step 1070 | BCE Loss: 0.011753\n",
      "[Epoch 3] Step 1080 | BCE Loss: 0.015686\n",
      "[Epoch 3] Step 1090 | BCE Loss: 0.013223\n",
      "[Epoch 3] Step 1100 | BCE Loss: 0.014893\n",
      "[Epoch 3] Step 1110 | BCE Loss: 0.016167\n",
      "[Epoch 3] Step 1120 | BCE Loss: 0.020808\n",
      "[Epoch 3] Step 1130 | BCE Loss: 0.011085\n",
      "[Epoch 3] Step 1140 | BCE Loss: 0.013280\n",
      "[Epoch 3] Step 1150 | BCE Loss: 0.015897\n",
      "[Epoch 3] Step 1160 | BCE Loss: 0.017529\n",
      "[Epoch 3] Step 1170 | BCE Loss: 0.011282\n",
      "[Epoch 3] Step 1180 | BCE Loss: 0.012857\n",
      "[Epoch 3] Step 1190 | BCE Loss: 0.045694\n",
      "[Epoch 3] Step 1200 | BCE Loss: 0.012774\n",
      "[Epoch 3] Step 1210 | BCE Loss: 0.012530\n",
      "[Epoch 3] Step 1220 | BCE Loss: 0.019022\n",
      "[Epoch 3] Step 1230 | BCE Loss: 0.015265\n",
      "[Epoch 3] Step 1240 | BCE Loss: 0.015156\n",
      "[Epoch 3] Step 1250 | BCE Loss: 0.014179\n",
      "[Epoch 3] Step 1260 | BCE Loss: 0.016490\n",
      "[Epoch 3] Step 1270 | BCE Loss: 0.013971\n",
      "[Epoch 3] Step 1280 | BCE Loss: 0.016529\n",
      "[Epoch 3] Step 1290 | BCE Loss: 0.019665\n",
      "[Epoch 3] Step 1300 | BCE Loss: 0.017803\n",
      "[Epoch 3] Step 1310 | BCE Loss: 0.017343\n",
      "[Epoch 3] Step 1320 | BCE Loss: 0.018282\n",
      "[Epoch 3] Step 1330 | BCE Loss: 0.018433\n",
      "[Epoch 3] Step 1340 | BCE Loss: 0.016260\n",
      "[Epoch 3] Step 1350 | BCE Loss: 0.019406\n",
      "[Epoch 3] Step 1360 | BCE Loss: 0.013776\n",
      "[Epoch 3] Step 1370 | BCE Loss: 0.018378\n",
      "[Epoch 3] Step 1380 | BCE Loss: 0.036091\n",
      "[Epoch 3] Step 1390 | BCE Loss: 0.015813\n",
      "[Epoch 3] Step 1400 | BCE Loss: 0.017273\n",
      "[Epoch 3] Step 1410 | BCE Loss: 0.029374\n",
      "[Epoch 3] Step 1420 | BCE Loss: 0.014702\n",
      "[Epoch 3] Step 1430 | BCE Loss: 0.019347\n",
      "[Epoch 3] Step 1440 | BCE Loss: 0.020364\n",
      "[Epoch 3] Step 1450 | BCE Loss: 0.015470\n",
      "[Epoch 3] Step 1460 | BCE Loss: 0.013477\n",
      "[Epoch 3] Step 1470 | BCE Loss: 0.013903\n",
      "[Epoch 3] Step 1480 | BCE Loss: 0.016811\n",
      "[Epoch 3] Step 1490 | BCE Loss: 0.018225\n",
      "[Epoch 3] Step 1500 | BCE Loss: 0.034524\n",
      "[Epoch 3] Step 1510 | BCE Loss: 0.016131\n",
      "[Epoch 3] Step 1520 | BCE Loss: 0.017918\n",
      "[Epoch 3] Step 1530 | BCE Loss: 0.015424\n",
      "[Epoch 3] Step 1540 | BCE Loss: 0.017616\n",
      "[Epoch 3] Step 1550 | BCE Loss: 0.014902\n",
      "[Epoch 3] Step 1560 | BCE Loss: 0.018767\n",
      "[Epoch 3] Step 1570 | BCE Loss: 0.016728\n",
      "[Epoch 3] Step 1580 | BCE Loss: 0.014355\n",
      "[Epoch 3] Step 1590 | BCE Loss: 0.013571\n",
      "[Epoch 3] Step 1600 | BCE Loss: 0.016007\n",
      "[Epoch 3] Step 1610 | BCE Loss: 0.012770\n",
      "[Epoch 3] Step 1620 | BCE Loss: 0.018742\n",
      "[Epoch 3] Step 1630 | BCE Loss: 0.016854\n",
      "[Epoch 3] Step 1640 | BCE Loss: 0.012269\n",
      "[Epoch 3] Step 1650 | BCE Loss: 0.019147\n",
      "[Epoch 3] Step 1660 | BCE Loss: 0.012229\n",
      "[Epoch 3] Step 1670 | BCE Loss: 0.011768\n",
      "[Epoch 3] Step 1680 | BCE Loss: 0.021049\n",
      "[Epoch 3] Step 1690 | BCE Loss: 0.013456\n",
      "[Epoch 3] Step 1700 | BCE Loss: 0.016768\n",
      "[Epoch 3] Step 1710 | BCE Loss: 0.013400\n",
      "[Epoch 3] Step 1720 | BCE Loss: 0.017569\n",
      "[Epoch 3] Step 1730 | BCE Loss: 0.014025\n",
      "[Epoch 3] Step 1740 | BCE Loss: 0.010410\n",
      "[Epoch 3] Step 1750 | BCE Loss: 0.030018\n",
      "[Epoch 3] Step 1760 | BCE Loss: 0.016696\n",
      "[Epoch 3] Step 1770 | BCE Loss: 0.017201\n",
      "[Epoch 3] Step 1780 | BCE Loss: 0.018717\n",
      "[Epoch 3] Step 1790 | BCE Loss: 0.014712\n",
      "[Epoch 3] Step 1800 | BCE Loss: 0.015057\n",
      "[Epoch 3] Step 1810 | BCE Loss: 0.012524\n",
      "[Epoch 3] Step 1820 | BCE Loss: 0.019140\n",
      "[Epoch 3] Step 1830 | BCE Loss: 0.017038\n",
      "[Epoch 3] Step 1840 | BCE Loss: 0.027181\n",
      "[Epoch 3] Step 1850 | BCE Loss: 0.013368\n",
      "[Epoch 3] Step 1860 | BCE Loss: 0.020838\n",
      "[Epoch 3] Step 1870 | BCE Loss: 0.018959\n",
      "[Epoch 3] Step 1880 | BCE Loss: 0.015273\n",
      "[Epoch 3] Step 1890 | BCE Loss: 0.016998\n",
      "[Epoch 3] Step 1900 | BCE Loss: 0.019442\n",
      "[Epoch 3] Step 1910 | BCE Loss: 0.015664\n",
      "[Epoch 3] Step 1920 | BCE Loss: 0.013462\n",
      "[Epoch 3] Step 1930 | BCE Loss: 0.013094\n",
      "[Epoch 3] Step 1940 | BCE Loss: 0.015948\n",
      "[Epoch 3] Step 1950 | BCE Loss: 0.029531\n",
      "[Epoch 3] Step 1960 | BCE Loss: 0.011501\n",
      "[Epoch 3] Step 1970 | BCE Loss: 0.014516\n",
      "[Epoch 3] Step 1980 | BCE Loss: 0.013620\n",
      "[Epoch 3] Step 1990 | BCE Loss: 0.012427\n",
      "[Epoch 3] Step 2000 | BCE Loss: 0.015532\n",
      "[Epoch 3] Step 2010 | BCE Loss: 0.014840\n",
      "[Epoch 3] Step 2020 | BCE Loss: 0.023492\n",
      "[Epoch 3] Step 2030 | BCE Loss: 0.015483\n",
      "[Epoch 3] Step 2040 | BCE Loss: 0.014526\n",
      "[Epoch 3] Step 2050 | BCE Loss: 0.014202\n",
      "[Epoch 3] Step 2060 | BCE Loss: 0.032850\n",
      "[Epoch 3] Step 2070 | BCE Loss: 0.013696\n",
      "[Epoch 3] Step 2080 | BCE Loss: 0.016170\n",
      "[Epoch 3] Step 2090 | BCE Loss: 0.023977\n",
      "[Epoch 3] Step 2100 | BCE Loss: 0.027626\n",
      "[Epoch 3] Step 2110 | BCE Loss: 0.014208\n",
      "[Epoch 3] Step 2120 | BCE Loss: 0.014314\n",
      "[Epoch 3] Step 2130 | BCE Loss: 0.012567\n",
      "[Epoch 3] Step 2140 | BCE Loss: 0.018208\n",
      "[Epoch 3] Step 2150 | BCE Loss: 0.030931\n",
      "[Epoch 3] Step 2160 | BCE Loss: 0.015358\n",
      "[Epoch 3] Step 2170 | BCE Loss: 0.012486\n",
      "[Epoch 3] Step 2180 | BCE Loss: 0.015527\n",
      "[Epoch 3] Step 2190 | BCE Loss: 0.012093\n",
      "[Epoch 3] Step 2200 | BCE Loss: 0.017807\n",
      "[Epoch 3] Step 2210 | BCE Loss: 0.016587\n",
      "[Epoch 3] Step 2220 | BCE Loss: 0.014280\n",
      "[Epoch 3] Step 2230 | BCE Loss: 0.013220\n",
      "[Epoch 3] Step 2240 | BCE Loss: 0.013145\n",
      "[Epoch 3] Step 2250 | BCE Loss: 0.014028\n",
      "[Epoch 3] Step 2260 | BCE Loss: 0.015380\n",
      "[Epoch 3] Step 2270 | BCE Loss: 0.016827\n",
      "[Epoch 3] Step 2280 | BCE Loss: 0.014748\n",
      "[Epoch 3] Step 2290 | BCE Loss: 0.012610\n",
      "[Epoch 3] Step 2300 | BCE Loss: 0.012664\n",
      "[Epoch 3] Step 2310 | BCE Loss: 0.017489\n",
      "[Epoch 3] Step 2320 | BCE Loss: 0.029968\n",
      "[Epoch 3] Step 2330 | BCE Loss: 0.017573\n",
      "[Epoch 3] Step 2340 | BCE Loss: 0.016400\n",
      "[Epoch 3] Step 2350 | BCE Loss: 0.011733\n",
      "[Epoch 3] Step 2360 | BCE Loss: 0.020835\n",
      "[Epoch 3] Step 2370 | BCE Loss: 0.014842\n",
      "[Epoch 3] Step 2380 | BCE Loss: 0.018826\n",
      "[Epoch 3] Step 2390 | BCE Loss: 0.023473\n",
      "[Epoch 3] Step 2400 | BCE Loss: 0.015244\n",
      "[Epoch 3] Step 2410 | BCE Loss: 0.014613\n",
      "[Epoch 3] Step 2420 | BCE Loss: 0.031211\n",
      "[Epoch 3] Step 2430 | BCE Loss: 0.013852\n",
      "[Epoch 3] Step 2440 | BCE Loss: 0.017269\n",
      "[Epoch 3] Step 2450 | BCE Loss: 0.028357\n",
      "[Epoch 3] Step 2460 | BCE Loss: 0.023608\n",
      "[Epoch 3] Step 2470 | BCE Loss: 0.015375\n",
      "[Epoch 3] Step 2480 | BCE Loss: 0.015551\n",
      "[Epoch 3] Step 2490 | BCE Loss: 0.013833\n",
      "[Epoch 3] Step 2500 | BCE Loss: 0.016888\n",
      "[Epoch 3] Step 2510 | BCE Loss: 0.027837\n",
      "[Epoch 3] Step 2520 | BCE Loss: 0.015116\n",
      "[Epoch 3] Step 2530 | BCE Loss: 0.027012\n",
      "[Epoch 3] Step 2540 | BCE Loss: 0.014132\n",
      "[Epoch 3] Step 2550 | BCE Loss: 0.013099\n",
      "[Epoch 3] Step 2560 | BCE Loss: 0.021035\n",
      "[Epoch 3] Step 2570 | BCE Loss: 0.017271\n",
      "[Epoch 3] Step 2580 | BCE Loss: 0.016795\n",
      "[Epoch 3] Step 2590 | BCE Loss: 0.021370\n",
      "[Epoch 3] Step 2600 | BCE Loss: 0.015391\n",
      "[Epoch 3] Step 2610 | BCE Loss: 0.013987\n",
      "[Epoch 3] Step 2620 | BCE Loss: 0.015312\n",
      "[Epoch 3] Step 2630 | BCE Loss: 0.014480\n",
      "[Epoch 3] Step 2640 | BCE Loss: 0.013400\n",
      "[Epoch 3] Step 2650 | BCE Loss: 0.010616\n",
      "[Epoch 3] Step 2660 | BCE Loss: 0.013154\n",
      "[Epoch 3] Step 2670 | BCE Loss: 0.028328\n",
      "[Epoch 3] Step 2680 | BCE Loss: 0.016983\n",
      "[Epoch 3] Step 2690 | BCE Loss: 0.020953\n",
      "[Epoch 3] Step 2700 | BCE Loss: 0.015205\n",
      "[Epoch 3] Step 2710 | BCE Loss: 0.015100\n",
      "[Epoch 3] Step 2720 | BCE Loss: 0.016644\n",
      "[Epoch 3] Step 2730 | BCE Loss: 0.013710\n",
      "[Epoch 3] Step 2740 | BCE Loss: 0.021948\n",
      "[Epoch 3] Step 2750 | BCE Loss: 0.015146\n",
      "[Epoch 3] Step 2760 | BCE Loss: 0.022363\n",
      "[Epoch 3] Step 2770 | BCE Loss: 0.022162\n",
      "[Epoch 3] Step 2780 | BCE Loss: 0.031013\n",
      "[Epoch 3] Step 2790 | BCE Loss: 0.014327\n",
      "[Epoch 3] Step 2800 | BCE Loss: 0.010784\n",
      "[Epoch 3] Step 2810 | BCE Loss: 0.017237\n",
      "[Epoch 3] Step 2820 | BCE Loss: 0.015780\n",
      "[Epoch 3] Step 2830 | BCE Loss: 0.018045\n",
      "[Epoch 3] Step 2840 | BCE Loss: 0.016009\n",
      "[Epoch 3] Step 2850 | BCE Loss: 0.021784\n",
      "[Epoch 3] Step 2860 | BCE Loss: 0.014761\n",
      "[Epoch 3] Step 2870 | BCE Loss: 0.022593\n",
      "[Epoch 3] Step 2880 | BCE Loss: 0.013611\n",
      "[Epoch 3] Step 2890 | BCE Loss: 0.015332\n",
      "[Epoch 3] Step 2900 | BCE Loss: 0.013370\n",
      "[Epoch 3] Step 2910 | BCE Loss: 0.014546\n",
      "[Epoch 3] Step 2920 | BCE Loss: 0.015955\n",
      "[Epoch 3] Step 2930 | BCE Loss: 0.018286\n",
      "[Epoch 3] Step 2940 | BCE Loss: 0.011547\n",
      "[Epoch 3] Step 2950 | BCE Loss: 0.020792\n",
      "[Epoch 3] Step 2960 | BCE Loss: 0.012977\n",
      "[Epoch 3] Step 2970 | BCE Loss: 0.029750\n",
      "[Epoch 3] Step 2980 | BCE Loss: 0.020239\n",
      "[Epoch 3] Step 2990 | BCE Loss: 0.016478\n",
      "[Epoch 3] Step 3000 | BCE Loss: 0.028070\n",
      "[Epoch 3] Step 3010 | BCE Loss: 0.014734\n",
      "[Epoch 3] Step 3020 | BCE Loss: 0.018588\n",
      "[Epoch 3] Step 3030 | BCE Loss: 0.010815\n",
      "[Epoch 3] Step 3040 | BCE Loss: 0.014156\n",
      "[Epoch 3] Step 3050 | BCE Loss: 0.017241\n",
      "[Epoch 3] Step 3060 | BCE Loss: 0.021010\n",
      "[Epoch 3] Step 3070 | BCE Loss: 0.014414\n",
      "[Epoch 3] Step 3080 | BCE Loss: 0.018394\n",
      "[Epoch 3] Step 3090 | BCE Loss: 0.018141\n",
      "[Epoch 3] Step 3100 | BCE Loss: 0.009272\n",
      "[Epoch 3] Step 3110 | BCE Loss: 0.014938\n",
      "[Epoch 3] Step 3120 | BCE Loss: 0.016765\n",
      "[Epoch 3] Step 3130 | BCE Loss: 0.025083\n",
      "[Epoch 3] Step 3140 | BCE Loss: 0.018346\n",
      "[Epoch 3] Step 3150 | BCE Loss: 0.017381\n",
      "[Epoch 3] Step 3160 | BCE Loss: 0.018550\n",
      "[Epoch 3] Step 3170 | BCE Loss: 0.046157\n",
      "[Epoch 3] Step 3180 | BCE Loss: 0.015346\n",
      "[Epoch 3] Step 3190 | BCE Loss: 0.018392\n",
      "[Epoch 3] Step 3200 | BCE Loss: 0.013988\n",
      "[Epoch 3] Step 3210 | BCE Loss: 0.017445\n",
      "[Epoch 3] Step 3220 | BCE Loss: 0.017980\n",
      "[Epoch 3] Step 3230 | BCE Loss: 0.013788\n",
      "[Epoch 3] Step 3240 | BCE Loss: 0.018360\n",
      "[Epoch 3] Step 3250 | BCE Loss: 0.012962\n",
      "[Epoch 3] Step 3260 | BCE Loss: 0.013214\n",
      "[Epoch 3] Step 3270 | BCE Loss: 0.020207\n",
      "[Epoch 3] Step 3280 | BCE Loss: 0.014632\n",
      "[Epoch 3] Step 3290 | BCE Loss: 0.013471\n",
      "[Epoch 3] Step 3300 | BCE Loss: 0.017361\n",
      "[Epoch 3] Step 3310 | BCE Loss: 0.017963\n",
      "[Epoch 3] Step 3320 | BCE Loss: 0.017903\n",
      "[Epoch 3] Step 3330 | BCE Loss: 0.015007\n",
      "[Epoch 3] Step 3340 | BCE Loss: 0.018873\n",
      "[Epoch 3] Step 3350 | BCE Loss: 0.016716\n",
      "[Epoch 3] Step 3360 | BCE Loss: 0.015146\n",
      "[Epoch 3] Step 3370 | BCE Loss: 0.013252\n",
      "[Epoch 3] Step 3380 | BCE Loss: 0.021972\n",
      "[Epoch 3] Step 3390 | BCE Loss: 0.017516\n",
      "[Epoch 3] Step 3400 | BCE Loss: 0.012406\n",
      "[Epoch 3] Step 3410 | BCE Loss: 0.020151\n",
      "[Epoch 3] Step 3420 | BCE Loss: 0.010220\n",
      "[Epoch 3] Step 3430 | BCE Loss: 0.019081\n",
      "[Epoch 3] Step 3440 | BCE Loss: 0.016340\n",
      "[Epoch 3] Step 3450 | BCE Loss: 0.015887\n",
      "[Epoch 3] Step 3460 | BCE Loss: 0.021619\n",
      "[Epoch 3] Step 3470 | BCE Loss: 0.015994\n",
      "[Epoch 3] Step 3480 | BCE Loss: 0.019928\n",
      "[Epoch 3] Step 3490 | BCE Loss: 0.019825\n",
      "[Epoch 3] Step 3500 | BCE Loss: 0.016468\n",
      "[Epoch 3] Step 3510 | BCE Loss: 0.018762\n",
      "[Epoch 3] Step 3520 | BCE Loss: 0.011913\n",
      "[Epoch 3] Step 3530 | BCE Loss: 0.017565\n",
      "[Epoch 3] Step 3540 | BCE Loss: 0.010844\n",
      "[Epoch 3] Step 3550 | BCE Loss: 0.014280\n",
      "[Epoch 3] Step 3560 | BCE Loss: 0.013810\n",
      "[Epoch 3] Step 3570 | BCE Loss: 0.025479\n",
      "[Epoch 3] Step 3580 | BCE Loss: 0.012814\n",
      "[Epoch 3] Step 3590 | BCE Loss: 0.018906\n",
      "[Epoch 3] Step 3600 | BCE Loss: 0.017129\n",
      "[Epoch 3] Step 3610 | BCE Loss: 0.011878\n",
      "[Epoch 3] Step 3620 | BCE Loss: 0.013571\n",
      "[Epoch 3] Step 3630 | BCE Loss: 0.010859\n",
      "[Epoch 3] Step 3640 | BCE Loss: 0.014728\n",
      "[Epoch 3] Step 3650 | BCE Loss: 0.012711\n",
      "[Epoch 3] Step 3660 | BCE Loss: 0.018138\n",
      "[Epoch 3] Step 3670 | BCE Loss: 0.025790\n",
      "[Epoch 3] Step 3680 | BCE Loss: 0.013856\n",
      "[Epoch 3] Step 3690 | BCE Loss: 0.016078\n",
      "[Epoch 3] Step 3700 | BCE Loss: 0.024451\n",
      "[Epoch 3] Step 3710 | BCE Loss: 0.013545\n",
      "[Epoch 3] Step 3720 | BCE Loss: 0.016029\n",
      "[Epoch 3] Step 3730 | BCE Loss: 0.012660\n",
      "[Epoch 3] Step 3740 | BCE Loss: 0.015983\n",
      "[Epoch 3] Step 3750 | BCE Loss: 0.013947\n",
      "[Epoch 3] Step 3760 | BCE Loss: 0.018205\n",
      "[Epoch 3] Step 3770 | BCE Loss: 0.016671\n",
      "[Epoch 3] Step 3780 | BCE Loss: 0.022230\n",
      "[Epoch 3] Step 3790 | BCE Loss: 0.011962\n",
      "[Epoch 3] Step 3800 | BCE Loss: 0.013628\n",
      "[Epoch 3] Step 3810 | BCE Loss: 0.017275\n",
      "[Epoch 3] Step 3820 | BCE Loss: 0.024417\n",
      "[Epoch 3] Step 3830 | BCE Loss: 0.017443\n",
      "[Epoch 3] Step 3840 | BCE Loss: 0.015872\n",
      "[Epoch 3] Step 3850 | BCE Loss: 0.023305\n",
      "[Epoch 3] Step 3860 | BCE Loss: 0.028962\n",
      "[Epoch 3] Step 3870 | BCE Loss: 0.017136\n",
      "[Epoch 3] Step 3880 | BCE Loss: 0.014371\n",
      "[Epoch 3] Step 3890 | BCE Loss: 0.022579\n",
      "[Epoch 3] Step 3900 | BCE Loss: 0.018650\n",
      "[Epoch 3] Step 3910 | BCE Loss: 0.012896\n",
      "[Epoch 3] Step 3920 | BCE Loss: 0.014580\n",
      "[Epoch 3] Step 3930 | BCE Loss: 0.015061\n",
      "[Epoch 3] Step 3940 | BCE Loss: 0.017039\n",
      "[Epoch 3] Step 3950 | BCE Loss: 0.021699\n",
      "[Epoch 3] Step 3960 | BCE Loss: 0.015877\n",
      "[Epoch 3] Step 3970 | BCE Loss: 0.011151\n",
      "[Epoch 3] Step 3980 | BCE Loss: 0.013930\n",
      "[Epoch 3] Step 3990 | BCE Loss: 0.012122\n",
      "[Epoch 3] Step 4000 | BCE Loss: 0.018285\n",
      "[Epoch 3] Step 4010 | BCE Loss: 0.019544\n",
      "[Epoch 3] Step 4020 | BCE Loss: 0.013728\n",
      "[Epoch 3] Step 4030 | BCE Loss: 0.018050\n",
      "[Epoch 3] Step 4040 | BCE Loss: 0.015325\n",
      "[Epoch 3] Step 4050 | BCE Loss: 0.013558\n",
      "[Epoch 3] Step 4060 | BCE Loss: 0.013238\n",
      "[Epoch 3] Step 4070 | BCE Loss: 0.013564\n",
      "[Epoch 3] Step 4080 | BCE Loss: 0.020046\n",
      "[Epoch 3] Step 4090 | BCE Loss: 0.026210\n",
      "[Epoch 3] Step 4100 | BCE Loss: 0.011845\n",
      "[Epoch 3] Step 4110 | BCE Loss: 0.019882\n",
      "[Epoch 3] Step 4120 | BCE Loss: 0.015488\n",
      "[Epoch 3] Step 4130 | BCE Loss: 0.012116\n",
      "[Epoch 3] Step 4140 | BCE Loss: 0.017574\n",
      "[Epoch 3] Step 4150 | BCE Loss: 0.020577\n",
      "[Epoch 3] Step 4160 | BCE Loss: 0.011403\n",
      "[Epoch 3] Step 4170 | BCE Loss: 0.015498\n",
      "[Epoch 3] Step 4180 | BCE Loss: 0.017935\n",
      "[Epoch 3] Step 4190 | BCE Loss: 0.018734\n",
      "[Epoch 3] Step 4200 | BCE Loss: 0.015470\n",
      "[Epoch 3] Step 4210 | BCE Loss: 0.019920\n",
      "[Epoch 3] Step 4220 | BCE Loss: 0.012582\n",
      "[Epoch 3] Step 4230 | BCE Loss: 0.013137\n",
      "[Epoch 3] Step 4240 | BCE Loss: 0.015559\n",
      "[Epoch 3] Step 4250 | BCE Loss: 0.014112\n",
      "[Epoch 3] Step 4260 | BCE Loss: 0.014556\n",
      "[Epoch 3] Step 4270 | BCE Loss: 0.009670\n",
      "[Epoch 3] Step 4280 | BCE Loss: 0.022655\n",
      "[Epoch 3] Step 4290 | BCE Loss: 0.015962\n",
      "[Epoch 3] Step 4300 | BCE Loss: 0.011210\n",
      "[Epoch 3] Step 4310 | BCE Loss: 0.014147\n",
      "[Epoch 3] Step 4320 | BCE Loss: 0.015571\n",
      "[Epoch 3] Step 4330 | BCE Loss: 0.016571\n",
      "[Epoch 3] Step 4340 | BCE Loss: 0.018238\n",
      "[Epoch 3] Step 4350 | BCE Loss: 0.011708\n",
      "[Epoch 3] Step 4360 | BCE Loss: 0.011797\n",
      "[Epoch 3] Step 4370 | BCE Loss: 0.019147\n",
      "[Epoch 3] Step 4380 | BCE Loss: 0.015428\n",
      "[Epoch 3] Step 4390 | BCE Loss: 0.013436\n",
      "[Epoch 3] Step 4400 | BCE Loss: 0.015930\n",
      "[Epoch 3] Step 4410 | BCE Loss: 0.014403\n",
      "[Epoch 3] Step 4420 | BCE Loss: 0.015488\n",
      "[Epoch 3] Step 4430 | BCE Loss: 0.016226\n",
      "[Epoch 3] Step 4440 | BCE Loss: 0.013162\n",
      "[Epoch 3] Step 4450 | BCE Loss: 0.012953\n",
      "[Epoch 3] Step 4460 | BCE Loss: 0.017506\n",
      "[Epoch 3] Step 4470 | BCE Loss: 0.014223\n",
      "[Epoch 3] Step 4480 | BCE Loss: 0.016307\n",
      "[Epoch 3] Step 4490 | BCE Loss: 0.014233\n",
      "[Epoch 3] Step 4500 | BCE Loss: 0.019468\n",
      "[Epoch 3] Step 4510 | BCE Loss: 0.015606\n",
      "[Epoch 3] Step 4520 | BCE Loss: 0.020902\n",
      "[Epoch 3] Step 4530 | BCE Loss: 0.013925\n",
      "[Epoch 3] Step 4540 | BCE Loss: 0.012622\n",
      "[Epoch 3] Step 4550 | BCE Loss: 0.012431\n",
      "[Epoch 3] Step 4560 | BCE Loss: 0.011941\n",
      "[Epoch 3] Step 4570 | BCE Loss: 0.013370\n",
      "[Epoch 3] Step 4580 | BCE Loss: 0.020510\n",
      "[Epoch 3] Step 4590 | BCE Loss: 0.010277\n",
      "[Epoch 3] Step 4600 | BCE Loss: 0.012839\n",
      "[Epoch 3] Step 4610 | BCE Loss: 0.020270\n",
      "[Epoch 3] Step 4620 | BCE Loss: 0.015738\n",
      "[Epoch 3] Step 4630 | BCE Loss: 0.012672\n",
      "[Epoch 3] Step 4640 | BCE Loss: 0.015742\n",
      "[Epoch 3] Step 4650 | BCE Loss: 0.012722\n",
      "[Epoch 3] Step 4660 | BCE Loss: 0.012710\n",
      "[Epoch 3] Step 4670 | BCE Loss: 0.012979\n",
      "[Epoch 3] Step 4680 | BCE Loss: 0.021398\n",
      "[Epoch 3] Step 4690 | BCE Loss: 0.020637\n",
      "[Epoch 3] Step 4700 | BCE Loss: 0.018554\n",
      "[Epoch 3] Step 4710 | BCE Loss: 0.022195\n",
      "[Epoch 3] Step 4720 | BCE Loss: 0.015436\n",
      "[Epoch 3] Step 4730 | BCE Loss: 0.014965\n",
      "[Epoch 3] Step 4740 | BCE Loss: 0.014033\n",
      "[Epoch 3] Step 4750 | BCE Loss: 0.042262\n",
      "[Epoch 3] Step 4760 | BCE Loss: 0.014326\n",
      "[Epoch 3] Step 4770 | BCE Loss: 0.015806\n",
      "[Epoch 3] Step 4780 | BCE Loss: 0.011048\n",
      "[Epoch 3] Step 4790 | BCE Loss: 0.022145\n",
      "[Epoch 3] Step 4800 | BCE Loss: 0.019416\n",
      "[Epoch 3] Step 4810 | BCE Loss: 0.014783\n",
      "[Epoch 3] Step 4820 | BCE Loss: 0.017779\n",
      "[Epoch 3] Step 4830 | BCE Loss: 0.015468\n",
      "[Epoch 3] Step 4840 | BCE Loss: 0.020398\n",
      "[Epoch 3] Step 4850 | BCE Loss: 0.015631\n",
      "[Epoch 3] Step 4860 | BCE Loss: 0.016580\n",
      "[Epoch 3] Step 4870 | BCE Loss: 0.015507\n",
      "[Epoch 3] Step 4880 | BCE Loss: 0.011139\n",
      "[Epoch 3] Step 4890 | BCE Loss: 0.013030\n",
      "[Epoch 3] Step 4900 | BCE Loss: 0.030512\n",
      "[Epoch 3] Step 4910 | BCE Loss: 0.013580\n",
      "[Epoch 3] Step 4920 | BCE Loss: 0.014597\n",
      "[Epoch 3] Step 4930 | BCE Loss: 0.018474\n",
      "[Epoch 3] Step 4940 | BCE Loss: 0.016618\n",
      "[Epoch 3] Step 4950 | BCE Loss: 0.014654\n",
      "[Epoch 3] Step 4960 | BCE Loss: 0.020176\n",
      "[Epoch 3] Step 4970 | BCE Loss: 0.018462\n",
      "[Epoch 3] Step 4980 | BCE Loss: 0.014218\n",
      "[Epoch 3] Step 4990 | BCE Loss: 0.009939\n",
      "[Epoch 3] Step 5000 | BCE Loss: 0.012574\n",
      "[Epoch 3] Step 5010 | BCE Loss: 0.017788\n",
      "[Epoch 3] Step 5020 | BCE Loss: 0.018738\n",
      "[Epoch 3] Step 5030 | BCE Loss: 0.016065\n",
      "[Epoch 3] Step 5040 | BCE Loss: 0.009829\n",
      "[Epoch 3] Step 5050 | BCE Loss: 0.010824\n",
      "[Epoch 3] Step 5060 | BCE Loss: 0.013118\n",
      "[Epoch 3] Step 5070 | BCE Loss: 0.012713\n",
      "[Epoch 3] Step 5080 | BCE Loss: 0.018296\n",
      "[Epoch 3] Step 5090 | BCE Loss: 0.011422\n",
      "[Epoch 3] Step 5100 | BCE Loss: 0.018337\n",
      "[Epoch 3] Step 5110 | BCE Loss: 0.073803\n",
      "[Epoch 3] Step 5120 | BCE Loss: 0.029657\n",
      "[Epoch 3] Step 5130 | BCE Loss: 0.014917\n",
      "[Epoch 3] Step 5140 | BCE Loss: 0.016159\n",
      "[Epoch 3] Step 5150 | BCE Loss: 0.015240\n",
      "[Epoch 3] Step 5160 | BCE Loss: 0.016272\n",
      "[Epoch 3] Step 5170 | BCE Loss: 0.014297\n",
      "[Epoch 3] Step 5180 | BCE Loss: 0.026136\n",
      "[Epoch 3] Step 5190 | BCE Loss: 0.010945\n",
      "[Epoch 3] Step 5200 | BCE Loss: 0.011075\n",
      "[Epoch 3] Step 5210 | BCE Loss: 0.017678\n",
      "[Epoch 3] Step 5220 | BCE Loss: 0.010169\n",
      "[Epoch 3] Step 5230 | BCE Loss: 0.012888\n",
      "[Epoch 3] Step 5240 | BCE Loss: 0.012663\n",
      "[Epoch 3] Step 5250 | BCE Loss: 0.010872\n",
      "[Epoch 3] Step 5260 | BCE Loss: 0.012604\n",
      "[Epoch 3] Step 5270 | BCE Loss: 0.013382\n",
      "[Epoch 3] Step 5280 | BCE Loss: 0.018885\n",
      "[Epoch 3] Step 5290 | BCE Loss: 0.017290\n",
      "[Epoch 3] Step 5300 | BCE Loss: 0.012563\n",
      "[Epoch 3] Step 5310 | BCE Loss: 0.024115\n",
      "[Epoch 3] Step 5320 | BCE Loss: 0.027330\n",
      "[Epoch 3] Step 5330 | BCE Loss: 0.014405\n",
      "[Epoch 3] Step 5340 | BCE Loss: 0.020342\n",
      "[Epoch 3] Step 5350 | BCE Loss: 0.013065\n",
      "[Epoch 3] Step 5360 | BCE Loss: 0.012375\n",
      "[Epoch 3] Step 5370 | BCE Loss: 0.012124\n",
      "[Epoch 3] Step 5380 | BCE Loss: 0.017396\n",
      "[Epoch 3] Step 5390 | BCE Loss: 0.013885\n",
      "[Epoch 3] Step 5400 | BCE Loss: 0.020296\n",
      "[Epoch 3] Step 5410 | BCE Loss: 0.024861\n",
      "[Epoch 3] Step 5420 | BCE Loss: 0.012626\n",
      "[Epoch 3] Step 5430 | BCE Loss: 0.013775\n",
      "[Epoch 3] Step 5440 | BCE Loss: 0.014370\n",
      "[Epoch 3] Step 5450 | BCE Loss: 0.019484\n",
      "[Epoch 3] Step 5460 | BCE Loss: 0.018569\n",
      "[Epoch 3] Step 5470 | BCE Loss: 0.013114\n",
      "[Epoch 3] Step 5480 | BCE Loss: 0.020300\n",
      "[Epoch 3] Step 5490 | BCE Loss: 0.013652\n",
      "[Epoch 3] Step 5500 | BCE Loss: 0.022961\n",
      "[Epoch 3] Step 5510 | BCE Loss: 0.011586\n",
      "[Epoch 3] Step 5520 | BCE Loss: 0.010768\n",
      "[Epoch 3] Step 5530 | BCE Loss: 0.011204\n",
      "[Epoch 3] Step 5540 | BCE Loss: 0.018859\n",
      "[Epoch 3] Step 5550 | BCE Loss: 0.014212\n",
      "[Epoch 3] Step 5560 | BCE Loss: 0.010572\n",
      "[Epoch 3] Step 5570 | BCE Loss: 0.017050\n",
      "[Epoch 3] Step 5580 | BCE Loss: 0.013302\n",
      "[Epoch 3] Step 5590 | BCE Loss: 0.013230\n",
      "[Epoch 3] Step 5600 | BCE Loss: 0.011649\n",
      "[Epoch 3] Step 5610 | BCE Loss: 0.014880\n",
      "[Epoch 3] Step 5620 | BCE Loss: 0.017365\n",
      "[Epoch 3] Step 5630 | BCE Loss: 0.012572\n",
      "[Epoch 3] Step 5640 | BCE Loss: 0.033776\n",
      "[Epoch 3] Step 5650 | BCE Loss: 0.013795\n",
      "[Epoch 3] Step 5660 | BCE Loss: 0.015746\n",
      "[Epoch 3] Step 5670 | BCE Loss: 0.017804\n",
      "[Epoch 3] Step 5680 | BCE Loss: 0.015987\n",
      "[Epoch 3] Step 5690 | BCE Loss: 0.013926\n",
      "[Epoch 3] Step 5700 | BCE Loss: 0.038305\n",
      "[Epoch 3] Step 5710 | BCE Loss: 0.084282\n",
      "[Epoch 3] Step 5720 | BCE Loss: 0.014761\n",
      "[Epoch 3] Step 5730 | BCE Loss: 0.017945\n",
      "[Epoch 3] Step 5740 | BCE Loss: 0.014113\n",
      "[Epoch 3] Step 5750 | BCE Loss: 0.015310\n",
      "[Epoch 3] Step 5760 | BCE Loss: 0.010889\n",
      "[Epoch 3] Step 5770 | BCE Loss: 0.012160\n",
      "[Epoch 3] Step 5780 | BCE Loss: 0.011593\n",
      "[Epoch 3] Step 5790 | BCE Loss: 0.012183\n",
      "[Epoch 3] Step 5800 | BCE Loss: 0.014258\n",
      "[Epoch 3] Step 5810 | BCE Loss: 0.040387\n",
      "[Epoch 3] Step 5820 | BCE Loss: 0.044021\n",
      "\n",
      "=== Epoch 3 Selesai | Avg BCE Loss: 0.017906 ===\n",
      "[SAVE] Merging weights and saving single .pth file...\n",
      "[SAVE] Full PEFT checkpoint saved to: /kaggle/working/output/sam2_finetuned.pth\n",
      "\n",
      "[Epoch 4/5]\n",
      "[Epoch 4] Step 0 | BCE Loss: 0.015467\n",
      "[Epoch 4] Step 10 | BCE Loss: 0.011545\n",
      "[Epoch 4] Step 20 | BCE Loss: 0.014981\n",
      "[Epoch 4] Step 30 | BCE Loss: 0.015543\n",
      "[Epoch 4] Step 40 | BCE Loss: 0.027451\n",
      "[Epoch 4] Step 50 | BCE Loss: 0.022374\n",
      "[Epoch 4] Step 60 | BCE Loss: 0.015301\n",
      "[Epoch 4] Step 70 | BCE Loss: 0.018898\n",
      "[Epoch 4] Step 80 | BCE Loss: 0.019272\n",
      "[Epoch 4] Step 90 | BCE Loss: 0.015076\n",
      "[Epoch 4] Step 100 | BCE Loss: 0.013154\n",
      "[Epoch 4] Step 110 | BCE Loss: 0.018358\n",
      "[Epoch 4] Step 120 | BCE Loss: 0.018591\n",
      "[Epoch 4] Step 130 | BCE Loss: 0.013063\n",
      "[Epoch 4] Step 140 | BCE Loss: 0.023095\n",
      "[Epoch 4] Step 150 | BCE Loss: 0.011963\n",
      "[Epoch 4] Step 160 | BCE Loss: 0.016995\n",
      "[Epoch 4] Step 170 | BCE Loss: 0.016531\n",
      "[Epoch 4] Step 180 | BCE Loss: 0.017069\n",
      "[Epoch 4] Step 190 | BCE Loss: 0.016704\n",
      "[Epoch 4] Step 200 | BCE Loss: 0.014350\n",
      "[Epoch 4] Step 210 | BCE Loss: 0.014445\n",
      "[Epoch 4] Step 220 | BCE Loss: 0.017660\n",
      "[Epoch 4] Step 230 | BCE Loss: 0.019477\n",
      "[Epoch 4] Step 240 | BCE Loss: 0.012674\n",
      "[Epoch 4] Step 250 | BCE Loss: 0.013435\n",
      "[Epoch 4] Step 260 | BCE Loss: 0.016166\n",
      "[Epoch 4] Step 270 | BCE Loss: 0.015470\n",
      "[Epoch 4] Step 280 | BCE Loss: 0.021260\n",
      "[Epoch 4] Step 290 | BCE Loss: 0.016961\n",
      "[Epoch 4] Step 300 | BCE Loss: 0.015963\n",
      "[Epoch 4] Step 310 | BCE Loss: 0.022545\n",
      "[Epoch 4] Step 320 | BCE Loss: 0.027601\n",
      "[Epoch 4] Step 330 | BCE Loss: 0.013086\n",
      "[Epoch 4] Step 340 | BCE Loss: 0.015915\n",
      "[Epoch 4] Step 350 | BCE Loss: 0.017951\n",
      "[Epoch 4] Step 360 | BCE Loss: 0.012841\n",
      "[Epoch 4] Step 370 | BCE Loss: 0.012679\n",
      "[Epoch 4] Step 380 | BCE Loss: 0.011449\n",
      "[Epoch 4] Step 390 | BCE Loss: 0.030307\n",
      "[Epoch 4] Step 400 | BCE Loss: 0.014351\n",
      "[Epoch 4] Step 410 | BCE Loss: 0.010541\n",
      "[Epoch 4] Step 420 | BCE Loss: 0.016576\n",
      "[Epoch 4] Step 430 | BCE Loss: 0.013424\n",
      "[Epoch 4] Step 440 | BCE Loss: 0.016717\n",
      "[Epoch 4] Step 450 | BCE Loss: 0.015039\n",
      "[Epoch 4] Step 460 | BCE Loss: 0.013714\n",
      "[Epoch 4] Step 470 | BCE Loss: 0.013832\n",
      "[Epoch 4] Step 480 | BCE Loss: 0.018188\n",
      "[Epoch 4] Step 490 | BCE Loss: 0.042494\n",
      "[Epoch 4] Step 500 | BCE Loss: 0.014731\n",
      "[Epoch 4] Step 510 | BCE Loss: 0.015767\n",
      "[Epoch 4] Step 520 | BCE Loss: 0.009902\n",
      "[Epoch 4] Step 530 | BCE Loss: 0.014733\n",
      "[Epoch 4] Step 540 | BCE Loss: 0.011759\n",
      "[Epoch 4] Step 550 | BCE Loss: 0.014091\n",
      "[Epoch 4] Step 560 | BCE Loss: 0.034096\n",
      "[Epoch 4] Step 570 | BCE Loss: 0.016093\n",
      "[Epoch 4] Step 580 | BCE Loss: 0.026181\n",
      "[Epoch 4] Step 590 | BCE Loss: 0.014177\n",
      "[Epoch 4] Step 600 | BCE Loss: 0.016601\n",
      "[Epoch 4] Step 610 | BCE Loss: 0.021240\n",
      "[Epoch 4] Step 620 | BCE Loss: 0.016925\n",
      "[Epoch 4] Step 630 | BCE Loss: 0.019181\n",
      "[Epoch 4] Step 640 | BCE Loss: 0.013362\n",
      "[Epoch 4] Step 650 | BCE Loss: 0.014842\n",
      "[Epoch 4] Step 660 | BCE Loss: 0.019506\n",
      "[Epoch 4] Step 670 | BCE Loss: 0.018534\n",
      "[Epoch 4] Step 680 | BCE Loss: 0.017319\n",
      "[Epoch 4] Step 690 | BCE Loss: 0.015781\n",
      "[Epoch 4] Step 700 | BCE Loss: 0.014262\n",
      "[Epoch 4] Step 710 | BCE Loss: 0.011084\n",
      "[Epoch 4] Step 720 | BCE Loss: 0.015356\n",
      "[Epoch 4] Step 730 | BCE Loss: 0.014857\n",
      "[Epoch 4] Step 740 | BCE Loss: 0.018456\n",
      "[Epoch 4] Step 750 | BCE Loss: 0.012909\n",
      "[Epoch 4] Step 760 | BCE Loss: 0.026257\n",
      "[Epoch 4] Step 770 | BCE Loss: 0.011327\n",
      "[Epoch 4] Step 780 | BCE Loss: 0.011566\n",
      "[Epoch 4] Step 790 | BCE Loss: 0.016048\n",
      "[Epoch 4] Step 800 | BCE Loss: 0.015328\n",
      "[Epoch 4] Step 810 | BCE Loss: 0.017190\n",
      "[Epoch 4] Step 820 | BCE Loss: 0.015242\n",
      "[Epoch 4] Step 830 | BCE Loss: 0.024361\n",
      "[Epoch 4] Step 840 | BCE Loss: 0.015633\n",
      "[Epoch 4] Step 850 | BCE Loss: 0.015368\n",
      "[Epoch 4] Step 860 | BCE Loss: 0.016895\n",
      "[Epoch 4] Step 870 | BCE Loss: 0.013556\n",
      "[Epoch 4] Step 880 | BCE Loss: 0.034652\n",
      "[Epoch 4] Step 890 | BCE Loss: 0.013014\n",
      "[Epoch 4] Step 900 | BCE Loss: 0.019236\n",
      "[Epoch 4] Step 910 | BCE Loss: 0.013794\n",
      "[Epoch 4] Step 920 | BCE Loss: 0.033041\n",
      "[Epoch 4] Step 930 | BCE Loss: 0.015841\n",
      "[Epoch 4] Step 940 | BCE Loss: 0.012163\n",
      "[Epoch 4] Step 950 | BCE Loss: 0.022267\n",
      "[Epoch 4] Step 960 | BCE Loss: 0.014401\n",
      "[Epoch 4] Step 970 | BCE Loss: 0.017770\n",
      "[Epoch 4] Step 980 | BCE Loss: 0.018006\n",
      "[Epoch 4] Step 990 | BCE Loss: 0.012057\n",
      "[Epoch 4] Step 1000 | BCE Loss: 0.015135\n",
      "[Epoch 4] Step 1010 | BCE Loss: 0.021017\n",
      "[Epoch 4] Step 1020 | BCE Loss: 0.013127\n",
      "[Epoch 4] Step 1030 | BCE Loss: 0.017721\n",
      "[Epoch 4] Step 1040 | BCE Loss: 0.023679\n",
      "[Epoch 4] Step 1050 | BCE Loss: 0.013698\n",
      "[Epoch 4] Step 1060 | BCE Loss: 0.013405\n",
      "[Epoch 4] Step 1070 | BCE Loss: 0.013355\n",
      "[Epoch 4] Step 1080 | BCE Loss: 0.015590\n",
      "[Epoch 4] Step 1090 | BCE Loss: 0.014458\n",
      "[Epoch 4] Step 1100 | BCE Loss: 0.021808\n",
      "[Epoch 4] Step 1110 | BCE Loss: 0.015812\n",
      "[Epoch 4] Step 1120 | BCE Loss: 0.013420\n",
      "[Epoch 4] Step 1130 | BCE Loss: 0.015294\n",
      "[Epoch 4] Step 1140 | BCE Loss: 0.010250\n",
      "[Epoch 4] Step 1150 | BCE Loss: 0.015869\n",
      "[Epoch 4] Step 1160 | BCE Loss: 0.017791\n",
      "[Epoch 4] Step 1170 | BCE Loss: 0.013449\n",
      "[Epoch 4] Step 1180 | BCE Loss: 0.014805\n",
      "[Epoch 4] Step 1190 | BCE Loss: 0.016133\n",
      "[Epoch 4] Step 1200 | BCE Loss: 0.024245\n",
      "[Epoch 4] Step 1210 | BCE Loss: 0.017050\n",
      "[Epoch 4] Step 1220 | BCE Loss: 0.015972\n",
      "[Epoch 4] Step 1230 | BCE Loss: 0.022799\n",
      "[Epoch 4] Step 1240 | BCE Loss: 0.012774\n",
      "[Epoch 4] Step 1250 | BCE Loss: 0.016617\n",
      "[Epoch 4] Step 1260 | BCE Loss: 0.014491\n",
      "[Epoch 4] Step 1270 | BCE Loss: 0.013993\n",
      "[Epoch 4] Step 1280 | BCE Loss: 0.015915\n",
      "[Epoch 4] Step 1290 | BCE Loss: 0.018643\n",
      "[Epoch 4] Step 1300 | BCE Loss: 0.014821\n",
      "[Epoch 4] Step 1310 | BCE Loss: 0.017632\n",
      "[Epoch 4] Step 1320 | BCE Loss: 0.028329\n",
      "[Epoch 4] Step 1330 | BCE Loss: 0.010212\n",
      "[Epoch 4] Step 1340 | BCE Loss: 0.014711\n",
      "[Epoch 4] Step 1350 | BCE Loss: 0.022154\n",
      "[Epoch 4] Step 1360 | BCE Loss: 0.013891\n",
      "[Epoch 4] Step 1370 | BCE Loss: 0.016010\n",
      "[Epoch 4] Step 1380 | BCE Loss: 0.015191\n",
      "[Epoch 4] Step 1390 | BCE Loss: 0.013491\n",
      "[Epoch 4] Step 1400 | BCE Loss: 0.017022\n",
      "[Epoch 4] Step 1410 | BCE Loss: 0.015732\n",
      "[Epoch 4] Step 1420 | BCE Loss: 0.013322\n",
      "[Epoch 4] Step 1430 | BCE Loss: 0.013459\n",
      "[Epoch 4] Step 1440 | BCE Loss: 0.012462\n",
      "[Epoch 4] Step 1450 | BCE Loss: 0.021602\n",
      "[Epoch 4] Step 1460 | BCE Loss: 0.016704\n",
      "[Epoch 4] Step 1470 | BCE Loss: 0.032309\n",
      "[Epoch 4] Step 1480 | BCE Loss: 0.010929\n",
      "[Epoch 4] Step 1490 | BCE Loss: 0.024422\n",
      "[Epoch 4] Step 1500 | BCE Loss: 0.012124\n",
      "[Epoch 4] Step 1510 | BCE Loss: 0.014964\n",
      "[Epoch 4] Step 1520 | BCE Loss: 0.011928\n",
      "[Epoch 4] Step 1530 | BCE Loss: 0.044374\n",
      "[Epoch 4] Step 1540 | BCE Loss: 0.032489\n",
      "[Epoch 4] Step 1550 | BCE Loss: 0.012053\n",
      "[Epoch 4] Step 1560 | BCE Loss: 0.015305\n",
      "[Epoch 4] Step 1570 | BCE Loss: 0.022101\n",
      "[Epoch 4] Step 1580 | BCE Loss: 0.020638\n",
      "[Epoch 4] Step 1590 | BCE Loss: 0.025161\n",
      "[Epoch 4] Step 1600 | BCE Loss: 0.015833\n",
      "[Epoch 4] Step 1610 | BCE Loss: 0.012207\n",
      "[Epoch 4] Step 1620 | BCE Loss: 0.013653\n",
      "[Epoch 4] Step 1630 | BCE Loss: 0.018062\n",
      "[Epoch 4] Step 1640 | BCE Loss: 0.015327\n",
      "[Epoch 4] Step 1650 | BCE Loss: 0.024274\n",
      "[Epoch 4] Step 1660 | BCE Loss: 0.012965\n",
      "[Epoch 4] Step 1670 | BCE Loss: 0.018471\n",
      "[Epoch 4] Step 1680 | BCE Loss: 0.020443\n",
      "[Epoch 4] Step 1690 | BCE Loss: 0.013902\n",
      "[Epoch 4] Step 1700 | BCE Loss: 0.012492\n",
      "[Epoch 4] Step 1710 | BCE Loss: 0.014519\n",
      "[Epoch 4] Step 1720 | BCE Loss: 0.010072\n",
      "[Epoch 4] Step 1730 | BCE Loss: 0.012292\n",
      "[Epoch 4] Step 1740 | BCE Loss: 0.013828\n",
      "[Epoch 4] Step 1750 | BCE Loss: 0.022300\n",
      "[Epoch 4] Step 1760 | BCE Loss: 0.017632\n",
      "[Epoch 4] Step 1770 | BCE Loss: 0.014481\n",
      "[Epoch 4] Step 1780 | BCE Loss: 0.012107\n",
      "[Epoch 4] Step 1790 | BCE Loss: 0.017980\n",
      "[Epoch 4] Step 1800 | BCE Loss: 0.008604\n",
      "[Epoch 4] Step 1810 | BCE Loss: 0.015606\n",
      "[Epoch 4] Step 1820 | BCE Loss: 0.014976\n",
      "[Epoch 4] Step 1830 | BCE Loss: 0.031807\n",
      "[Epoch 4] Step 1840 | BCE Loss: 0.022276\n",
      "[Epoch 4] Step 1850 | BCE Loss: 0.014455\n",
      "[Epoch 4] Step 1860 | BCE Loss: 0.012449\n",
      "[Epoch 4] Step 1870 | BCE Loss: 0.058595\n",
      "[Epoch 4] Step 1880 | BCE Loss: 0.015822\n",
      "[Epoch 4] Step 1890 | BCE Loss: 0.017578\n",
      "[Epoch 4] Step 1900 | BCE Loss: 0.013054\n",
      "[Epoch 4] Step 1910 | BCE Loss: 0.016421\n",
      "[Epoch 4] Step 1920 | BCE Loss: 0.015703\n",
      "[Epoch 4] Step 1930 | BCE Loss: 0.020248\n",
      "[Epoch 4] Step 1940 | BCE Loss: 0.016563\n",
      "[Epoch 4] Step 1950 | BCE Loss: 0.013690\n",
      "[Epoch 4] Step 1960 | BCE Loss: 0.009758\n",
      "[Epoch 4] Step 1970 | BCE Loss: 0.016720\n",
      "[Epoch 4] Step 1980 | BCE Loss: 0.013402\n",
      "[Epoch 4] Step 1990 | BCE Loss: 0.017434\n",
      "[Epoch 4] Step 2000 | BCE Loss: 0.035084\n",
      "[Epoch 4] Step 2010 | BCE Loss: 0.019874\n",
      "[Epoch 4] Step 2020 | BCE Loss: 0.020183\n",
      "[Epoch 4] Step 2030 | BCE Loss: 0.010056\n",
      "[Epoch 4] Step 2040 | BCE Loss: 0.018945\n",
      "[Epoch 4] Step 2050 | BCE Loss: 0.016686\n",
      "[Epoch 4] Step 2060 | BCE Loss: 0.016693\n",
      "[Epoch 4] Step 2070 | BCE Loss: 0.012849\n",
      "[Epoch 4] Step 2080 | BCE Loss: 0.012938\n",
      "[Epoch 4] Step 2090 | BCE Loss: 0.015676\n",
      "[Epoch 4] Step 2100 | BCE Loss: 0.013568\n",
      "[Epoch 4] Step 2110 | BCE Loss: 0.010661\n",
      "[Epoch 4] Step 2120 | BCE Loss: 0.016811\n",
      "[Epoch 4] Step 2130 | BCE Loss: 0.013742\n",
      "[Epoch 4] Step 2140 | BCE Loss: 0.012877\n",
      "[Epoch 4] Step 2150 | BCE Loss: 0.020900\n",
      "[Epoch 4] Step 2160 | BCE Loss: 0.011003\n",
      "[Epoch 4] Step 2170 | BCE Loss: 0.016551\n",
      "[Epoch 4] Step 2180 | BCE Loss: 0.016344\n",
      "[Epoch 4] Step 2190 | BCE Loss: 0.011927\n",
      "[Epoch 4] Step 2200 | BCE Loss: 0.023481\n",
      "[Epoch 4] Step 2210 | BCE Loss: 0.021685\n",
      "[Epoch 4] Step 2220 | BCE Loss: 0.010913\n",
      "[Epoch 4] Step 2230 | BCE Loss: 0.015543\n",
      "[Epoch 4] Step 2240 | BCE Loss: 0.020401\n",
      "[Epoch 4] Step 2250 | BCE Loss: 0.019239\n",
      "[Epoch 4] Step 2260 | BCE Loss: 0.025309\n",
      "[Epoch 4] Step 2270 | BCE Loss: 0.017181\n",
      "[Epoch 4] Step 2280 | BCE Loss: 0.010786\n",
      "[Epoch 4] Step 2290 | BCE Loss: 0.015775\n",
      "[Epoch 4] Step 2300 | BCE Loss: 0.015743\n",
      "[Epoch 4] Step 2310 | BCE Loss: 0.014748\n",
      "[Epoch 4] Step 2320 | BCE Loss: 0.028520\n",
      "[Epoch 4] Step 2330 | BCE Loss: 0.015031\n",
      "[Epoch 4] Step 2340 | BCE Loss: 0.012293\n",
      "[Epoch 4] Step 2350 | BCE Loss: 0.023132\n",
      "[Epoch 4] Step 2360 | BCE Loss: 0.013257\n",
      "[Epoch 4] Step 2370 | BCE Loss: 0.014491\n",
      "[Epoch 4] Step 2380 | BCE Loss: 0.012901\n",
      "[Epoch 4] Step 2390 | BCE Loss: 0.013641\n",
      "[Epoch 4] Step 2400 | BCE Loss: 0.016485\n",
      "[Epoch 4] Step 2410 | BCE Loss: 0.011849\n",
      "[Epoch 4] Step 2420 | BCE Loss: 0.025169\n",
      "[Epoch 4] Step 2430 | BCE Loss: 0.012123\n",
      "[Epoch 4] Step 2440 | BCE Loss: 0.019148\n",
      "[Epoch 4] Step 2450 | BCE Loss: 0.018753\n",
      "[Epoch 4] Step 2460 | BCE Loss: 0.013539\n",
      "[Epoch 4] Step 2470 | BCE Loss: 0.017031\n",
      "[Epoch 4] Step 2480 | BCE Loss: 0.014983\n",
      "[Epoch 4] Step 2490 | BCE Loss: 0.011574\n",
      "[Epoch 4] Step 2500 | BCE Loss: 0.015976\n",
      "[Epoch 4] Step 2510 | BCE Loss: 0.015742\n",
      "[Epoch 4] Step 2520 | BCE Loss: 0.018093\n",
      "[Epoch 4] Step 2530 | BCE Loss: 0.011012\n",
      "[Epoch 4] Step 2540 | BCE Loss: 0.011485\n",
      "[Epoch 4] Step 2550 | BCE Loss: 0.019597\n",
      "[Epoch 4] Step 2560 | BCE Loss: 0.014315\n",
      "[Epoch 4] Step 2570 | BCE Loss: 0.009832\n",
      "[Epoch 4] Step 2580 | BCE Loss: 0.014738\n",
      "[Epoch 4] Step 2590 | BCE Loss: 0.011999\n",
      "[Epoch 4] Step 2600 | BCE Loss: 0.010506\n",
      "[Epoch 4] Step 2610 | BCE Loss: 0.015877\n",
      "[Epoch 4] Step 2620 | BCE Loss: 0.011717\n",
      "[Epoch 4] Step 2630 | BCE Loss: 0.015041\n",
      "[Epoch 4] Step 2640 | BCE Loss: 0.020912\n",
      "[Epoch 4] Step 2650 | BCE Loss: 0.013302\n",
      "[Epoch 4] Step 2660 | BCE Loss: 0.014446\n",
      "[Epoch 4] Step 2670 | BCE Loss: 0.012222\n",
      "[Epoch 4] Step 2680 | BCE Loss: 0.025205\n",
      "[Epoch 4] Step 2690 | BCE Loss: 0.013175\n",
      "[Epoch 4] Step 2700 | BCE Loss: 0.027929\n",
      "[Epoch 4] Step 2710 | BCE Loss: 0.030277\n",
      "[Epoch 4] Step 2720 | BCE Loss: 0.013346\n",
      "[Epoch 4] Step 2730 | BCE Loss: 0.015710\n",
      "[Epoch 4] Step 2740 | BCE Loss: 0.012829\n",
      "[Epoch 4] Step 2750 | BCE Loss: 0.011865\n",
      "[Epoch 4] Step 2760 | BCE Loss: 0.019628\n",
      "[Epoch 4] Step 2770 | BCE Loss: 0.032018\n",
      "[Epoch 4] Step 2780 | BCE Loss: 0.016446\n",
      "[Epoch 4] Step 2790 | BCE Loss: 0.015273\n",
      "[Epoch 4] Step 2800 | BCE Loss: 0.014817\n",
      "[Epoch 4] Step 2810 | BCE Loss: 0.014747\n",
      "[Epoch 4] Step 2820 | BCE Loss: 0.012399\n",
      "[Epoch 4] Step 2830 | BCE Loss: 0.013712\n",
      "[Epoch 4] Step 2840 | BCE Loss: 0.011365\n",
      "[Epoch 4] Step 2850 | BCE Loss: 0.013113\n",
      "[Epoch 4] Step 2860 | BCE Loss: 0.015871\n",
      "[Epoch 4] Step 2870 | BCE Loss: 0.024328\n",
      "[Epoch 4] Step 2880 | BCE Loss: 0.009562\n",
      "[Epoch 4] Step 2890 | BCE Loss: 0.012506\n",
      "[Epoch 4] Step 2900 | BCE Loss: 0.010228\n",
      "[Epoch 4] Step 2910 | BCE Loss: 0.011359\n",
      "[Epoch 4] Step 2920 | BCE Loss: 0.011382\n",
      "[Epoch 4] Step 2930 | BCE Loss: 0.021531\n",
      "[Epoch 4] Step 2940 | BCE Loss: 0.015732\n",
      "[Epoch 4] Step 2950 | BCE Loss: 0.012750\n",
      "[Epoch 4] Step 2960 | BCE Loss: 0.016520\n",
      "[Epoch 4] Step 2970 | BCE Loss: 0.014038\n",
      "[Epoch 4] Step 2980 | BCE Loss: 0.015575\n",
      "[Epoch 4] Step 2990 | BCE Loss: 0.018828\n",
      "[Epoch 4] Step 3000 | BCE Loss: 0.024635\n",
      "[Epoch 4] Step 3010 | BCE Loss: 0.018835\n",
      "[Epoch 4] Step 3020 | BCE Loss: 0.014507\n",
      "[Epoch 4] Step 3030 | BCE Loss: 0.012359\n",
      "[Epoch 4] Step 3040 | BCE Loss: 0.015267\n",
      "[Epoch 4] Step 3050 | BCE Loss: 0.012546\n",
      "[Epoch 4] Step 3060 | BCE Loss: 0.015974\n",
      "[Epoch 4] Step 3070 | BCE Loss: 0.016734\n",
      "[Epoch 4] Step 3080 | BCE Loss: 0.018880\n",
      "[Epoch 4] Step 3090 | BCE Loss: 0.015035\n",
      "[Epoch 4] Step 3100 | BCE Loss: 0.024554\n",
      "[Epoch 4] Step 3110 | BCE Loss: 0.016470\n",
      "[Epoch 4] Step 3120 | BCE Loss: 0.015986\n",
      "[Epoch 4] Step 3130 | BCE Loss: 0.014260\n",
      "[Epoch 4] Step 3140 | BCE Loss: 0.021128\n",
      "[Epoch 4] Step 3150 | BCE Loss: 0.016409\n",
      "[Epoch 4] Step 3160 | BCE Loss: 0.013929\n",
      "[Epoch 4] Step 3170 | BCE Loss: 0.013206\n",
      "[Epoch 4] Step 3180 | BCE Loss: 0.012370\n",
      "[Epoch 4] Step 3190 | BCE Loss: 0.017862\n",
      "[Epoch 4] Step 3200 | BCE Loss: 0.023515\n",
      "[Epoch 4] Step 3210 | BCE Loss: 0.010665\n",
      "[Epoch 4] Step 3220 | BCE Loss: 0.009683\n",
      "[Epoch 4] Step 3230 | BCE Loss: 0.061688\n",
      "[Epoch 4] Step 3240 | BCE Loss: 0.009994\n",
      "[Epoch 4] Step 3250 | BCE Loss: 0.028768\n",
      "[Epoch 4] Step 3260 | BCE Loss: 0.023999\n",
      "[Epoch 4] Step 3270 | BCE Loss: 0.013757\n",
      "[Epoch 4] Step 3280 | BCE Loss: 0.013372\n",
      "[Epoch 4] Step 3290 | BCE Loss: 0.012302\n",
      "[Epoch 4] Step 3300 | BCE Loss: 0.012697\n",
      "[Epoch 4] Step 3310 | BCE Loss: 0.015561\n",
      "[Epoch 4] Step 3320 | BCE Loss: 0.014886\n",
      "[Epoch 4] Step 3330 | BCE Loss: 0.016983\n",
      "[Epoch 4] Step 3340 | BCE Loss: 0.014244\n",
      "[Epoch 4] Step 3350 | BCE Loss: 0.014222\n",
      "[Epoch 4] Step 3360 | BCE Loss: 0.017329\n",
      "[Epoch 4] Step 3370 | BCE Loss: 0.012632\n",
      "[Epoch 4] Step 3380 | BCE Loss: 0.011323\n",
      "[Epoch 4] Step 3390 | BCE Loss: 0.011836\n",
      "[Epoch 4] Step 3400 | BCE Loss: 0.016040\n",
      "[Epoch 4] Step 3410 | BCE Loss: 0.024181\n",
      "[Epoch 4] Step 3420 | BCE Loss: 0.017026\n",
      "[Epoch 4] Step 3430 | BCE Loss: 0.016407\n",
      "[Epoch 4] Step 3440 | BCE Loss: 0.020617\n",
      "[Epoch 4] Step 3450 | BCE Loss: 0.010959\n",
      "[Epoch 4] Step 3460 | BCE Loss: 0.016463\n",
      "[Epoch 4] Step 3470 | BCE Loss: 0.020277\n",
      "[Epoch 4] Step 3480 | BCE Loss: 0.013731\n",
      "[Epoch 4] Step 3490 | BCE Loss: 0.018912\n",
      "[Epoch 4] Step 3500 | BCE Loss: 0.014673\n",
      "[Epoch 4] Step 3510 | BCE Loss: 0.015851\n",
      "[Epoch 4] Step 3520 | BCE Loss: 0.018774\n",
      "[Epoch 4] Step 3530 | BCE Loss: 0.053240\n",
      "[Epoch 4] Step 3540 | BCE Loss: 0.012584\n",
      "[Epoch 4] Step 3550 | BCE Loss: 0.018183\n",
      "[Epoch 4] Step 3560 | BCE Loss: 0.195364\n",
      "[Epoch 4] Step 3570 | BCE Loss: 0.014584\n",
      "[Epoch 4] Step 3580 | BCE Loss: 0.015442\n",
      "[Epoch 4] Step 3590 | BCE Loss: 0.015581\n",
      "[Epoch 4] Step 3600 | BCE Loss: 0.012559\n",
      "[Epoch 4] Step 3610 | BCE Loss: 0.013181\n",
      "[Epoch 4] Step 3620 | BCE Loss: 0.020445\n",
      "[Epoch 4] Step 3630 | BCE Loss: 0.013376\n",
      "[Epoch 4] Step 3640 | BCE Loss: 0.021653\n",
      "[Epoch 4] Step 3650 | BCE Loss: 0.011603\n",
      "[Epoch 4] Step 3660 | BCE Loss: 0.012688\n",
      "[Epoch 4] Step 3670 | BCE Loss: 0.010750\n",
      "[Epoch 4] Step 3680 | BCE Loss: 0.010166\n",
      "[Epoch 4] Step 3690 | BCE Loss: 0.013569\n",
      "[Epoch 4] Step 3700 | BCE Loss: 0.015684\n",
      "[Epoch 4] Step 3710 | BCE Loss: 0.011096\n",
      "[Epoch 4] Step 3720 | BCE Loss: 0.014403\n",
      "[Epoch 4] Step 3730 | BCE Loss: 0.019987\n",
      "[Epoch 4] Step 3740 | BCE Loss: 0.014871\n",
      "[Epoch 4] Step 3750 | BCE Loss: 0.016858\n",
      "[Epoch 4] Step 3760 | BCE Loss: 0.016383\n",
      "[Epoch 4] Step 3770 | BCE Loss: 0.012423\n",
      "[Epoch 4] Step 3780 | BCE Loss: 0.014503\n",
      "[Epoch 4] Step 3790 | BCE Loss: 0.016239\n",
      "[Epoch 4] Step 3800 | BCE Loss: 0.021116\n",
      "[Epoch 4] Step 3810 | BCE Loss: 0.017546\n",
      "[Epoch 4] Step 3820 | BCE Loss: 0.013897\n",
      "[Epoch 4] Step 3830 | BCE Loss: 0.017872\n",
      "[Epoch 4] Step 3840 | BCE Loss: 0.014516\n",
      "[Epoch 4] Step 3850 | BCE Loss: 0.017896\n",
      "[Epoch 4] Step 3860 | BCE Loss: 0.013103\n",
      "[Epoch 4] Step 3870 | BCE Loss: 0.017846\n",
      "[Epoch 4] Step 3880 | BCE Loss: 0.010917\n",
      "[Epoch 4] Step 3890 | BCE Loss: 0.016147\n",
      "[Epoch 4] Step 3900 | BCE Loss: 0.019118\n",
      "[Epoch 4] Step 3910 | BCE Loss: 0.011399\n",
      "[Epoch 4] Step 3920 | BCE Loss: 0.010846\n",
      "[Epoch 4] Step 3930 | BCE Loss: 0.010164\n",
      "[Epoch 4] Step 3940 | BCE Loss: 0.014713\n",
      "[Epoch 4] Step 3950 | BCE Loss: 0.011933\n",
      "[Epoch 4] Step 3960 | BCE Loss: 0.019598\n",
      "[Epoch 4] Step 3970 | BCE Loss: 0.011378\n",
      "[Epoch 4] Step 3980 | BCE Loss: 0.022199\n",
      "[Epoch 4] Step 3990 | BCE Loss: 0.015884\n",
      "[Epoch 4] Step 4000 | BCE Loss: 0.014129\n",
      "[Epoch 4] Step 4010 | BCE Loss: 0.021623\n",
      "[Epoch 4] Step 4020 | BCE Loss: 0.014738\n",
      "[Epoch 4] Step 4030 | BCE Loss: 0.013877\n",
      "[Epoch 4] Step 4040 | BCE Loss: 0.020443\n",
      "[Epoch 4] Step 4050 | BCE Loss: 0.015736\n",
      "[Epoch 4] Step 4060 | BCE Loss: 0.014177\n",
      "[Epoch 4] Step 4070 | BCE Loss: 0.018618\n",
      "[Epoch 4] Step 4080 | BCE Loss: 0.016893\n",
      "[Epoch 4] Step 4090 | BCE Loss: 0.012973\n",
      "[Epoch 4] Step 4100 | BCE Loss: 0.017615\n",
      "[Epoch 4] Step 4110 | BCE Loss: 0.010190\n",
      "[Epoch 4] Step 4120 | BCE Loss: 0.011903\n",
      "[Epoch 4] Step 4130 | BCE Loss: 0.019046\n",
      "[Epoch 4] Step 4140 | BCE Loss: 0.012990\n",
      "[Epoch 4] Step 4150 | BCE Loss: 0.013847\n",
      "[Epoch 4] Step 4160 | BCE Loss: 0.014371\n",
      "[Epoch 4] Step 4170 | BCE Loss: 0.029585\n",
      "[Epoch 4] Step 4180 | BCE Loss: 0.016379\n",
      "[Epoch 4] Step 4190 | BCE Loss: 0.018717\n",
      "[Epoch 4] Step 4200 | BCE Loss: 0.012989\n",
      "[Epoch 4] Step 4210 | BCE Loss: 0.020131\n",
      "[Epoch 4] Step 4220 | BCE Loss: 0.021602\n",
      "[Epoch 4] Step 4230 | BCE Loss: 0.061400\n",
      "[Epoch 4] Step 4240 | BCE Loss: 0.012793\n",
      "[Epoch 4] Step 4250 | BCE Loss: 0.011390\n",
      "[Epoch 4] Step 4260 | BCE Loss: 0.015030\n",
      "[Epoch 4] Step 4270 | BCE Loss: 0.012258\n",
      "[Epoch 4] Step 4280 | BCE Loss: 0.021469\n",
      "[Epoch 4] Step 4290 | BCE Loss: 0.011568\n",
      "[Epoch 4] Step 4300 | BCE Loss: 0.018032\n",
      "[Epoch 4] Step 4310 | BCE Loss: 0.016291\n",
      "[Epoch 4] Step 4320 | BCE Loss: 0.013722\n",
      "[Epoch 4] Step 4330 | BCE Loss: 0.021687\n",
      "[Epoch 4] Step 4340 | BCE Loss: 0.018803\n",
      "[Epoch 4] Step 4350 | BCE Loss: 0.012321\n",
      "[Epoch 4] Step 4360 | BCE Loss: 0.024127\n",
      "[Epoch 4] Step 4370 | BCE Loss: 0.028740\n",
      "[Epoch 4] Step 4380 | BCE Loss: 0.017142\n",
      "[Epoch 4] Step 4390 | BCE Loss: 0.018960\n",
      "[Epoch 4] Step 4400 | BCE Loss: 0.018257\n",
      "[Epoch 4] Step 4410 | BCE Loss: 0.015742\n",
      "[Epoch 4] Step 4420 | BCE Loss: 0.012823\n",
      "[Epoch 4] Step 4430 | BCE Loss: 0.030408\n",
      "[Epoch 4] Step 4440 | BCE Loss: 0.015211\n",
      "[Epoch 4] Step 4450 | BCE Loss: 0.010683\n",
      "[Epoch 4] Step 4460 | BCE Loss: 0.019782\n",
      "[Epoch 4] Step 4470 | BCE Loss: 0.014547\n",
      "[Epoch 4] Step 4480 | BCE Loss: 0.016800\n",
      "[Epoch 4] Step 4490 | BCE Loss: 0.019494\n",
      "[Epoch 4] Step 4500 | BCE Loss: 0.018639\n",
      "[Epoch 4] Step 4510 | BCE Loss: 0.038146\n",
      "[Epoch 4] Step 4520 | BCE Loss: 0.008751\n",
      "[Epoch 4] Step 4530 | BCE Loss: 0.013197\n",
      "[Epoch 4] Step 4540 | BCE Loss: 0.015388\n",
      "[Epoch 4] Step 4550 | BCE Loss: 0.015673\n",
      "[Epoch 4] Step 4560 | BCE Loss: 0.012505\n",
      "[Epoch 4] Step 4570 | BCE Loss: 0.020305\n",
      "[Epoch 4] Step 4580 | BCE Loss: 0.018163\n",
      "[Epoch 4] Step 4590 | BCE Loss: 0.014086\n",
      "[Epoch 4] Step 4600 | BCE Loss: 0.014557\n",
      "[Epoch 4] Step 4610 | BCE Loss: 0.019816\n",
      "[Epoch 4] Step 4620 | BCE Loss: 0.023288\n",
      "[Epoch 4] Step 4630 | BCE Loss: 0.013620\n",
      "[Epoch 4] Step 4640 | BCE Loss: 0.016729\n",
      "[Epoch 4] Step 4650 | BCE Loss: 0.014652\n",
      "[Epoch 4] Step 4660 | BCE Loss: 0.017107\n",
      "[Epoch 4] Step 4670 | BCE Loss: 0.013380\n",
      "[Epoch 4] Step 4680 | BCE Loss: 0.034101\n",
      "[Epoch 4] Step 4690 | BCE Loss: 0.012474\n",
      "[Epoch 4] Step 4700 | BCE Loss: 0.014300\n",
      "[Epoch 4] Step 4710 | BCE Loss: 0.015745\n",
      "[Epoch 4] Step 4720 | BCE Loss: 0.028075\n",
      "[Epoch 4] Step 4730 | BCE Loss: 0.020623\n",
      "[Epoch 4] Step 4740 | BCE Loss: 0.011190\n",
      "[Epoch 4] Step 4750 | BCE Loss: 0.014316\n",
      "[Epoch 4] Step 4760 | BCE Loss: 0.014287\n",
      "[Epoch 4] Step 4770 | BCE Loss: 0.050364\n",
      "[Epoch 4] Step 4780 | BCE Loss: 0.019746\n",
      "[Epoch 4] Step 4790 | BCE Loss: 0.014374\n",
      "[Epoch 4] Step 4800 | BCE Loss: 0.010832\n",
      "[Epoch 4] Step 4810 | BCE Loss: 0.010875\n",
      "[Epoch 4] Step 4820 | BCE Loss: 0.013227\n",
      "[Epoch 4] Step 4830 | BCE Loss: 0.020013\n",
      "[Epoch 4] Step 4840 | BCE Loss: 0.022525\n",
      "[Epoch 4] Step 4850 | BCE Loss: 0.018710\n",
      "[Epoch 4] Step 4860 | BCE Loss: 0.040688\n",
      "[Epoch 4] Step 4870 | BCE Loss: 0.016840\n",
      "[Epoch 4] Step 4880 | BCE Loss: 0.011993\n",
      "[Epoch 4] Step 4890 | BCE Loss: 0.013553\n",
      "[Epoch 4] Step 4900 | BCE Loss: 0.011174\n",
      "[Epoch 4] Step 4910 | BCE Loss: 0.019597\n",
      "[Epoch 4] Step 4920 | BCE Loss: 0.016159\n",
      "[Epoch 4] Step 4930 | BCE Loss: 0.011618\n",
      "[Epoch 4] Step 4940 | BCE Loss: 0.011931\n",
      "[Epoch 4] Step 4950 | BCE Loss: 0.017166\n",
      "[Epoch 4] Step 4960 | BCE Loss: 0.012804\n",
      "[Epoch 4] Step 4970 | BCE Loss: 0.034478\n",
      "[Epoch 4] Step 4980 | BCE Loss: 0.014691\n",
      "[Epoch 4] Step 4990 | BCE Loss: 0.014473\n",
      "[Epoch 4] Step 5000 | BCE Loss: 0.016014\n",
      "[Epoch 4] Step 5010 | BCE Loss: 0.016638\n",
      "[Epoch 4] Step 5020 | BCE Loss: 0.016498\n",
      "[Epoch 4] Step 5030 | BCE Loss: 0.015913\n",
      "[Epoch 4] Step 5040 | BCE Loss: 0.012764\n",
      "[Epoch 4] Step 5050 | BCE Loss: 0.015769\n",
      "[Epoch 4] Step 5060 | BCE Loss: 0.012053\n",
      "[Epoch 4] Step 5070 | BCE Loss: 0.014807\n",
      "[Epoch 4] Step 5080 | BCE Loss: 0.013564\n",
      "[Epoch 4] Step 5090 | BCE Loss: 0.016010\n",
      "[Epoch 4] Step 5100 | BCE Loss: 0.018908\n",
      "[Epoch 4] Step 5110 | BCE Loss: 0.010550\n",
      "[Epoch 4] Step 5120 | BCE Loss: 0.011487\n",
      "[Epoch 4] Step 5130 | BCE Loss: 0.022937\n",
      "[Epoch 4] Step 5140 | BCE Loss: 0.024272\n",
      "[Epoch 4] Step 5150 | BCE Loss: 0.011346\n",
      "[Epoch 4] Step 5160 | BCE Loss: 0.013265\n",
      "[Epoch 4] Step 5170 | BCE Loss: 0.018994\n",
      "[Epoch 4] Step 5180 | BCE Loss: 0.018131\n",
      "[Epoch 4] Step 5190 | BCE Loss: 0.010369\n",
      "[Epoch 4] Step 5200 | BCE Loss: 0.010094\n",
      "[Epoch 4] Step 5210 | BCE Loss: 0.014398\n",
      "[Epoch 4] Step 5220 | BCE Loss: 0.015554\n",
      "[Epoch 4] Step 5230 | BCE Loss: 0.011623\n",
      "[Epoch 4] Step 5240 | BCE Loss: 0.011026\n",
      "[Epoch 4] Step 5250 | BCE Loss: 0.013428\n",
      "[Epoch 4] Step 5260 | BCE Loss: 0.014052\n",
      "[Epoch 4] Step 5270 | BCE Loss: 0.013620\n",
      "[Epoch 4] Step 5280 | BCE Loss: 0.012058\n",
      "[Epoch 4] Step 5290 | BCE Loss: 0.016242\n",
      "[Epoch 4] Step 5300 | BCE Loss: 0.016203\n",
      "[Epoch 4] Step 5310 | BCE Loss: 0.017899\n",
      "[Epoch 4] Step 5320 | BCE Loss: 0.013981\n",
      "[Epoch 4] Step 5330 | BCE Loss: 0.014407\n",
      "[Epoch 4] Step 5340 | BCE Loss: 0.015171\n",
      "[Epoch 4] Step 5350 | BCE Loss: 0.012672\n",
      "[Epoch 4] Step 5360 | BCE Loss: 0.028940\n",
      "[Epoch 4] Step 5370 | BCE Loss: 0.019575\n",
      "[Epoch 4] Step 5380 | BCE Loss: 0.013959\n",
      "[Epoch 4] Step 5390 | BCE Loss: 0.013078\n",
      "[Epoch 4] Step 5400 | BCE Loss: 0.015705\n",
      "[Epoch 4] Step 5410 | BCE Loss: 0.019675\n",
      "[Epoch 4] Step 5420 | BCE Loss: 0.014270\n",
      "[Epoch 4] Step 5430 | BCE Loss: 0.011181\n",
      "[Epoch 4] Step 5440 | BCE Loss: 0.012059\n",
      "[Epoch 4] Step 5450 | BCE Loss: 0.013534\n",
      "[Epoch 4] Step 5460 | BCE Loss: 0.016365\n",
      "[Epoch 4] Step 5470 | BCE Loss: 0.010080\n",
      "[Epoch 4] Step 5480 | BCE Loss: 0.017952\n",
      "[Epoch 4] Step 5490 | BCE Loss: 0.012107\n",
      "[Epoch 4] Step 5500 | BCE Loss: 0.017669\n",
      "[Epoch 4] Step 5510 | BCE Loss: 0.017009\n",
      "[Epoch 4] Step 5520 | BCE Loss: 0.014011\n",
      "[Epoch 4] Step 5530 | BCE Loss: 0.012571\n",
      "[Epoch 4] Step 5540 | BCE Loss: 0.014253\n",
      "[Epoch 4] Step 5550 | BCE Loss: 0.014612\n",
      "[Epoch 4] Step 5560 | BCE Loss: 0.011521\n",
      "[Epoch 4] Step 5570 | BCE Loss: 0.020773\n",
      "[Epoch 4] Step 5580 | BCE Loss: 0.012411\n",
      "[Epoch 4] Step 5590 | BCE Loss: 0.024790\n",
      "[Epoch 4] Step 5600 | BCE Loss: 0.017472\n",
      "[Epoch 4] Step 5610 | BCE Loss: 0.014884\n",
      "[Epoch 4] Step 5620 | BCE Loss: 0.013805\n",
      "[Epoch 4] Step 5630 | BCE Loss: 0.014164\n",
      "[Epoch 4] Step 5640 | BCE Loss: 0.013056\n",
      "[Epoch 4] Step 5650 | BCE Loss: 0.016050\n",
      "[Epoch 4] Step 5660 | BCE Loss: 0.015959\n",
      "[Epoch 4] Step 5670 | BCE Loss: 0.014460\n",
      "[Epoch 4] Step 5680 | BCE Loss: 0.014232\n",
      "[Epoch 4] Step 5690 | BCE Loss: 0.015024\n",
      "[Epoch 4] Step 5700 | BCE Loss: 0.022629\n",
      "[Epoch 4] Step 5710 | BCE Loss: 0.012445\n",
      "[Epoch 4] Step 5720 | BCE Loss: 0.014456\n",
      "[Epoch 4] Step 5730 | BCE Loss: 0.023385\n",
      "[Epoch 4] Step 5740 | BCE Loss: 0.018566\n",
      "[Epoch 4] Step 5750 | BCE Loss: 0.015928\n",
      "[Epoch 4] Step 5760 | BCE Loss: 0.012376\n",
      "[Epoch 4] Step 5770 | BCE Loss: 0.013225\n",
      "[Epoch 4] Step 5780 | BCE Loss: 0.012071\n",
      "[Epoch 4] Step 5790 | BCE Loss: 0.011749\n",
      "[Epoch 4] Step 5800 | BCE Loss: 0.015279\n",
      "[Epoch 4] Step 5810 | BCE Loss: 0.025642\n",
      "[Epoch 4] Step 5820 | BCE Loss: 0.013060\n",
      "\n",
      "=== Epoch 4 Selesai | Avg BCE Loss: 0.017343 ===\n",
      "[SAVE] Merging weights and saving single .pth file...\n",
      "[SAVE] Full PEFT checkpoint saved to: /kaggle/working/output/sam2_finetuned.pth\n",
      "\n",
      "[Epoch 5/5]\n",
      "[Epoch 5] Step 0 | BCE Loss: 0.013388\n",
      "[Epoch 5] Step 10 | BCE Loss: 0.013605\n",
      "[Epoch 5] Step 20 | BCE Loss: 0.013566\n",
      "[Epoch 5] Step 30 | BCE Loss: 0.035042\n",
      "[Epoch 5] Step 40 | BCE Loss: 0.015212\n",
      "[Epoch 5] Step 50 | BCE Loss: 0.022705\n",
      "[Epoch 5] Step 60 | BCE Loss: 0.015549\n",
      "[Epoch 5] Step 70 | BCE Loss: 0.028671\n",
      "[Epoch 5] Step 80 | BCE Loss: 0.016539\n",
      "[Epoch 5] Step 90 | BCE Loss: 0.018549\n",
      "[Epoch 5] Step 100 | BCE Loss: 0.280699\n",
      "[Epoch 5] Step 110 | BCE Loss: 0.014907\n",
      "[Epoch 5] Step 120 | BCE Loss: 0.020402\n",
      "[Epoch 5] Step 130 | BCE Loss: 0.012925\n",
      "[Epoch 5] Step 140 | BCE Loss: 0.013680\n",
      "[Epoch 5] Step 150 | BCE Loss: 0.014999\n",
      "[Epoch 5] Step 160 | BCE Loss: 0.014700\n",
      "[Epoch 5] Step 170 | BCE Loss: 0.013629\n",
      "[Epoch 5] Step 180 | BCE Loss: 0.016039\n",
      "[Epoch 5] Step 190 | BCE Loss: 0.012142\n",
      "[Epoch 5] Step 200 | BCE Loss: 0.018186\n",
      "[Epoch 5] Step 210 | BCE Loss: 0.015588\n",
      "[Epoch 5] Step 220 | BCE Loss: 0.012994\n",
      "[Epoch 5] Step 230 | BCE Loss: 0.020153\n",
      "[Epoch 5] Step 240 | BCE Loss: 0.013270\n",
      "[Epoch 5] Step 250 | BCE Loss: 0.009443\n",
      "[Epoch 5] Step 260 | BCE Loss: 0.023537\n",
      "[Epoch 5] Step 270 | BCE Loss: 0.014135\n",
      "[Epoch 5] Step 280 | BCE Loss: 0.016196\n",
      "[Epoch 5] Step 290 | BCE Loss: 0.018185\n",
      "[Epoch 5] Step 300 | BCE Loss: 0.025429\n",
      "[Epoch 5] Step 310 | BCE Loss: 0.015580\n",
      "[Epoch 5] Step 320 | BCE Loss: 0.013331\n",
      "[Epoch 5] Step 330 | BCE Loss: 0.022719\n",
      "[Epoch 5] Step 340 | BCE Loss: 0.014407\n",
      "[Epoch 5] Step 350 | BCE Loss: 0.015137\n",
      "[Epoch 5] Step 360 | BCE Loss: 0.010594\n",
      "[Epoch 5] Step 370 | BCE Loss: 0.012039\n",
      "[Epoch 5] Step 380 | BCE Loss: 0.017015\n",
      "[Epoch 5] Step 390 | BCE Loss: 0.023955\n",
      "[Epoch 5] Step 400 | BCE Loss: 0.011565\n",
      "[Epoch 5] Step 410 | BCE Loss: 0.015533\n",
      "[Epoch 5] Step 420 | BCE Loss: 0.013563\n",
      "[Epoch 5] Step 430 | BCE Loss: 0.018712\n",
      "[Epoch 5] Step 440 | BCE Loss: 0.013470\n",
      "[Epoch 5] Step 450 | BCE Loss: 0.016924\n",
      "[Epoch 5] Step 460 | BCE Loss: 0.021835\n",
      "[Epoch 5] Step 470 | BCE Loss: 0.016222\n",
      "[Epoch 5] Step 480 | BCE Loss: 0.014516\n",
      "[Epoch 5] Step 490 | BCE Loss: 0.017282\n",
      "[Epoch 5] Step 500 | BCE Loss: 0.016045\n",
      "[Epoch 5] Step 510 | BCE Loss: 0.013019\n",
      "[Epoch 5] Step 520 | BCE Loss: 0.013188\n",
      "[Epoch 5] Step 530 | BCE Loss: 0.013738\n",
      "[Epoch 5] Step 540 | BCE Loss: 0.013129\n",
      "[Epoch 5] Step 550 | BCE Loss: 0.012850\n",
      "[Epoch 5] Step 560 | BCE Loss: 0.018712\n",
      "[Epoch 5] Step 570 | BCE Loss: 0.019041\n",
      "[Epoch 5] Step 580 | BCE Loss: 0.012103\n",
      "[Epoch 5] Step 590 | BCE Loss: 0.018105\n",
      "[Epoch 5] Step 600 | BCE Loss: 0.012056\n",
      "[Epoch 5] Step 610 | BCE Loss: 0.021370\n",
      "[Epoch 5] Step 620 | BCE Loss: 0.012465\n",
      "[Epoch 5] Step 630 | BCE Loss: 0.015159\n",
      "[Epoch 5] Step 640 | BCE Loss: 0.016421\n",
      "[Epoch 5] Step 650 | BCE Loss: 0.010720\n",
      "[Epoch 5] Step 660 | BCE Loss: 0.019781\n",
      "[Epoch 5] Step 670 | BCE Loss: 0.016969\n",
      "[Epoch 5] Step 680 | BCE Loss: 0.017696\n",
      "[Epoch 5] Step 690 | BCE Loss: 0.013567\n",
      "[Epoch 5] Step 700 | BCE Loss: 0.012319\n",
      "[Epoch 5] Step 710 | BCE Loss: 0.013603\n",
      "[Epoch 5] Step 720 | BCE Loss: 0.010223\n",
      "[Epoch 5] Step 730 | BCE Loss: 0.035399\n",
      "[Epoch 5] Step 740 | BCE Loss: 0.013257\n",
      "[Epoch 5] Step 750 | BCE Loss: 0.031513\n",
      "[Epoch 5] Step 760 | BCE Loss: 0.012457\n",
      "[Epoch 5] Step 770 | BCE Loss: 0.012847\n",
      "[Epoch 5] Step 780 | BCE Loss: 0.013409\n",
      "[Epoch 5] Step 790 | BCE Loss: 0.015534\n",
      "[Epoch 5] Step 800 | BCE Loss: 0.014122\n",
      "[Epoch 5] Step 810 | BCE Loss: 0.011023\n",
      "[Epoch 5] Step 820 | BCE Loss: 0.012161\n",
      "[Epoch 5] Step 830 | BCE Loss: 0.024962\n",
      "[Epoch 5] Step 840 | BCE Loss: 0.017210\n",
      "[Epoch 5] Step 850 | BCE Loss: 0.018679\n",
      "[Epoch 5] Step 860 | BCE Loss: 0.011866\n",
      "[Epoch 5] Step 870 | BCE Loss: 0.014712\n",
      "[Epoch 5] Step 880 | BCE Loss: 0.009784\n",
      "[Epoch 5] Step 890 | BCE Loss: 0.018264\n",
      "[Epoch 5] Step 900 | BCE Loss: 0.015937\n",
      "[Epoch 5] Step 910 | BCE Loss: 0.017494\n",
      "[Epoch 5] Step 920 | BCE Loss: 0.015339\n",
      "[Epoch 5] Step 930 | BCE Loss: 0.012805\n",
      "[Epoch 5] Step 940 | BCE Loss: 0.014794\n",
      "[Epoch 5] Step 950 | BCE Loss: 0.015237\n",
      "[Epoch 5] Step 960 | BCE Loss: 0.020693\n",
      "[Epoch 5] Step 970 | BCE Loss: 0.013871\n",
      "[Epoch 5] Step 980 | BCE Loss: 0.018308\n",
      "[Epoch 5] Step 990 | BCE Loss: 0.018138\n",
      "[Epoch 5] Step 1000 | BCE Loss: 0.012072\n",
      "[Epoch 5] Step 1010 | BCE Loss: 0.016359\n",
      "[Epoch 5] Step 1020 | BCE Loss: 0.017154\n",
      "[Epoch 5] Step 1030 | BCE Loss: 0.024102\n",
      "[Epoch 5] Step 1040 | BCE Loss: 0.019035\n",
      "[Epoch 5] Step 1050 | BCE Loss: 0.023224\n",
      "[Epoch 5] Step 1060 | BCE Loss: 0.017815\n",
      "[Epoch 5] Step 1070 | BCE Loss: 0.012985\n",
      "[Epoch 5] Step 1080 | BCE Loss: 0.021284\n",
      "[Epoch 5] Step 1090 | BCE Loss: 0.014432\n",
      "[Epoch 5] Step 1100 | BCE Loss: 0.013862\n",
      "[Epoch 5] Step 1110 | BCE Loss: 0.011264\n",
      "[Epoch 5] Step 1120 | BCE Loss: 0.013427\n",
      "[Epoch 5] Step 1130 | BCE Loss: 0.019643\n",
      "[Epoch 5] Step 1140 | BCE Loss: 0.015639\n",
      "[Epoch 5] Step 1150 | BCE Loss: 0.017357\n",
      "[Epoch 5] Step 1160 | BCE Loss: 0.013387\n",
      "[Epoch 5] Step 1170 | BCE Loss: 0.011905\n",
      "[Epoch 5] Step 1180 | BCE Loss: 0.019427\n",
      "[Epoch 5] Step 1190 | BCE Loss: 0.011545\n",
      "[Epoch 5] Step 1200 | BCE Loss: 0.011673\n",
      "[Epoch 5] Step 1210 | BCE Loss: 0.014966\n",
      "[Epoch 5] Step 1220 | BCE Loss: 0.012651\n",
      "[Epoch 5] Step 1230 | BCE Loss: 0.013713\n",
      "[Epoch 5] Step 1240 | BCE Loss: 0.015691\n",
      "[Epoch 5] Step 1250 | BCE Loss: 0.016540\n",
      "[Epoch 5] Step 1260 | BCE Loss: 0.018688\n",
      "[Epoch 5] Step 1270 | BCE Loss: 0.016180\n",
      "[Epoch 5] Step 1280 | BCE Loss: 0.013826\n",
      "[Epoch 5] Step 1290 | BCE Loss: 0.020941\n",
      "[Epoch 5] Step 1300 | BCE Loss: 0.016278\n",
      "[Epoch 5] Step 1310 | BCE Loss: 0.014173\n",
      "[Epoch 5] Step 1320 | BCE Loss: 0.025433\n",
      "[Epoch 5] Step 1330 | BCE Loss: 0.015360\n",
      "[Epoch 5] Step 1340 | BCE Loss: 0.016048\n",
      "[Epoch 5] Step 1350 | BCE Loss: 0.012645\n",
      "[Epoch 5] Step 1360 | BCE Loss: 0.024556\n",
      "[Epoch 5] Step 1370 | BCE Loss: 0.030249\n",
      "[Epoch 5] Step 1380 | BCE Loss: 0.011484\n",
      "[Epoch 5] Step 1390 | BCE Loss: 0.016634\n",
      "[Epoch 5] Step 1400 | BCE Loss: 0.012308\n",
      "[Epoch 5] Step 1410 | BCE Loss: 0.017298\n",
      "[Epoch 5] Step 1420 | BCE Loss: 0.013746\n",
      "[Epoch 5] Step 1430 | BCE Loss: 0.019748\n",
      "[Epoch 5] Step 1440 | BCE Loss: 0.012509\n",
      "[Epoch 5] Step 1450 | BCE Loss: 0.015889\n",
      "[Epoch 5] Step 1460 | BCE Loss: 0.016714\n",
      "[Epoch 5] Step 1470 | BCE Loss: 0.017932\n",
      "[Epoch 5] Step 1480 | BCE Loss: 0.014377\n",
      "[Epoch 5] Step 1490 | BCE Loss: 0.013339\n",
      "[Epoch 5] Step 1500 | BCE Loss: 0.013499\n",
      "[Epoch 5] Step 1510 | BCE Loss: 0.019057\n",
      "[Epoch 5] Step 1520 | BCE Loss: 0.015560\n",
      "[Epoch 5] Step 1530 | BCE Loss: 0.016102\n",
      "[Epoch 5] Step 1540 | BCE Loss: 0.017479\n",
      "[Epoch 5] Step 1550 | BCE Loss: 0.011740\n",
      "[Epoch 5] Step 1560 | BCE Loss: 0.010722\n",
      "[Epoch 5] Step 1570 | BCE Loss: 0.012929\n",
      "[Epoch 5] Step 1580 | BCE Loss: 0.015079\n",
      "[Epoch 5] Step 1590 | BCE Loss: 0.019859\n",
      "[Epoch 5] Step 1600 | BCE Loss: 0.026636\n",
      "[Epoch 5] Step 1610 | BCE Loss: 0.013830\n",
      "[Epoch 5] Step 1620 | BCE Loss: 0.013873\n",
      "[Epoch 5] Step 1630 | BCE Loss: 0.013475\n",
      "[Epoch 5] Step 1640 | BCE Loss: 0.014898\n",
      "[Epoch 5] Step 1650 | BCE Loss: 0.012848\n",
      "[Epoch 5] Step 1660 | BCE Loss: 0.011843\n",
      "[Epoch 5] Step 1670 | BCE Loss: 0.012295\n",
      "[Epoch 5] Step 1680 | BCE Loss: 0.015975\n",
      "[Epoch 5] Step 1690 | BCE Loss: 0.010694\n",
      "[Epoch 5] Step 1700 | BCE Loss: 0.027370\n",
      "[Epoch 5] Step 1710 | BCE Loss: 0.025546\n",
      "[Epoch 5] Step 1720 | BCE Loss: 0.016144\n",
      "[Epoch 5] Step 1730 | BCE Loss: 0.018963\n",
      "[Epoch 5] Step 1740 | BCE Loss: 0.012971\n",
      "[Epoch 5] Step 1750 | BCE Loss: 0.015113\n",
      "[Epoch 5] Step 1760 | BCE Loss: 0.012321\n",
      "[Epoch 5] Step 1770 | BCE Loss: 0.009623\n",
      "[Epoch 5] Step 1780 | BCE Loss: 0.032775\n",
      "[Epoch 5] Step 1790 | BCE Loss: 0.016504\n",
      "[Epoch 5] Step 1800 | BCE Loss: 0.014676\n",
      "[Epoch 5] Step 1810 | BCE Loss: 0.021852\n",
      "[Epoch 5] Step 1820 | BCE Loss: 0.018171\n",
      "[Epoch 5] Step 1830 | BCE Loss: 0.018157\n",
      "[Epoch 5] Step 1840 | BCE Loss: 0.017615\n",
      "[Epoch 5] Step 1850 | BCE Loss: 0.022730\n",
      "[Epoch 5] Step 1860 | BCE Loss: 0.014861\n",
      "[Epoch 5] Step 1870 | BCE Loss: 0.013734\n",
      "[Epoch 5] Step 1880 | BCE Loss: 0.012797\n",
      "[Epoch 5] Step 1890 | BCE Loss: 0.013637\n",
      "[Epoch 5] Step 1900 | BCE Loss: 0.020185\n",
      "[Epoch 5] Step 1910 | BCE Loss: 0.015901\n",
      "[Epoch 5] Step 1920 | BCE Loss: 0.016857\n",
      "[Epoch 5] Step 1930 | BCE Loss: 0.013200\n",
      "[Epoch 5] Step 1940 | BCE Loss: 0.018991\n",
      "[Epoch 5] Step 1950 | BCE Loss: 0.020160\n",
      "[Epoch 5] Step 1960 | BCE Loss: 0.023016\n",
      "[Epoch 5] Step 1970 | BCE Loss: 0.014862\n",
      "[Epoch 5] Step 1980 | BCE Loss: 0.010828\n",
      "[Epoch 5] Step 1990 | BCE Loss: 0.014877\n",
      "[Epoch 5] Step 2000 | BCE Loss: 0.012265\n",
      "[Epoch 5] Step 2010 | BCE Loss: 0.022018\n",
      "[Epoch 5] Step 2020 | BCE Loss: 0.018558\n",
      "[Epoch 5] Step 2030 | BCE Loss: 0.017506\n",
      "[Epoch 5] Step 2040 | BCE Loss: 0.016372\n",
      "[Epoch 5] Step 2050 | BCE Loss: 0.011932\n",
      "[Epoch 5] Step 2060 | BCE Loss: 0.016596\n",
      "[Epoch 5] Step 2070 | BCE Loss: 0.030224\n",
      "[Epoch 5] Step 2080 | BCE Loss: 0.020285\n",
      "[Epoch 5] Step 2090 | BCE Loss: 0.038092\n",
      "[Epoch 5] Step 2100 | BCE Loss: 0.014267\n",
      "[Epoch 5] Step 2110 | BCE Loss: 0.024516\n",
      "[Epoch 5] Step 2120 | BCE Loss: 0.013438\n",
      "[Epoch 5] Step 2130 | BCE Loss: 0.012153\n",
      "[Epoch 5] Step 2140 | BCE Loss: 0.016132\n",
      "[Epoch 5] Step 2150 | BCE Loss: 0.011676\n",
      "[Epoch 5] Step 2160 | BCE Loss: 0.018153\n",
      "[Epoch 5] Step 2170 | BCE Loss: 0.016420\n",
      "[Epoch 5] Step 2180 | BCE Loss: 0.014940\n",
      "[Epoch 5] Step 2190 | BCE Loss: 0.013517\n",
      "[Epoch 5] Step 2200 | BCE Loss: 0.016801\n",
      "[Epoch 5] Step 2210 | BCE Loss: 0.015216\n",
      "[Epoch 5] Step 2220 | BCE Loss: 0.017541\n",
      "[Epoch 5] Step 2230 | BCE Loss: 0.021998\n",
      "[Epoch 5] Step 2240 | BCE Loss: 0.019172\n",
      "[Epoch 5] Step 2250 | BCE Loss: 0.014065\n",
      "[Epoch 5] Step 2260 | BCE Loss: 0.022483\n",
      "[Epoch 5] Step 2270 | BCE Loss: 0.011271\n",
      "[Epoch 5] Step 2280 | BCE Loss: 0.022625\n",
      "[Epoch 5] Step 2290 | BCE Loss: 0.014970\n",
      "[Epoch 5] Step 2300 | BCE Loss: 0.018231\n",
      "[Epoch 5] Step 2310 | BCE Loss: 0.012181\n",
      "[Epoch 5] Step 2320 | BCE Loss: 0.014619\n",
      "[Epoch 5] Step 2330 | BCE Loss: 0.010758\n",
      "[Epoch 5] Step 2340 | BCE Loss: 0.015810\n",
      "[Epoch 5] Step 2350 | BCE Loss: 0.011485\n",
      "[Epoch 5] Step 2360 | BCE Loss: 0.016890\n",
      "[Epoch 5] Step 2370 | BCE Loss: 0.018026\n",
      "[Epoch 5] Step 2380 | BCE Loss: 0.018180\n",
      "[Epoch 5] Step 2390 | BCE Loss: 0.018392\n",
      "[Epoch 5] Step 2400 | BCE Loss: 0.019409\n",
      "[Epoch 5] Step 2410 | BCE Loss: 0.013275\n",
      "[Epoch 5] Step 2420 | BCE Loss: 0.024049\n",
      "[Epoch 5] Step 2430 | BCE Loss: 0.017967\n",
      "[Epoch 5] Step 2440 | BCE Loss: 0.013669\n",
      "[Epoch 5] Step 2450 | BCE Loss: 0.018225\n",
      "[Epoch 5] Step 2460 | BCE Loss: 0.021497\n",
      "[Epoch 5] Step 2470 | BCE Loss: 0.010250\n",
      "[Epoch 5] Step 2480 | BCE Loss: 0.016589\n",
      "[Epoch 5] Step 2490 | BCE Loss: 0.015916\n",
      "[Epoch 5] Step 2500 | BCE Loss: 0.019121\n",
      "[Epoch 5] Step 2510 | BCE Loss: 0.012918\n",
      "[Epoch 5] Step 2520 | BCE Loss: 0.016462\n",
      "[Epoch 5] Step 2530 | BCE Loss: 0.018429\n",
      "[Epoch 5] Step 2540 | BCE Loss: 0.017566\n",
      "[Epoch 5] Step 2550 | BCE Loss: 0.023247\n",
      "[Epoch 5] Step 2560 | BCE Loss: 0.014818\n",
      "[Epoch 5] Step 2570 | BCE Loss: 0.013308\n",
      "[Epoch 5] Step 2580 | BCE Loss: 0.019125\n",
      "[Epoch 5] Step 2590 | BCE Loss: 0.031701\n",
      "[Epoch 5] Step 2600 | BCE Loss: 0.013126\n",
      "[Epoch 5] Step 2610 | BCE Loss: 0.023126\n",
      "[Epoch 5] Step 2620 | BCE Loss: 0.016174\n",
      "[Epoch 5] Step 2630 | BCE Loss: 0.018736\n",
      "[Epoch 5] Step 2640 | BCE Loss: 0.016349\n",
      "[Epoch 5] Step 2650 | BCE Loss: 0.013164\n",
      "[Epoch 5] Step 2660 | BCE Loss: 0.026097\n",
      "[Epoch 5] Step 2670 | BCE Loss: 0.019237\n",
      "[Epoch 5] Step 2680 | BCE Loss: 0.012581\n",
      "[Epoch 5] Step 2690 | BCE Loss: 0.013387\n",
      "[Epoch 5] Step 2700 | BCE Loss: 0.010402\n",
      "[Epoch 5] Step 2710 | BCE Loss: 0.014674\n",
      "[Epoch 5] Step 2720 | BCE Loss: 0.013755\n",
      "[Epoch 5] Step 2730 | BCE Loss: 0.016325\n",
      "[Epoch 5] Step 2740 | BCE Loss: 0.017916\n",
      "[Epoch 5] Step 2750 | BCE Loss: 0.015150\n",
      "[Epoch 5] Step 2760 | BCE Loss: 0.011436\n",
      "[Epoch 5] Step 2770 | BCE Loss: 0.010442\n",
      "[Epoch 5] Step 2780 | BCE Loss: 0.012353\n",
      "[Epoch 5] Step 2790 | BCE Loss: 0.011542\n",
      "[Epoch 5] Step 2800 | BCE Loss: 0.013371\n",
      "[Epoch 5] Step 2810 | BCE Loss: 0.013377\n",
      "[Epoch 5] Step 2820 | BCE Loss: 0.013773\n",
      "[Epoch 5] Step 2830 | BCE Loss: 0.036013\n",
      "[Epoch 5] Step 2840 | BCE Loss: 0.016137\n",
      "[Epoch 5] Step 2850 | BCE Loss: 0.020105\n",
      "[Epoch 5] Step 2860 | BCE Loss: 0.030273\n",
      "[Epoch 5] Step 2870 | BCE Loss: 0.015392\n",
      "[Epoch 5] Step 2880 | BCE Loss: 0.017991\n",
      "[Epoch 5] Step 2890 | BCE Loss: 0.012926\n",
      "[Epoch 5] Step 2900 | BCE Loss: 0.012292\n",
      "[Epoch 5] Step 2910 | BCE Loss: 0.010211\n",
      "[Epoch 5] Step 2920 | BCE Loss: 0.019465\n",
      "[Epoch 5] Step 2930 | BCE Loss: 0.014819\n",
      "[Epoch 5] Step 2940 | BCE Loss: 0.014058\n",
      "[Epoch 5] Step 2950 | BCE Loss: 0.012919\n",
      "[Epoch 5] Step 2960 | BCE Loss: 0.017905\n",
      "[Epoch 5] Step 2970 | BCE Loss: 0.015535\n",
      "[Epoch 5] Step 2980 | BCE Loss: 0.018774\n",
      "[Epoch 5] Step 2990 | BCE Loss: 0.010143\n",
      "[Epoch 5] Step 3000 | BCE Loss: 0.029283\n",
      "[Epoch 5] Step 3010 | BCE Loss: 0.015656\n",
      "[Epoch 5] Step 3020 | BCE Loss: 0.012250\n",
      "[Epoch 5] Step 3030 | BCE Loss: 0.011308\n",
      "[Epoch 5] Step 3040 | BCE Loss: 0.016123\n",
      "[Epoch 5] Step 3050 | BCE Loss: 0.011259\n",
      "[Epoch 5] Step 3060 | BCE Loss: 0.019089\n",
      "[Epoch 5] Step 3070 | BCE Loss: 0.013012\n",
      "[Epoch 5] Step 3080 | BCE Loss: 0.016781\n",
      "[Epoch 5] Step 3090 | BCE Loss: 0.015246\n",
      "[Epoch 5] Step 3100 | BCE Loss: 0.016544\n",
      "[Epoch 5] Step 3110 | BCE Loss: 0.017303\n",
      "[Epoch 5] Step 3120 | BCE Loss: 0.057637\n",
      "[Epoch 5] Step 3130 | BCE Loss: 0.015879\n",
      "[Epoch 5] Step 3140 | BCE Loss: 0.012133\n",
      "[Epoch 5] Step 3150 | BCE Loss: 0.011216\n",
      "[Epoch 5] Step 3160 | BCE Loss: 0.012058\n",
      "[Epoch 5] Step 3170 | BCE Loss: 0.015792\n",
      "[Epoch 5] Step 3180 | BCE Loss: 0.016395\n",
      "[Epoch 5] Step 3190 | BCE Loss: 0.012211\n",
      "[Epoch 5] Step 3200 | BCE Loss: 0.014297\n",
      "[Epoch 5] Step 3210 | BCE Loss: 0.016027\n",
      "[Epoch 5] Step 3220 | BCE Loss: 0.012851\n",
      "[Epoch 5] Step 3230 | BCE Loss: 0.012216\n",
      "[Epoch 5] Step 3240 | BCE Loss: 0.014891\n",
      "[Epoch 5] Step 3250 | BCE Loss: 0.014081\n",
      "[Epoch 5] Step 3260 | BCE Loss: 0.017303\n",
      "[Epoch 5] Step 3270 | BCE Loss: 0.014764\n",
      "[Epoch 5] Step 3280 | BCE Loss: 0.013360\n",
      "[Epoch 5] Step 3290 | BCE Loss: 0.015443\n",
      "[Epoch 5] Step 3300 | BCE Loss: 0.014849\n",
      "[Epoch 5] Step 3310 | BCE Loss: 0.028721\n",
      "[Epoch 5] Step 3320 | BCE Loss: 0.010329\n",
      "[Epoch 5] Step 3330 | BCE Loss: 0.013732\n",
      "[Epoch 5] Step 3340 | BCE Loss: 0.012681\n",
      "[Epoch 5] Step 3350 | BCE Loss: 0.014139\n",
      "[Epoch 5] Step 3360 | BCE Loss: 0.012829\n",
      "[Epoch 5] Step 3370 | BCE Loss: 0.008727\n",
      "[Epoch 5] Step 3380 | BCE Loss: 0.029607\n",
      "[Epoch 5] Step 3390 | BCE Loss: 0.012115\n",
      "[Epoch 5] Step 3400 | BCE Loss: 0.020747\n",
      "[Epoch 5] Step 3410 | BCE Loss: 0.020400\n",
      "[Epoch 5] Step 3420 | BCE Loss: 0.012462\n",
      "[Epoch 5] Step 3430 | BCE Loss: 0.015803\n",
      "[Epoch 5] Step 3440 | BCE Loss: 0.021259\n",
      "[Epoch 5] Step 3450 | BCE Loss: 0.016057\n",
      "[Epoch 5] Step 3460 | BCE Loss: 0.014913\n",
      "[Epoch 5] Step 3470 | BCE Loss: 0.013373\n",
      "[Epoch 5] Step 3480 | BCE Loss: 0.016819\n",
      "[Epoch 5] Step 3490 | BCE Loss: 0.011967\n",
      "[Epoch 5] Step 3500 | BCE Loss: 0.012315\n",
      "[Epoch 5] Step 3510 | BCE Loss: 0.013056\n",
      "[Epoch 5] Step 3520 | BCE Loss: 0.027270\n",
      "[Epoch 5] Step 3530 | BCE Loss: 0.013612\n",
      "[Epoch 5] Step 3540 | BCE Loss: 0.009724\n",
      "[Epoch 5] Step 3550 | BCE Loss: 0.017280\n",
      "[Epoch 5] Step 3560 | BCE Loss: 0.014352\n",
      "[Epoch 5] Step 3570 | BCE Loss: 0.013828\n",
      "[Epoch 5] Step 3580 | BCE Loss: 0.014582\n",
      "[Epoch 5] Step 3590 | BCE Loss: 0.008640\n",
      "[Epoch 5] Step 3600 | BCE Loss: 0.021528\n",
      "[Epoch 5] Step 3610 | BCE Loss: 0.015143\n",
      "[Epoch 5] Step 3620 | BCE Loss: 0.012381\n",
      "[Epoch 5] Step 3630 | BCE Loss: 0.010707\n",
      "[Epoch 5] Step 3640 | BCE Loss: 0.012367\n",
      "[Epoch 5] Step 3650 | BCE Loss: 0.014772\n",
      "[Epoch 5] Step 3660 | BCE Loss: 0.017384\n",
      "[Epoch 5] Step 3670 | BCE Loss: 0.015015\n",
      "[Epoch 5] Step 3680 | BCE Loss: 0.016172\n",
      "[Epoch 5] Step 3690 | BCE Loss: 0.017320\n",
      "[Epoch 5] Step 3700 | BCE Loss: 0.013176\n",
      "[Epoch 5] Step 3710 | BCE Loss: 0.013321\n",
      "[Epoch 5] Step 3720 | BCE Loss: 0.018125\n",
      "[Epoch 5] Step 3730 | BCE Loss: 0.013815\n",
      "[Epoch 5] Step 3740 | BCE Loss: 0.012470\n",
      "[Epoch 5] Step 3750 | BCE Loss: 0.018974\n",
      "[Epoch 5] Step 3760 | BCE Loss: 0.015360\n",
      "[Epoch 5] Step 3770 | BCE Loss: 0.018022\n",
      "[Epoch 5] Step 3780 | BCE Loss: 0.012258\n",
      "[Epoch 5] Step 3790 | BCE Loss: 0.025805\n",
      "[Epoch 5] Step 3800 | BCE Loss: 0.017527\n",
      "[Epoch 5] Step 3810 | BCE Loss: 0.016547\n",
      "[Epoch 5] Step 3820 | BCE Loss: 0.013719\n",
      "[Epoch 5] Step 3830 | BCE Loss: 0.016133\n",
      "[Epoch 5] Step 3840 | BCE Loss: 0.022068\n",
      "[Epoch 5] Step 3850 | BCE Loss: 0.009661\n",
      "[Epoch 5] Step 3860 | BCE Loss: 0.016828\n",
      "[Epoch 5] Step 3870 | BCE Loss: 0.020879\n",
      "[Epoch 5] Step 3880 | BCE Loss: 0.019316\n",
      "[Epoch 5] Step 3890 | BCE Loss: 0.014374\n",
      "[Epoch 5] Step 3900 | BCE Loss: 0.016777\n",
      "[Epoch 5] Step 3910 | BCE Loss: 0.017448\n",
      "[Epoch 5] Step 3920 | BCE Loss: 0.011126\n",
      "[Epoch 5] Step 3930 | BCE Loss: 0.010957\n",
      "[Epoch 5] Step 3940 | BCE Loss: 0.012940\n",
      "[Epoch 5] Step 3950 | BCE Loss: 0.017298\n",
      "[Epoch 5] Step 3960 | BCE Loss: 0.021413\n",
      "[Epoch 5] Step 3970 | BCE Loss: 0.009242\n",
      "[Epoch 5] Step 3980 | BCE Loss: 0.016903\n",
      "[Epoch 5] Step 3990 | BCE Loss: 0.013476\n",
      "[Epoch 5] Step 4000 | BCE Loss: 0.015345\n",
      "[Epoch 5] Step 4010 | BCE Loss: 0.016101\n",
      "[Epoch 5] Step 4020 | BCE Loss: 0.020443\n",
      "[Epoch 5] Step 4030 | BCE Loss: 0.016665\n",
      "[Epoch 5] Step 4040 | BCE Loss: 0.011302\n",
      "[Epoch 5] Step 4050 | BCE Loss: 0.017572\n",
      "[Epoch 5] Step 4060 | BCE Loss: 0.033357\n",
      "[Epoch 5] Step 4070 | BCE Loss: 0.016973\n",
      "[Epoch 5] Step 4080 | BCE Loss: 0.017544\n",
      "[Epoch 5] Step 4090 | BCE Loss: 0.020383\n",
      "[Epoch 5] Step 4100 | BCE Loss: 0.013658\n",
      "[Epoch 5] Step 4110 | BCE Loss: 0.011544\n",
      "[Epoch 5] Step 4120 | BCE Loss: 0.014216\n",
      "[Epoch 5] Step 4130 | BCE Loss: 0.014904\n",
      "[Epoch 5] Step 4140 | BCE Loss: 0.016506\n",
      "[Epoch 5] Step 4150 | BCE Loss: 0.015772\n",
      "[Epoch 5] Step 4160 | BCE Loss: 0.012328\n",
      "[Epoch 5] Step 4170 | BCE Loss: 0.011351\n",
      "[Epoch 5] Step 4180 | BCE Loss: 0.018623\n",
      "[Epoch 5] Step 4190 | BCE Loss: 0.035780\n",
      "[Epoch 5] Step 4200 | BCE Loss: 0.017117\n",
      "[Epoch 5] Step 4210 | BCE Loss: 0.018637\n",
      "[Epoch 5] Step 4220 | BCE Loss: 0.015701\n",
      "[Epoch 5] Step 4230 | BCE Loss: 0.014250\n",
      "[Epoch 5] Step 4240 | BCE Loss: 0.010141\n",
      "[Epoch 5] Step 4250 | BCE Loss: 0.015675\n",
      "[Epoch 5] Step 4260 | BCE Loss: 0.017914\n",
      "[Epoch 5] Step 4270 | BCE Loss: 0.013586\n",
      "[Epoch 5] Step 4280 | BCE Loss: 0.014937\n",
      "[Epoch 5] Step 4290 | BCE Loss: 0.014687\n",
      "[Epoch 5] Step 4300 | BCE Loss: 0.068532\n",
      "[Epoch 5] Step 4310 | BCE Loss: 0.011188\n",
      "[Epoch 5] Step 4320 | BCE Loss: 0.018466\n",
      "[Epoch 5] Step 4330 | BCE Loss: 0.019758\n",
      "[Epoch 5] Step 4340 | BCE Loss: 0.015263\n",
      "[Epoch 5] Step 4350 | BCE Loss: 0.017038\n",
      "[Epoch 5] Step 4360 | BCE Loss: 0.018624\n",
      "[Epoch 5] Step 4370 | BCE Loss: 0.018969\n",
      "[Epoch 5] Step 4380 | BCE Loss: 0.016355\n",
      "[Epoch 5] Step 4390 | BCE Loss: 0.015777\n",
      "[Epoch 5] Step 4400 | BCE Loss: 0.016998\n",
      "[Epoch 5] Step 4410 | BCE Loss: 0.012065\n",
      "[Epoch 5] Step 4420 | BCE Loss: 0.076441\n",
      "[Epoch 5] Step 4430 | BCE Loss: 0.020336\n",
      "[Epoch 5] Step 4440 | BCE Loss: 0.019107\n",
      "[Epoch 5] Step 4450 | BCE Loss: 0.012054\n",
      "[Epoch 5] Step 4460 | BCE Loss: 0.022866\n",
      "[Epoch 5] Step 4470 | BCE Loss: 0.015306\n",
      "[Epoch 5] Step 4480 | BCE Loss: 0.014164\n",
      "[Epoch 5] Step 4490 | BCE Loss: 0.012995\n",
      "[Epoch 5] Step 4500 | BCE Loss: 0.025219\n",
      "[Epoch 5] Step 4510 | BCE Loss: 0.015046\n",
      "[Epoch 5] Step 4520 | BCE Loss: 0.011603\n",
      "[Epoch 5] Step 4530 | BCE Loss: 0.012082\n",
      "[Epoch 5] Step 4540 | BCE Loss: 0.012484\n",
      "[Epoch 5] Step 4550 | BCE Loss: 0.017794\n",
      "[Epoch 5] Step 4560 | BCE Loss: 0.014678\n",
      "[Epoch 5] Step 4570 | BCE Loss: 0.014846\n",
      "[Epoch 5] Step 4580 | BCE Loss: 0.018043\n",
      "[Epoch 5] Step 4590 | BCE Loss: 0.017738\n",
      "[Epoch 5] Step 4600 | BCE Loss: 0.029253\n",
      "[Epoch 5] Step 4610 | BCE Loss: 0.015263\n",
      "[Epoch 5] Step 4620 | BCE Loss: 0.011100\n",
      "[Epoch 5] Step 4630 | BCE Loss: 0.010598\n",
      "[Epoch 5] Step 4640 | BCE Loss: 0.014361\n",
      "[Epoch 5] Step 4650 | BCE Loss: 0.017521\n",
      "[Epoch 5] Step 4660 | BCE Loss: 0.014148\n",
      "[Epoch 5] Step 4670 | BCE Loss: 0.012928\n",
      "[Epoch 5] Step 4680 | BCE Loss: 0.010684\n",
      "[Epoch 5] Step 4690 | BCE Loss: 0.013333\n",
      "[Epoch 5] Step 4700 | BCE Loss: 0.013549\n",
      "[Epoch 5] Step 4710 | BCE Loss: 0.016000\n",
      "[Epoch 5] Step 4720 | BCE Loss: 0.012367\n",
      "[Epoch 5] Step 4730 | BCE Loss: 0.021567\n",
      "[Epoch 5] Step 4740 | BCE Loss: 0.017231\n",
      "[Epoch 5] Step 4750 | BCE Loss: 0.011182\n",
      "[Epoch 5] Step 4760 | BCE Loss: 0.013609\n",
      "[Epoch 5] Step 4770 | BCE Loss: 0.033532\n",
      "[Epoch 5] Step 4780 | BCE Loss: 0.016045\n",
      "[Epoch 5] Step 4790 | BCE Loss: 0.034285\n",
      "[Epoch 5] Step 4800 | BCE Loss: 0.016176\n",
      "[Epoch 5] Step 4810 | BCE Loss: 0.014096\n",
      "[Epoch 5] Step 4820 | BCE Loss: 0.015223\n",
      "[Epoch 5] Step 4830 | BCE Loss: 0.011101\n",
      "[Epoch 5] Step 4840 | BCE Loss: 0.017645\n",
      "[Epoch 5] Step 4850 | BCE Loss: 0.011161\n",
      "[Epoch 5] Step 4860 | BCE Loss: 0.014057\n",
      "[Epoch 5] Step 4870 | BCE Loss: 0.012185\n",
      "[Epoch 5] Step 4880 | BCE Loss: 0.013007\n",
      "[Epoch 5] Step 4890 | BCE Loss: 0.019260\n",
      "[Epoch 5] Step 4900 | BCE Loss: 0.027746\n",
      "[Epoch 5] Step 4910 | BCE Loss: 0.009919\n",
      "[Epoch 5] Step 4920 | BCE Loss: 0.012612\n",
      "[Epoch 5] Step 4930 | BCE Loss: 0.013772\n",
      "[Epoch 5] Step 4940 | BCE Loss: 0.011059\n",
      "[Epoch 5] Step 4950 | BCE Loss: 0.014412\n",
      "[Epoch 5] Step 4960 | BCE Loss: 0.013165\n",
      "[Epoch 5] Step 4970 | BCE Loss: 0.015557\n",
      "[Epoch 5] Step 4980 | BCE Loss: 0.013453\n",
      "[Epoch 5] Step 4990 | BCE Loss: 0.034674\n",
      "[Epoch 5] Step 5000 | BCE Loss: 0.011761\n",
      "[Epoch 5] Step 5010 | BCE Loss: 0.016735\n",
      "[Epoch 5] Step 5020 | BCE Loss: 0.011957\n",
      "[Epoch 5] Step 5030 | BCE Loss: 0.019012\n",
      "[Epoch 5] Step 5040 | BCE Loss: 0.016311\n",
      "[Epoch 5] Step 5050 | BCE Loss: 0.016114\n",
      "[Epoch 5] Step 5060 | BCE Loss: 0.016535\n",
      "[Epoch 5] Step 5070 | BCE Loss: 0.012794\n",
      "[Epoch 5] Step 5080 | BCE Loss: 0.031179\n",
      "[Epoch 5] Step 5090 | BCE Loss: 0.014035\n",
      "[Epoch 5] Step 5100 | BCE Loss: 0.014920\n",
      "[Epoch 5] Step 5110 | BCE Loss: 0.016787\n",
      "[Epoch 5] Step 5120 | BCE Loss: 0.016570\n",
      "[Epoch 5] Step 5130 | BCE Loss: 0.014884\n",
      "[Epoch 5] Step 5140 | BCE Loss: 0.015109\n",
      "[Epoch 5] Step 5150 | BCE Loss: 0.015570\n",
      "[Epoch 5] Step 5160 | BCE Loss: 0.022996\n",
      "[Epoch 5] Step 5170 | BCE Loss: 0.015597\n",
      "[Epoch 5] Step 5180 | BCE Loss: 0.012664\n",
      "[Epoch 5] Step 5190 | BCE Loss: 0.021109\n",
      "[Epoch 5] Step 5200 | BCE Loss: 0.014097\n",
      "[Epoch 5] Step 5210 | BCE Loss: 0.012084\n",
      "[Epoch 5] Step 5220 | BCE Loss: 0.010420\n",
      "[Epoch 5] Step 5230 | BCE Loss: 0.012721\n",
      "[Epoch 5] Step 5240 | BCE Loss: 0.016771\n",
      "[Epoch 5] Step 5250 | BCE Loss: 0.023574\n",
      "[Epoch 5] Step 5260 | BCE Loss: 0.012301\n",
      "[Epoch 5] Step 5270 | BCE Loss: 0.015883\n",
      "[Epoch 5] Step 5280 | BCE Loss: 0.017824\n",
      "[Epoch 5] Step 5290 | BCE Loss: 0.012729\n",
      "[Epoch 5] Step 5300 | BCE Loss: 0.018639\n",
      "[Epoch 5] Step 5310 | BCE Loss: 0.012690\n",
      "[Epoch 5] Step 5320 | BCE Loss: 0.016104\n",
      "[Epoch 5] Step 5330 | BCE Loss: 0.016431\n",
      "[Epoch 5] Step 5340 | BCE Loss: 0.021364\n",
      "[Epoch 5] Step 5350 | BCE Loss: 0.033794\n",
      "[Epoch 5] Step 5360 | BCE Loss: 0.012701\n",
      "[Epoch 5] Step 5370 | BCE Loss: 0.017202\n",
      "[Epoch 5] Step 5380 | BCE Loss: 0.015331\n",
      "[Epoch 5] Step 5390 | BCE Loss: 0.012316\n",
      "[Epoch 5] Step 5400 | BCE Loss: 0.014890\n",
      "[Epoch 5] Step 5410 | BCE Loss: 0.035221\n",
      "[Epoch 5] Step 5420 | BCE Loss: 0.020620\n",
      "[Epoch 5] Step 5430 | BCE Loss: 0.020946\n",
      "[Epoch 5] Step 5440 | BCE Loss: 0.014429\n",
      "[Epoch 5] Step 5450 | BCE Loss: 0.013788\n",
      "[Epoch 5] Step 5460 | BCE Loss: 0.013758\n",
      "[Epoch 5] Step 5470 | BCE Loss: 0.024738\n",
      "[Epoch 5] Step 5480 | BCE Loss: 0.012260\n",
      "[Epoch 5] Step 5490 | BCE Loss: 0.013882\n",
      "[Epoch 5] Step 5500 | BCE Loss: 0.013333\n",
      "[Epoch 5] Step 5510 | BCE Loss: 0.015142\n",
      "[Epoch 5] Step 5520 | BCE Loss: 0.023602\n",
      "[Epoch 5] Step 5530 | BCE Loss: 0.015755\n",
      "[Epoch 5] Step 5540 | BCE Loss: 0.011385\n",
      "[Epoch 5] Step 5550 | BCE Loss: 0.011067\n",
      "[Epoch 5] Step 5560 | BCE Loss: 0.011827\n",
      "[Epoch 5] Step 5570 | BCE Loss: 0.014992\n",
      "[Epoch 5] Step 5580 | BCE Loss: 0.013883\n",
      "[Epoch 5] Step 5590 | BCE Loss: 0.015167\n",
      "[Epoch 5] Step 5600 | BCE Loss: 0.013577\n",
      "[Epoch 5] Step 5610 | BCE Loss: 0.017979\n",
      "[Epoch 5] Step 5620 | BCE Loss: 0.014836\n",
      "[Epoch 5] Step 5630 | BCE Loss: 0.025168\n",
      "[Epoch 5] Step 5640 | BCE Loss: 0.015849\n",
      "[Epoch 5] Step 5650 | BCE Loss: 0.018526\n",
      "[Epoch 5] Step 5660 | BCE Loss: 0.014837\n",
      "[Epoch 5] Step 5670 | BCE Loss: 0.027535\n",
      "[Epoch 5] Step 5680 | BCE Loss: 0.026067\n",
      "[Epoch 5] Step 5690 | BCE Loss: 0.025656\n",
      "[Epoch 5] Step 5700 | BCE Loss: 0.014481\n",
      "[Epoch 5] Step 5710 | BCE Loss: 0.014606\n",
      "[Epoch 5] Step 5720 | BCE Loss: 0.021556\n",
      "[Epoch 5] Step 5730 | BCE Loss: 0.010719\n",
      "[Epoch 5] Step 5740 | BCE Loss: 0.010068\n",
      "[Epoch 5] Step 5750 | BCE Loss: 0.015516\n",
      "[Epoch 5] Step 5760 | BCE Loss: 0.016541\n",
      "[Epoch 5] Step 5770 | BCE Loss: 0.020400\n",
      "[Epoch 5] Step 5780 | BCE Loss: 0.022724\n",
      "[Epoch 5] Step 5790 | BCE Loss: 0.014188\n",
      "[Epoch 5] Step 5800 | BCE Loss: 0.011490\n",
      "[Epoch 5] Step 5810 | BCE Loss: 0.021770\n",
      "[Epoch 5] Step 5820 | BCE Loss: 0.016536\n",
      "\n",
      "=== Epoch 5 Selesai | Avg BCE Loss: 0.016977 ===\n",
      "[SAVE] Merging weights and saving single .pth file...\n",
      "[SAVE] Full PEFT checkpoint saved to: /kaggle/working/output/sam2_finetuned.pth\n",
      "\n",
      "========================================\n",
      "TRAINING SELESAI. File tersimpan di: /kaggle/working/output/sam2_finetuned.pth\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Path (<tt>output/sam2_finetuned.pth</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": [
       "/kaggle/working/sam2/output/sam2_finetuned.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import FileLink, display\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "IMAGE_DIR = \"/kaggle/input/high-resolution-viton-zalando-dataset/train/image\"\n",
    "MASK_DIR  = \"/kaggle/input/high-resolution-viton-zalando-dataset/train/image-parse-v3\" \n",
    "\n",
    "CHECKPOINT = \"/kaggle/working/sam2/checkpoints/sam2_hiera_small.pt\"\n",
    "CONFIG     = \"sam2_hiera_s.yaml\"\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "DATA_SIZE = 1024       \n",
    "BATCH_SIZE = 2         \n",
    "LR = 1e-4              \n",
    "EPOCHS = 5             \n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.05\n",
    "\n",
    "FINAL_FILENAME = \"sam2_finetuned.pth\"\n",
    "OUTPUT_DIR = \"/kaggle/working/output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "\n",
    "class VITONDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, size=1024):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.size = size\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "        if len(self.images) == 0:\n",
    "            raise RuntimeError(f\"No images found in {image_dir}\")\n",
    "        print(f\"[DATA] {len(self.images)} VITON images found.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        base = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        mask_path = os.path.join(self.mask_dir, base + \".png\")\n",
    "        if not os.path.exists(mask_path):\n",
    "            mask_path = os.path.join(self.mask_dir, base + \".jpg\")\n",
    "            if not os.path.exists(mask_path):\n",
    "                 mask_path = os.path.join(self.mask_dir, base + \"_label.png\")\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = None\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None or mask is None:\n",
    "            new_idx = (idx + 1) % len(self)\n",
    "            return self.__getitem__(new_idx)\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (self.size, self.size))\n",
    "        mask = cv2.resize(mask, (self.size, self.size), interpolation=cv2.INTER_NEAREST)\n",
    "        binary_mask = (mask > 0).astype(np.float32)\n",
    "\n",
    "        if binary_mask.sum() == 0:\n",
    "            new_idx = (idx + 1) % len(self)\n",
    "            return self.__getitem__(new_idx)\n",
    "\n",
    "        ys, xs = np.where(binary_mask > 0)\n",
    "        x_min, x_max = xs.min(), xs.max()\n",
    "        y_min, y_max = ys.min(), ys.max()\n",
    "\n",
    "        noise = np.random.randint(-10, 10, size=4)\n",
    "        box = np.array([x_min, y_min, x_max, y_max]) + noise\n",
    "        box = np.clip(box, 0, self.size).astype(np.float32)\n",
    "\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = torch.tensor(image).permute(2,0,1).contiguous()\n",
    "        binary_mask = torch.tensor(binary_mask).unsqueeze(0).float()\n",
    "        box = torch.tensor(box).float()\n",
    "\n",
    "        return image, binary_mask, box\n",
    "\n",
    "print(\"[MODEL] Building SAM2 model...\")\n",
    "model = build_sam2(CONFIG, CHECKPOINT, device=DEVICE)\n",
    "\n",
    "# 1. Identifikasi layer Linear di dalam Mask Decoder untuk dipasang LoRA\n",
    "target_modules = []\n",
    "for name, module in model.sam_mask_decoder.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        full_name = f\"sam_mask_decoder.{name}\"\n",
    "        target_modules.append(full_name)\n",
    "\n",
    "print(f\"[PEFT] Found {len(target_modules)} linear layers in Mask Decoder to target.\")\n",
    "\n",
    "# 2. Konfigurasi LoRA menggunakan PEFT\n",
    "peft_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=None, \n",
    ")\n",
    "\n",
    "# 3. Wrap model dengan PEFT\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# 4. Unfreeze Prompt Encoder\n",
    "for n, p in model.base_model.model.sam_prompt_encoder.named_parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "dataset = VITONDataset(IMAGE_DIR, MASK_DIR, size=DATA_SIZE)\n",
    "print(\"[DATA] Dataset length:\", len(dataset))\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(\"[OPTIMIZER] Using bitsandbytes 8-bit AdamW\")\n",
    "optimizer = bnb.optim.AdamW8bit(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "model.train()\n",
    "print(\"\\n--- MULAI TRAINING VITON (PEFT + BNB 8-bit) ---\")\n",
    "\n",
    "try:\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n[Epoch {epoch+1}/{EPOCHS}]\")\n",
    "        total_loss = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        for i, (images, gt_masks, boxes) in enumerate(dataloader):\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            gt_masks = gt_masks.to(DEVICE, non_blocking=True)\n",
    "            boxes = boxes.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if DEVICE == \"cuda\":\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        backbone_out = model.forward_image(images)\n",
    "                else:\n",
    "                    backbone_out = model.forward_image(images)\n",
    "\n",
    "            boxes_for_encoder = boxes.unsqueeze(1)\n",
    "            sparse_embeddings, dense_embeddings = model.base_model.model.sam_prompt_encoder(\n",
    "                points=None,\n",
    "                boxes=boxes_for_encoder,\n",
    "                masks=None\n",
    "            )\n",
    "\n",
    "            image_embed = backbone_out.get(\"vision_features\", None)\n",
    "            image_pe = model.base_model.model.sam_prompt_encoder.get_dense_pe()\n",
    "            \n",
    "            if \"backbone_fpn\" in backbone_out:\n",
    "                fpn = backbone_out[\"backbone_fpn\"]\n",
    "                if isinstance(fpn, (list, tuple)) and len(fpn) >= 2:\n",
    "                    high_res_features = [fpn[0], fpn[1]]\n",
    "                else:\n",
    "                    high_res_features = list(fpn) if isinstance(fpn, (list, tuple)) else [fpn]\n",
    "            else:\n",
    "                high_res_features = None\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "                decoder_out = model.base_model.model.sam_mask_decoder(\n",
    "                    image_embeddings=image_embed,\n",
    "                    image_pe=image_pe,\n",
    "                    sparse_prompt_embeddings=sparse_embeddings,\n",
    "                    dense_prompt_embeddings=dense_embeddings,\n",
    "                    multimask_output=False,\n",
    "                    repeat_image=False,\n",
    "                    high_res_features=high_res_features,\n",
    "                )\n",
    "\n",
    "                if isinstance(decoder_out, tuple) or isinstance(decoder_out, list):\n",
    "                     low_res_masks = decoder_out[0]\n",
    "                else:\n",
    "                     low_res_masks = decoder_out\n",
    "\n",
    "                pred_masks = torch.nn.functional.interpolate(\n",
    "                    low_res_masks,\n",
    "                    size=(gt_masks.shape[2], gt_masks.shape[3]),\n",
    "                    mode=\"bilinear\",\n",
    "                    align_corners=False\n",
    "                )\n",
    "                \n",
    "                loss = loss_fn(pred_masks, gt_masks)\n",
    "\n",
    "            if DEVICE == \"cuda\":\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"[Epoch {epoch+1}] Step {i} | BCE Loss: {loss.item():.6f}\")\n",
    "\n",
    "        avg_loss = total_loss / steps if steps > 0 else 0.0\n",
    "        print(f\"\\n=== Epoch {epoch+1} Selesai | Avg BCE Loss: {avg_loss:.6f} ===\")\n",
    "        print(\"[SAVE] Merging weights and saving single .pth file...\")\n",
    "        \n",
    "        save_path = os.path.join(OUTPUT_DIR, FINAL_FILENAME)\n",
    "        \n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"[SAVE] Full PEFT checkpoint saved to: {save_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"TRAINING SELESAI. File tersimpan di: {save_path}\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    relative_path = os.path.join(\"output\", FINAL_FILENAME)\n",
    "    if os.path.exists(save_path):\n",
    "        display(FileLink(relative_path))\n",
    "    else:\n",
    "        print(\"File tidak ditemukan.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] Crash occurred:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3855472,
     "sourceId": 6683799,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
